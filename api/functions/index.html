
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://pyjanitor-devs.github.io/pyjanitor/api/functions/">
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.4.2, mkdocs-material-8.5.2">
    
    
      
        <title>Functions - pyjanitor documentation</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.9f9400aa.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.cbb835fc.min.css">
        
          
          
          <meta name="theme-color" content="#546d78">
        
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../css/nb_mods.css">
    
      <link rel="stylesheet" href="../../css/apidocs.css">
    
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.7.2/styles/nord.min.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="blue-grey" data-md-color-accent="blue-grey">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#functions" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="pyjanitor documentation" class="md-header__button md-logo" aria-label="pyjanitor documentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M96 0C43 0 0 43 0 96v320c0 53 43 96 96 96h320c17.7 0 32-14.3 32-32s-14.3-32-32-32v-64c17.7 0 32-14.3 32-32V32c0-17.7-14.3-32-32-32H96zm0 384h256v64H96c-17.7 0-32-14.3-32-32s14.3-32 32-32zm32-240c0-8.8 7.2-16 16-16h192c8.8 0 16 7.2 16 16s-7.2 16-16 16H144c-8.8 0-16-7.2-16-16zm16 48h192c8.8 0 16 7.2 16 16s-7.2 16-16 16H144c-8.8 0-16-7.2-16-16s7.2-16 16-16z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            pyjanitor documentation
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Functions
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/pyjanitor-devs/pyjanitor" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    pyjanitor-devs/pyjanitor
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="pyjanitor documentation" class="md-nav__button md-logo" aria-label="pyjanitor documentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M96 0C43 0 0 43 0 96v320c0 53 43 96 96 96h320c17.7 0 32-14.3 32-32s-14.3-32-32-32v-64c17.7 0 32-14.3 32-32V32c0-17.7-14.3-32-32-32H96zm0 384h256v64H96c-17.7 0-32-14.3-32-32s14.3-32 32-32zm32-240c0-8.8 7.2-16 16-16h192c8.8 0 16 7.2 16 16s-7.2 16-16 16H144c-8.8 0-16-7.2-16-16zm16 48h192c8.8 0 16 7.2 16 16s-7.2 16-16 16H144c-8.8 0-16-7.2-16-16s7.2-16 16-16z"/></svg>

    </a>
    pyjanitor documentation
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/pyjanitor-devs/pyjanitor" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    pyjanitor-devs/pyjanitor
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../devguide/" class="md-nav__link">
        Development Guide
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_3">
          API Reference
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="API Reference" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          API Reference
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Functions
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Functions
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#janitor.functions" class="md-nav__link">
    janitor.functions
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions--general-functions" class="md-nav__link">
    General Functions
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.add_columns" class="md-nav__link">
    add_columns
  </a>
  
    <nav class="md-nav" aria-label="add_columns">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.add_columns.add_column" class="md-nav__link">
    add_column()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#janitor.functions.add_columns.add_columns" class="md-nav__link">
    add_columns()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.also" class="md-nav__link">
    also
  </a>
  
    <nav class="md-nav" aria-label="also">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.also.also" class="md-nav__link">
    also()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.bin_numeric" class="md-nav__link">
    bin_numeric
  </a>
  
    <nav class="md-nav" aria-label="bin_numeric">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.bin_numeric.bin_numeric" class="md-nav__link">
    bin_numeric()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.case_when" class="md-nav__link">
    case_when
  </a>
  
    <nav class="md-nav" aria-label="case_when">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.case_when.case_when" class="md-nav__link">
    case_when()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.change_type" class="md-nav__link">
    change_type
  </a>
  
    <nav class="md-nav" aria-label="change_type">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.change_type.change_type" class="md-nav__link">
    change_type()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.clean_names" class="md-nav__link">
    clean_names
  </a>
  
    <nav class="md-nav" aria-label="clean_names">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.clean_names.clean_names" class="md-nav__link">
    clean_names()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.coalesce" class="md-nav__link">
    coalesce
  </a>
  
    <nav class="md-nav" aria-label="coalesce">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.coalesce.coalesce" class="md-nav__link">
    coalesce()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.collapse_levels" class="md-nav__link">
    collapse_levels
  </a>
  
    <nav class="md-nav" aria-label="collapse_levels">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.collapse_levels.collapse_levels" class="md-nav__link">
    collapse_levels()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.complete" class="md-nav__link">
    complete
  </a>
  
    <nav class="md-nav" aria-label="complete">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.complete.complete" class="md-nav__link">
    complete()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.concatenate_columns" class="md-nav__link">
    concatenate_columns
  </a>
  
    <nav class="md-nav" aria-label="concatenate_columns">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.concatenate_columns.concatenate_columns" class="md-nav__link">
    concatenate_columns()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.conditional_join" class="md-nav__link">
    conditional_join
  </a>
  
    <nav class="md-nav" aria-label="conditional_join">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.conditional_join.conditional_join" class="md-nav__link">
    conditional_join()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.convert_date" class="md-nav__link">
    convert_date
  </a>
  
    <nav class="md-nav" aria-label="convert_date">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.convert_date.convert_excel_date" class="md-nav__link">
    convert_excel_date()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#janitor.functions.convert_date.convert_matlab_date" class="md-nav__link">
    convert_matlab_date()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#janitor.functions.convert_date.convert_unix_date" class="md-nav__link">
    convert_unix_date()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.count_cumulative_unique" class="md-nav__link">
    count_cumulative_unique
  </a>
  
    <nav class="md-nav" aria-label="count_cumulative_unique">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.count_cumulative_unique.count_cumulative_unique" class="md-nav__link">
    count_cumulative_unique()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.currency_column_to_numeric" class="md-nav__link">
    currency_column_to_numeric
  </a>
  
    <nav class="md-nav" aria-label="currency_column_to_numeric">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.currency_column_to_numeric.currency_column_to_numeric" class="md-nav__link">
    currency_column_to_numeric()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.deconcatenate_column" class="md-nav__link">
    deconcatenate_column
  </a>
  
    <nav class="md-nav" aria-label="deconcatenate_column">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.deconcatenate_column.deconcatenate_column" class="md-nav__link">
    deconcatenate_column()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.drop_constant_columns" class="md-nav__link">
    drop_constant_columns
  </a>
  
    <nav class="md-nav" aria-label="drop_constant_columns">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.drop_constant_columns.drop_constant_columns" class="md-nav__link">
    drop_constant_columns()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.drop_duplicate_columns" class="md-nav__link">
    drop_duplicate_columns
  </a>
  
    <nav class="md-nav" aria-label="drop_duplicate_columns">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.drop_duplicate_columns.drop_duplicate_columns" class="md-nav__link">
    drop_duplicate_columns()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.dropnotnull" class="md-nav__link">
    dropnotnull
  </a>
  
    <nav class="md-nav" aria-label="dropnotnull">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.dropnotnull.dropnotnull" class="md-nav__link">
    dropnotnull()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.encode_categorical" class="md-nav__link">
    encode_categorical
  </a>
  
    <nav class="md-nav" aria-label="encode_categorical">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.encode_categorical.encode_categorical" class="md-nav__link">
    encode_categorical()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.expand_column" class="md-nav__link">
    expand_column
  </a>
  
    <nav class="md-nav" aria-label="expand_column">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.expand_column.expand_column" class="md-nav__link">
    expand_column()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.expand_grid" class="md-nav__link">
    expand_grid
  </a>
  
    <nav class="md-nav" aria-label="expand_grid">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.expand_grid.expand_grid" class="md-nav__link">
    expand_grid()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.factorize_columns" class="md-nav__link">
    factorize_columns
  </a>
  
    <nav class="md-nav" aria-label="factorize_columns">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.factorize_columns.factorize_columns" class="md-nav__link">
    factorize_columns()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.fill" class="md-nav__link">
    fill
  </a>
  
    <nav class="md-nav" aria-label="fill">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.fill.fill_direction" class="md-nav__link">
    fill_direction()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#janitor.functions.fill.fill_empty" class="md-nav__link">
    fill_empty()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.filter" class="md-nav__link">
    filter
  </a>
  
    <nav class="md-nav" aria-label="filter">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.filter.filter_column_isin" class="md-nav__link">
    filter_column_isin()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#janitor.functions.filter.filter_date" class="md-nav__link">
    filter_date()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#janitor.functions.filter.filter_on" class="md-nav__link">
    filter_on()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#janitor.functions.filter.filter_string" class="md-nav__link">
    filter_string()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.find_replace" class="md-nav__link">
    find_replace
  </a>
  
    <nav class="md-nav" aria-label="find_replace">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.find_replace.find_replace" class="md-nav__link">
    find_replace()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.flag_nulls" class="md-nav__link">
    flag_nulls
  </a>
  
    <nav class="md-nav" aria-label="flag_nulls">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.flag_nulls.flag_nulls" class="md-nav__link">
    flag_nulls()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.get_dupes" class="md-nav__link">
    get_dupes
  </a>
  
    <nav class="md-nav" aria-label="get_dupes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.get_dupes.get_dupes" class="md-nav__link">
    get_dupes()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.groupby_agg" class="md-nav__link">
    groupby_agg
  </a>
  
    <nav class="md-nav" aria-label="groupby_agg">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.groupby_agg.groupby_agg" class="md-nav__link">
    groupby_agg()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.groupby_topk" class="md-nav__link">
    groupby_topk
  </a>
  
    <nav class="md-nav" aria-label="groupby_topk">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.groupby_topk.groupby_topk" class="md-nav__link">
    groupby_topk()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.impute" class="md-nav__link">
    impute
  </a>
  
    <nav class="md-nav" aria-label="impute">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.impute.impute" class="md-nav__link">
    impute()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.jitter" class="md-nav__link">
    jitter
  </a>
  
    <nav class="md-nav" aria-label="jitter">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.jitter.jitter" class="md-nav__link">
    jitter()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.join_apply" class="md-nav__link">
    join_apply
  </a>
  
    <nav class="md-nav" aria-label="join_apply">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.join_apply.join_apply" class="md-nav__link">
    join_apply()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.label_encode" class="md-nav__link">
    label_encode
  </a>
  
    <nav class="md-nav" aria-label="label_encode">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.label_encode.label_encode" class="md-nav__link">
    label_encode()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.limit_column_characters" class="md-nav__link">
    limit_column_characters
  </a>
  
    <nav class="md-nav" aria-label="limit_column_characters">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.limit_column_characters.limit_column_characters" class="md-nav__link">
    limit_column_characters()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.min_max_scale" class="md-nav__link">
    min_max_scale
  </a>
  
    <nav class="md-nav" aria-label="min_max_scale">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.min_max_scale.min_max_scale" class="md-nav__link">
    min_max_scale()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.move" class="md-nav__link">
    move
  </a>
  
    <nav class="md-nav" aria-label="move">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.move.move" class="md-nav__link">
    move()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.pivot" class="md-nav__link">
    pivot
  </a>
  
    <nav class="md-nav" aria-label="pivot">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.pivot.pivot_longer" class="md-nav__link">
    pivot_longer()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#janitor.functions.pivot.pivot_wider" class="md-nav__link">
    pivot_wider()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.process_text" class="md-nav__link">
    process_text
  </a>
  
    <nav class="md-nav" aria-label="process_text">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.process_text.process_text" class="md-nav__link">
    process_text()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.remove_columns" class="md-nav__link">
    remove_columns
  </a>
  
    <nav class="md-nav" aria-label="remove_columns">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.remove_columns.remove_columns" class="md-nav__link">
    remove_columns()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.remove_empty" class="md-nav__link">
    remove_empty
  </a>
  
    <nav class="md-nav" aria-label="remove_empty">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.remove_empty.remove_empty" class="md-nav__link">
    remove_empty()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.rename_columns" class="md-nav__link">
    rename_columns
  </a>
  
    <nav class="md-nav" aria-label="rename_columns">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.rename_columns.rename_column" class="md-nav__link">
    rename_column()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#janitor.functions.rename_columns.rename_columns" class="md-nav__link">
    rename_columns()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.reorder_columns" class="md-nav__link">
    reorder_columns
  </a>
  
    <nav class="md-nav" aria-label="reorder_columns">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.reorder_columns.reorder_columns" class="md-nav__link">
    reorder_columns()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.round_to_fraction" class="md-nav__link">
    round_to_fraction
  </a>
  
    <nav class="md-nav" aria-label="round_to_fraction">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.round_to_fraction.round_to_fraction" class="md-nav__link">
    round_to_fraction()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.row_to_names" class="md-nav__link">
    row_to_names
  </a>
  
    <nav class="md-nav" aria-label="row_to_names">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.row_to_names.row_to_names" class="md-nav__link">
    row_to_names()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.select" class="md-nav__link">
    select
  </a>
  
    <nav class="md-nav" aria-label="select">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.select.select" class="md-nav__link">
    select()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#janitor.functions.select.select_columns" class="md-nav__link">
    select_columns()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#janitor.functions.select.select_rows" class="md-nav__link">
    select_rows()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.shuffle" class="md-nav__link">
    shuffle
  </a>
  
    <nav class="md-nav" aria-label="shuffle">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.shuffle.shuffle" class="md-nav__link">
    shuffle()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.sort_column_value_order" class="md-nav__link">
    sort_column_value_order
  </a>
  
    <nav class="md-nav" aria-label="sort_column_value_order">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.sort_column_value_order.sort_column_value_order" class="md-nav__link">
    sort_column_value_order()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.sort_naturally" class="md-nav__link">
    sort_naturally
  </a>
  
    <nav class="md-nav" aria-label="sort_naturally">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.sort_naturally.sort_naturally" class="md-nav__link">
    sort_naturally()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.take_first" class="md-nav__link">
    take_first
  </a>
  
    <nav class="md-nav" aria-label="take_first">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.take_first.take_first" class="md-nav__link">
    take_first()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.then" class="md-nav__link">
    then
  </a>
  
    <nav class="md-nav" aria-label="then">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.then.then" class="md-nav__link">
    then()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.to_datetime" class="md-nav__link">
    to_datetime
  </a>
  
    <nav class="md-nav" aria-label="to_datetime">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.to_datetime.to_datetime" class="md-nav__link">
    to_datetime()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.toset" class="md-nav__link">
    toset
  </a>
  
    <nav class="md-nav" aria-label="toset">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.toset.toset" class="md-nav__link">
    toset()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.transform_columns" class="md-nav__link">
    transform_columns
  </a>
  
    <nav class="md-nav" aria-label="transform_columns">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.transform_columns.transform_column" class="md-nav__link">
    transform_column()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#janitor.functions.transform_columns.transform_columns" class="md-nav__link">
    transform_columns()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.truncate_datetime" class="md-nav__link">
    truncate_datetime
  </a>
  
    <nav class="md-nav" aria-label="truncate_datetime">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.truncate_datetime.truncate_datetime_dataframe" class="md-nav__link">
    truncate_datetime_dataframe()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.update_where" class="md-nav__link">
    update_where
  </a>
  
    <nav class="md-nav" aria-label="update_where">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.update_where.update_where" class="md-nav__link">
    update_where()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.utils" class="md-nav__link">
    utils
  </a>
  
    <nav class="md-nav" aria-label="utils">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.utils.DropLabel" class="md-nav__link">
    DropLabel
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#janitor.functions.utils.patterns" class="md-nav__link">
    patterns()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#janitor.functions.utils.unionize_dataframe_categories" class="md-nav__link">
    unionize_dataframe_categories()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../biology/" class="md-nav__link">
        Biology
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../chemistry/" class="md-nav__link">
        Chemistry
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../engineering/" class="md-nav__link">
        Engineering
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../finance/" class="md-nav__link">
        Finance
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../io/" class="md-nav__link">
        Input/Output (io)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../ml/" class="md-nav__link">
        Machine Learning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../math/" class="md-nav__link">
        Math
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../timeseries/" class="md-nav__link">
        Timeseries
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../utils/" class="md-nav__link">
        Utils
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xarray/" class="md-nav__link">
        XArray
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../CHANGELOG/" class="md-nav__link">
        Changelog
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../AUTHORS/" class="md-nav__link">
        Authors
      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#janitor.functions" class="md-nav__link">
    janitor.functions
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions--general-functions" class="md-nav__link">
    General Functions
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.add_columns" class="md-nav__link">
    add_columns
  </a>
  
    <nav class="md-nav" aria-label="add_columns">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.add_columns.add_column" class="md-nav__link">
    add_column()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#janitor.functions.add_columns.add_columns" class="md-nav__link">
    add_columns()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.also" class="md-nav__link">
    also
  </a>
  
    <nav class="md-nav" aria-label="also">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.also.also" class="md-nav__link">
    also()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.bin_numeric" class="md-nav__link">
    bin_numeric
  </a>
  
    <nav class="md-nav" aria-label="bin_numeric">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.bin_numeric.bin_numeric" class="md-nav__link">
    bin_numeric()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.case_when" class="md-nav__link">
    case_when
  </a>
  
    <nav class="md-nav" aria-label="case_when">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.case_when.case_when" class="md-nav__link">
    case_when()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.change_type" class="md-nav__link">
    change_type
  </a>
  
    <nav class="md-nav" aria-label="change_type">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.change_type.change_type" class="md-nav__link">
    change_type()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.clean_names" class="md-nav__link">
    clean_names
  </a>
  
    <nav class="md-nav" aria-label="clean_names">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.clean_names.clean_names" class="md-nav__link">
    clean_names()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.coalesce" class="md-nav__link">
    coalesce
  </a>
  
    <nav class="md-nav" aria-label="coalesce">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.coalesce.coalesce" class="md-nav__link">
    coalesce()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.collapse_levels" class="md-nav__link">
    collapse_levels
  </a>
  
    <nav class="md-nav" aria-label="collapse_levels">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.collapse_levels.collapse_levels" class="md-nav__link">
    collapse_levels()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.complete" class="md-nav__link">
    complete
  </a>
  
    <nav class="md-nav" aria-label="complete">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.complete.complete" class="md-nav__link">
    complete()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.concatenate_columns" class="md-nav__link">
    concatenate_columns
  </a>
  
    <nav class="md-nav" aria-label="concatenate_columns">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.concatenate_columns.concatenate_columns" class="md-nav__link">
    concatenate_columns()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.conditional_join" class="md-nav__link">
    conditional_join
  </a>
  
    <nav class="md-nav" aria-label="conditional_join">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.conditional_join.conditional_join" class="md-nav__link">
    conditional_join()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.convert_date" class="md-nav__link">
    convert_date
  </a>
  
    <nav class="md-nav" aria-label="convert_date">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.convert_date.convert_excel_date" class="md-nav__link">
    convert_excel_date()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#janitor.functions.convert_date.convert_matlab_date" class="md-nav__link">
    convert_matlab_date()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#janitor.functions.convert_date.convert_unix_date" class="md-nav__link">
    convert_unix_date()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.count_cumulative_unique" class="md-nav__link">
    count_cumulative_unique
  </a>
  
    <nav class="md-nav" aria-label="count_cumulative_unique">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.count_cumulative_unique.count_cumulative_unique" class="md-nav__link">
    count_cumulative_unique()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.currency_column_to_numeric" class="md-nav__link">
    currency_column_to_numeric
  </a>
  
    <nav class="md-nav" aria-label="currency_column_to_numeric">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.currency_column_to_numeric.currency_column_to_numeric" class="md-nav__link">
    currency_column_to_numeric()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.deconcatenate_column" class="md-nav__link">
    deconcatenate_column
  </a>
  
    <nav class="md-nav" aria-label="deconcatenate_column">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.deconcatenate_column.deconcatenate_column" class="md-nav__link">
    deconcatenate_column()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.drop_constant_columns" class="md-nav__link">
    drop_constant_columns
  </a>
  
    <nav class="md-nav" aria-label="drop_constant_columns">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.drop_constant_columns.drop_constant_columns" class="md-nav__link">
    drop_constant_columns()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.drop_duplicate_columns" class="md-nav__link">
    drop_duplicate_columns
  </a>
  
    <nav class="md-nav" aria-label="drop_duplicate_columns">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.drop_duplicate_columns.drop_duplicate_columns" class="md-nav__link">
    drop_duplicate_columns()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.dropnotnull" class="md-nav__link">
    dropnotnull
  </a>
  
    <nav class="md-nav" aria-label="dropnotnull">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.dropnotnull.dropnotnull" class="md-nav__link">
    dropnotnull()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.encode_categorical" class="md-nav__link">
    encode_categorical
  </a>
  
    <nav class="md-nav" aria-label="encode_categorical">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.encode_categorical.encode_categorical" class="md-nav__link">
    encode_categorical()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.expand_column" class="md-nav__link">
    expand_column
  </a>
  
    <nav class="md-nav" aria-label="expand_column">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.expand_column.expand_column" class="md-nav__link">
    expand_column()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.expand_grid" class="md-nav__link">
    expand_grid
  </a>
  
    <nav class="md-nav" aria-label="expand_grid">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.expand_grid.expand_grid" class="md-nav__link">
    expand_grid()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.factorize_columns" class="md-nav__link">
    factorize_columns
  </a>
  
    <nav class="md-nav" aria-label="factorize_columns">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.factorize_columns.factorize_columns" class="md-nav__link">
    factorize_columns()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.fill" class="md-nav__link">
    fill
  </a>
  
    <nav class="md-nav" aria-label="fill">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.fill.fill_direction" class="md-nav__link">
    fill_direction()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#janitor.functions.fill.fill_empty" class="md-nav__link">
    fill_empty()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.filter" class="md-nav__link">
    filter
  </a>
  
    <nav class="md-nav" aria-label="filter">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.filter.filter_column_isin" class="md-nav__link">
    filter_column_isin()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#janitor.functions.filter.filter_date" class="md-nav__link">
    filter_date()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#janitor.functions.filter.filter_on" class="md-nav__link">
    filter_on()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#janitor.functions.filter.filter_string" class="md-nav__link">
    filter_string()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.find_replace" class="md-nav__link">
    find_replace
  </a>
  
    <nav class="md-nav" aria-label="find_replace">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.find_replace.find_replace" class="md-nav__link">
    find_replace()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.flag_nulls" class="md-nav__link">
    flag_nulls
  </a>
  
    <nav class="md-nav" aria-label="flag_nulls">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.flag_nulls.flag_nulls" class="md-nav__link">
    flag_nulls()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.get_dupes" class="md-nav__link">
    get_dupes
  </a>
  
    <nav class="md-nav" aria-label="get_dupes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.get_dupes.get_dupes" class="md-nav__link">
    get_dupes()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.groupby_agg" class="md-nav__link">
    groupby_agg
  </a>
  
    <nav class="md-nav" aria-label="groupby_agg">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.groupby_agg.groupby_agg" class="md-nav__link">
    groupby_agg()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.groupby_topk" class="md-nav__link">
    groupby_topk
  </a>
  
    <nav class="md-nav" aria-label="groupby_topk">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.groupby_topk.groupby_topk" class="md-nav__link">
    groupby_topk()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.impute" class="md-nav__link">
    impute
  </a>
  
    <nav class="md-nav" aria-label="impute">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.impute.impute" class="md-nav__link">
    impute()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.jitter" class="md-nav__link">
    jitter
  </a>
  
    <nav class="md-nav" aria-label="jitter">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.jitter.jitter" class="md-nav__link">
    jitter()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.join_apply" class="md-nav__link">
    join_apply
  </a>
  
    <nav class="md-nav" aria-label="join_apply">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.join_apply.join_apply" class="md-nav__link">
    join_apply()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.label_encode" class="md-nav__link">
    label_encode
  </a>
  
    <nav class="md-nav" aria-label="label_encode">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.label_encode.label_encode" class="md-nav__link">
    label_encode()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.limit_column_characters" class="md-nav__link">
    limit_column_characters
  </a>
  
    <nav class="md-nav" aria-label="limit_column_characters">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.limit_column_characters.limit_column_characters" class="md-nav__link">
    limit_column_characters()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.min_max_scale" class="md-nav__link">
    min_max_scale
  </a>
  
    <nav class="md-nav" aria-label="min_max_scale">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.min_max_scale.min_max_scale" class="md-nav__link">
    min_max_scale()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.move" class="md-nav__link">
    move
  </a>
  
    <nav class="md-nav" aria-label="move">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.move.move" class="md-nav__link">
    move()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.pivot" class="md-nav__link">
    pivot
  </a>
  
    <nav class="md-nav" aria-label="pivot">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.pivot.pivot_longer" class="md-nav__link">
    pivot_longer()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#janitor.functions.pivot.pivot_wider" class="md-nav__link">
    pivot_wider()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.process_text" class="md-nav__link">
    process_text
  </a>
  
    <nav class="md-nav" aria-label="process_text">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.process_text.process_text" class="md-nav__link">
    process_text()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.remove_columns" class="md-nav__link">
    remove_columns
  </a>
  
    <nav class="md-nav" aria-label="remove_columns">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.remove_columns.remove_columns" class="md-nav__link">
    remove_columns()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.remove_empty" class="md-nav__link">
    remove_empty
  </a>
  
    <nav class="md-nav" aria-label="remove_empty">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.remove_empty.remove_empty" class="md-nav__link">
    remove_empty()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.rename_columns" class="md-nav__link">
    rename_columns
  </a>
  
    <nav class="md-nav" aria-label="rename_columns">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.rename_columns.rename_column" class="md-nav__link">
    rename_column()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#janitor.functions.rename_columns.rename_columns" class="md-nav__link">
    rename_columns()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.reorder_columns" class="md-nav__link">
    reorder_columns
  </a>
  
    <nav class="md-nav" aria-label="reorder_columns">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.reorder_columns.reorder_columns" class="md-nav__link">
    reorder_columns()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.round_to_fraction" class="md-nav__link">
    round_to_fraction
  </a>
  
    <nav class="md-nav" aria-label="round_to_fraction">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.round_to_fraction.round_to_fraction" class="md-nav__link">
    round_to_fraction()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.row_to_names" class="md-nav__link">
    row_to_names
  </a>
  
    <nav class="md-nav" aria-label="row_to_names">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.row_to_names.row_to_names" class="md-nav__link">
    row_to_names()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.select" class="md-nav__link">
    select
  </a>
  
    <nav class="md-nav" aria-label="select">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.select.select" class="md-nav__link">
    select()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#janitor.functions.select.select_columns" class="md-nav__link">
    select_columns()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#janitor.functions.select.select_rows" class="md-nav__link">
    select_rows()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.shuffle" class="md-nav__link">
    shuffle
  </a>
  
    <nav class="md-nav" aria-label="shuffle">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.shuffle.shuffle" class="md-nav__link">
    shuffle()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.sort_column_value_order" class="md-nav__link">
    sort_column_value_order
  </a>
  
    <nav class="md-nav" aria-label="sort_column_value_order">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.sort_column_value_order.sort_column_value_order" class="md-nav__link">
    sort_column_value_order()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.sort_naturally" class="md-nav__link">
    sort_naturally
  </a>
  
    <nav class="md-nav" aria-label="sort_naturally">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.sort_naturally.sort_naturally" class="md-nav__link">
    sort_naturally()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.take_first" class="md-nav__link">
    take_first
  </a>
  
    <nav class="md-nav" aria-label="take_first">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.take_first.take_first" class="md-nav__link">
    take_first()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.then" class="md-nav__link">
    then
  </a>
  
    <nav class="md-nav" aria-label="then">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.then.then" class="md-nav__link">
    then()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.to_datetime" class="md-nav__link">
    to_datetime
  </a>
  
    <nav class="md-nav" aria-label="to_datetime">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.to_datetime.to_datetime" class="md-nav__link">
    to_datetime()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.toset" class="md-nav__link">
    toset
  </a>
  
    <nav class="md-nav" aria-label="toset">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.toset.toset" class="md-nav__link">
    toset()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.transform_columns" class="md-nav__link">
    transform_columns
  </a>
  
    <nav class="md-nav" aria-label="transform_columns">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.transform_columns.transform_column" class="md-nav__link">
    transform_column()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#janitor.functions.transform_columns.transform_columns" class="md-nav__link">
    transform_columns()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.truncate_datetime" class="md-nav__link">
    truncate_datetime
  </a>
  
    <nav class="md-nav" aria-label="truncate_datetime">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.truncate_datetime.truncate_datetime_dataframe" class="md-nav__link">
    truncate_datetime_dataframe()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.update_where" class="md-nav__link">
    update_where
  </a>
  
    <nav class="md-nav" aria-label="update_where">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.update_where.update_where" class="md-nav__link">
    update_where()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#janitor.functions.utils" class="md-nav__link">
    utils
  </a>
  
    <nav class="md-nav" aria-label="utils">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#janitor.functions.utils.DropLabel" class="md-nav__link">
    DropLabel
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#janitor.functions.utils.patterns" class="md-nav__link">
    patterns()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#janitor.functions.utils.unionize_dataframe_categories" class="md-nav__link">
    unionize_dataframe_categories()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  <a href="https://github.com/pyjanitor-devs/pyjanitor/edit/master/docs/api/functions.md" title="Edit this page" class="md-content__button md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25Z"/></svg>
  </a>


<h1 id="functions">Functions</h1>


  <div class="doc doc-object doc-module">

<a id="janitor.functions"></a>
    <div class="doc doc-contents first">

      <h2 id="janitor.functions--general-functions">General Functions</h2>
<p>pyjanitor's general-purpose data cleaning functions.</p>
<p>NOTE: Instructions for future contributors:</p>
<ol>
<li>Place the source code of the functions in a file named after the function.</li>
<li>Place utility functions in the same file.</li>
<li>If you use a utility function from another source file,
please refactor it out to <code>janitor.functions.utils</code>.</li>
<li>Import the function into this file so that it shows up in the top-level API.</li>
<li>Sort the imports in alphabetical order.</li>
<li>Try to group related functions together (e.g. see <code>convert_date.py</code>)</li>
<li>Never import utils.</li>
</ol>



  <div class="doc doc-children">










  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.add_columns" class="doc doc-heading">
        <code>add_columns</code>



</h2>

    <div class="doc doc-contents ">




  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.add_columns.add_column" class="doc doc-heading">
<code class="highlight language-python">add_column(df, column_name, value, fill_remaining=False)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Add a column to the dataframe.</p>
<p>Intended to be the method-chaining alternative to:</p>
<pre><code class="language-python">df[column_name] = value
</code></pre>
<p>Example: Add a column of constant values to the dataframe.</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({"a": list(range(3)), "b": list("abc")})
&gt;&gt;&gt; df.add_column(column_name="c", value=1)
   a  b  c
0  0  a  1
1  1  b  1
2  2  c  1
</code></pre>
<p>Example: Add a column of different values to the dataframe.</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({"a": list(range(3)), "b": list("abc")})
&gt;&gt;&gt; df.add_column(column_name="c", value=list("efg"))
   a  b  c
0  0  a  e
1  1  b  f
2  2  c  g
</code></pre>
<p>Example: Add a column using an iterator.</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({"a": list(range(3)), "b": list("abc")})
&gt;&gt;&gt; df.add_column(column_name="c", value=range(4, 7))
   a  b  c
0  0  a  4
1  1  b  5
2  2  c  6


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A pandas DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>column_name</code></td>
        <td><code>str</code></td>
        <td><p>Name of the new column. Should be a string, in order for the column name to be compatible with the Feather binary format (this is a useful thing to have).</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>value</code></td>
        <td><code>Union[List[Any], Tuple[Any], Any]</code></td>
        <td><p>Either a single value, or a list/tuple of values.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>fill_remaining</code></td>
        <td><code>bool</code></td>
        <td><p>If value is a tuple or list that is smaller than the number of rows in the DataFrame, repeat the list or tuple (R-style) to the end of the DataFrame.</p></td>
        <td><code>False</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame with an added column.</p></td>
    </tr>
  </tbody>
</table>
<p><strong>Exceptions:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>ValueError</code></td>
        <td><p>If attempting to add a column that already exists.</p></td>
      </tr>
      <tr>
        <td><code>ValueError</code></td>
        <td><p>If <code>value</code> has more elements that number of rows in the DataFrame.</p></td>
      </tr>
      <tr>
        <td><code>ValueError</code></td>
        <td><p>If attempting to add an iterable of values with a length not equal to the number of DataFrame rows.</p></td>
      </tr>
      <tr>
        <td><code>ValueError</code></td>
        <td><p>If <code>value</code> has length of <code>0</code>.</p></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/add_columns.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
@deprecated_alias(col_name="column_name")
def add_column(
    df: pd.DataFrame,
    column_name: str,
    value: Union[List[Any], Tuple[Any], Any],
    fill_remaining: bool = False,
) -&gt; pd.DataFrame:
    """Add a column to the dataframe.

    Intended to be the method-chaining alternative to:

    ```python
    df[column_name] = value
    ```

    Example: Add a column of constant values to the dataframe.

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({"a": list(range(3)), "b": list("abc")})
        &gt;&gt;&gt; df.add_column(column_name="c", value=1)
           a  b  c
        0  0  a  1
        1  1  b  1
        2  2  c  1

    Example: Add a column of different values to the dataframe.

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({"a": list(range(3)), "b": list("abc")})
        &gt;&gt;&gt; df.add_column(column_name="c", value=list("efg"))
           a  b  c
        0  0  a  e
        1  1  b  f
        2  2  c  g

    Example: Add a column using an iterator.

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({"a": list(range(3)), "b": list("abc")})
        &gt;&gt;&gt; df.add_column(column_name="c", value=range(4, 7))
           a  b  c
        0  0  a  4
        1  1  b  5
        2  2  c  6

    :param df: A pandas DataFrame.
    :param column_name: Name of the new column. Should be a string, in order
        for the column name to be compatible with the Feather binary
        format (this is a useful thing to have).
    :param value: Either a single value, or a list/tuple of values.
    :param fill_remaining: If value is a tuple or list that is smaller than
        the number of rows in the DataFrame, repeat the list or tuple
        (R-style) to the end of the DataFrame.
    :returns: A pandas DataFrame with an added column.
    :raises ValueError: If attempting to add a column that already exists.
    :raises ValueError: If `value` has more elements that number of
        rows in the DataFrame.
    :raises ValueError: If attempting to add an iterable of values with
        a length not equal to the number of DataFrame rows.
    :raises ValueError: If `value` has length of `0`.
    """
    check("column_name", column_name, [str])

    if column_name in df.columns:
        raise ValueError(
            f"Attempted to add column that already exists: " f"{column_name}."
        )

    nrows = len(df)

    if hasattr(value, "__len__") and not isinstance(
        value, (str, bytes, bytearray)
    ):
        len_value = len(value)

        # if `value` is a list, ndarray, etc.
        if len_value &gt; nrows:
            raise ValueError(
                "`value` has more elements than number of rows "
                f"in your `DataFrame`. vals: {len_value}, "
                f"df: {nrows}"
            )
        if len_value != nrows and not fill_remaining:
            raise ValueError(
                "Attempted to add iterable of values with length"
                " not equal to number of DataFrame rows"
            )
        if not len_value:
            raise ValueError(
                "`value` has to be an iterable of minimum length 1"
            )

    elif fill_remaining:
        # relevant if a scalar val was passed, yet fill_remaining == True
        len_value = 1
        value = [value]

    df = df.copy()
    if fill_remaining:
        times_to_loop = int(np.ceil(nrows / len_value))
        fill_values = list(value) * times_to_loop
        df[column_name] = fill_values[:nrows]
    else:
        df[column_name] = value

    return df
</code></pre>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.add_columns.add_columns" class="doc doc-heading">
<code class="highlight language-python">add_columns(df, fill_remaining=False, **kwargs)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Add multiple columns to the dataframe.</p>
<p>This method does not mutate the original DataFrame.</p>
<p>Method to augment
<a class="autorefs autorefs-internal" href="#janitor.functions.add_columns.add_column"><code>add_column</code></a>
with ability to add multiple columns in
one go. This replaces the need for multiple
<a class="autorefs autorefs-internal" href="#janitor.functions.add_columns.add_column"><code>add_column</code></a> calls.</p>
<p>Usage is through supplying kwargs where the key is the col name and the
values correspond to the values of the new DataFrame column.</p>
<p>Values passed can be scalar or iterable (list, ndarray, etc.)</p>
<p>Example: Inserting two more columns into a dataframe.</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({"a": list(range(3)), "b": list("abc")})
&gt;&gt;&gt; df.add_columns(x=4, y=list("def"))
   a  b  x  y
0  0  a  4  d
1  1  b  4  e
2  2  c  4  f


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A pandas dataframe.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>fill_remaining</code></td>
        <td><code>bool</code></td>
        <td><p>If value is a tuple or list that is smaller than the number of rows in the DataFrame, repeat the list or tuple (R-style) to the end of the DataFrame. (Passed to <code>add_column</code>)</p></td>
        <td><code>False</code></td>
      </tr>
      <tr>
        <td><code>**kwargs</code></td>
        <td></td>
        <td><p>Column, value pairs which are looped through in <code>add_column</code> calls.</p></td>
        <td><code>{}</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame with added columns.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/add_columns.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
def add_columns(
    df: pd.DataFrame,
    fill_remaining: bool = False,
    **kwargs,
) -&gt; pd.DataFrame:
    """Add multiple columns to the dataframe.

    This method does not mutate the original DataFrame.

    Method to augment
    [`add_column`][janitor.functions.add_columns.add_column]
    with ability to add multiple columns in
    one go. This replaces the need for multiple
    [`add_column`][janitor.functions.add_columns.add_column] calls.

    Usage is through supplying kwargs where the key is the col name and the
    values correspond to the values of the new DataFrame column.

    Values passed can be scalar or iterable (list, ndarray, etc.)

    Example: Inserting two more columns into a dataframe.

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({"a": list(range(3)), "b": list("abc")})
        &gt;&gt;&gt; df.add_columns(x=4, y=list("def"))
           a  b  x  y
        0  0  a  4  d
        1  1  b  4  e
        2  2  c  4  f

    :param df: A pandas dataframe.
    :param fill_remaining: If value is a tuple or list that is smaller than
        the number of rows in the DataFrame, repeat the list or tuple
        (R-style) to the end of the DataFrame. (Passed to `add_column`)
    :param **kwargs: Column, value pairs which are looped through in
        `add_column` calls.
    :returns: A pandas DataFrame with added columns.
    """
    # Note: error checking can pretty much be handled in `add_column`

    for col_name, values in kwargs.items():
        df = df.add_column(col_name, values, fill_remaining=fill_remaining)

    return df
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.also" class="doc doc-heading">
        <code>also</code>



</h2>

    <div class="doc doc-contents ">

      <p>Implementation source for chainable function <code>also</code>.</p>



  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.also.also" class="doc doc-heading">
<code class="highlight language-python">also(df, func, *args, **kwargs)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Run a function with side effects.</p>
<p>This function allows you to run an arbitrary function
in the <code>pyjanitor</code> method chain.
Doing so will let you do things like save the dataframe to disk midway
while continuing to modify the dataframe afterwards.</p>
<p>Example:</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = (
...     pd.DataFrame({"a": [1, 2, 3], "b": list("abc")})
...     .query("a &gt; 1")
...     .also(lambda df: print(f"DataFrame shape is: {df.shape}"))
...     .rename_column(old_column_name="a", new_column_name="a_new")
...     .also(lambda df: df.to_csv("midpoint.csv"))
...     .also(
...         lambda df: print(f"Columns: {df.columns}")
...     )
... )
DataFrame shape is: (2, 2)
Columns: Index(['a_new', 'b'], dtype='object')


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A pandas DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>func</code></td>
        <td><code>Callable</code></td>
        <td><p>A function you would like to run in the method chain. It should take one DataFrame object as a parameter and have no return. If there is a return, it will be ignored.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>args</code></td>
        <td></td>
        <td><p>Optional arguments for <code>func</code>.</p></td>
        <td><code>()</code></td>
      </tr>
      <tr>
        <td><code>kwargs</code></td>
        <td></td>
        <td><p>Optional keyword arguments for <code>func</code>.</p></td>
        <td><code>{}</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>The input pandas DataFrame, unmodified.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/also.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
def also(df: pd.DataFrame, func: Callable, *args, **kwargs) -&gt; pd.DataFrame:
    """Run a function with side effects.

    This function allows you to run an arbitrary function
    in the `pyjanitor` method chain.
    Doing so will let you do things like save the dataframe to disk midway
    while continuing to modify the dataframe afterwards.

    Example:

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = (
        ...     pd.DataFrame({"a": [1, 2, 3], "b": list("abc")})
        ...     .query("a &gt; 1")
        ...     .also(lambda df: print(f"DataFrame shape is: {df.shape}"))
        ...     .rename_column(old_column_name="a", new_column_name="a_new")
        ...     .also(lambda df: df.to_csv("midpoint.csv"))
        ...     .also(
        ...         lambda df: print(f"Columns: {df.columns}")
        ...     )
        ... )
        DataFrame shape is: (2, 2)
        Columns: Index(['a_new', 'b'], dtype='object')

    :param df: A pandas DataFrame.
    :param func: A function you would like to run in the method chain.
        It should take one DataFrame object as a parameter and have no return.
        If there is a return, it will be ignored.
    :param args: Optional arguments for `func`.
    :param kwargs: Optional keyword arguments for `func`.
    :returns: The input pandas DataFrame, unmodified.
    """  # noqa: E501
    func(df.copy(), *args, **kwargs)
    return df
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.bin_numeric" class="doc doc-heading">
        <code>bin_numeric</code>



</h2>

    <div class="doc doc-contents ">




  <div class="doc doc-children">









  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.bin_numeric.bin_numeric" class="doc doc-heading">
<code class="highlight language-python">bin_numeric(df, from_column_name, to_column_name, bins=5, **kwargs)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Generate a new column that labels bins for a specified numeric column.</p>
<p>This method does not mutate the original DataFrame.</p>
<p>A wrapper around the pandas <a href="https://pandas.pydata.org/docs/reference/api/pandas.cut.html"><code>cut()</code></a> function to bin data of
one column, generating a new column with the results.</p>
<p>Example: Binning a numeric column with specific bin edges.</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({"a": [3, 6, 9, 12, 15]})
&gt;&gt;&gt; df.bin_numeric(
...     from_column_name="a", to_column_name="a_binned",
...     bins=[0, 5, 11, 15],
... )
    a  a_binned
0   3    (0, 5]
1   6   (5, 11]
2   9   (5, 11]
3  12  (11, 15]
4  15  (11, 15]


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A pandas DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>from_column_name</code></td>
        <td><code>str</code></td>
        <td><p>The column whose data you want binned.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>to_column_name</code></td>
        <td><code>str</code></td>
        <td><p>The new column to be created with the binned data.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>bins</code></td>
        <td><code>Union[int, Sequence[float], pandas.core.indexes.interval.IntervalIndex]</code></td>
        <td><p>The binning strategy to be utilized. Read the <code>pd.cut</code> documentation for more details.</p></td>
        <td><code>5</code></td>
      </tr>
      <tr>
        <td><code>**kwargs</code></td>
        <td></td>
        <td><p>Additional kwargs to pass to <code>pd.cut</code>, except <code>retbins</code>.</p></td>
        <td><code>{}</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame.</p></td>
    </tr>
  </tbody>
</table>
<p><strong>Exceptions:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>ValueError</code></td>
        <td><p>If <code>retbins</code> is passed in as a kwarg.</p></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/bin_numeric.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
@deprecated_alias(
    from_column="from_column_name",
    to_column="to_column_name",
    num_bins="bins",
)
def bin_numeric(
    df: pd.DataFrame,
    from_column_name: str,
    to_column_name: str,
    bins: Optional[Union[int, ScalarSequence, pd.IntervalIndex]] = 5,
    **kwargs,
) -&gt; pd.DataFrame:
    """
    Generate a new column that labels bins for a specified numeric column.

    This method does not mutate the original DataFrame.

    A wrapper around the pandas [`cut()`][pd_cut_docs] function to bin data of
    one column, generating a new column with the results.

    [pd_cut_docs]: https://pandas.pydata.org/docs/reference/api/pandas.cut.html

    Example: Binning a numeric column with specific bin edges.

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({"a": [3, 6, 9, 12, 15]})
        &gt;&gt;&gt; df.bin_numeric(
        ...     from_column_name="a", to_column_name="a_binned",
        ...     bins=[0, 5, 11, 15],
        ... )
            a  a_binned
        0   3    (0, 5]
        1   6   (5, 11]
        2   9   (5, 11]
        3  12  (11, 15]
        4  15  (11, 15]

    :param df: A pandas DataFrame.
    :param from_column_name: The column whose data you want binned.
    :param to_column_name: The new column to be created with the binned data.
    :param bins: The binning strategy to be utilized. Read the `pd.cut`
        documentation for more details.
    :param **kwargs: Additional kwargs to pass to `pd.cut`, except `retbins`.
    :return: A pandas DataFrame.
    :raises ValueError: If `retbins` is passed in as a kwarg.
    """
    if "retbins" in kwargs:
        raise ValueError("`retbins` is not an acceptable keyword argument.")

    check("from_column_name", from_column_name, [str])
    check("to_column_name", to_column_name, [str])
    check_column(df, from_column_name)

    df = df.assign(
        **{
            to_column_name: pd.cut(df[from_column_name], bins=bins, **kwargs),
        }
    )

    return df
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.case_when" class="doc doc-heading">
        <code>case_when</code>



</h2>

    <div class="doc doc-contents ">




  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.case_when.case_when" class="doc doc-heading">
<code class="highlight language-python">case_when(df, *args, *, default=None, column_name)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Create a column based on a condition or multiple conditions.</p>
<p>Example usage:</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame(
...     {
...         "a": [0, 0, 1, 2, "hi"],
...         "b": [0, 3, 4, 5, "bye"],
...         "c": [6, 7, 8, 9, "wait"],
...     }
... )
&gt;&gt;&gt; df
    a    b     c
0   0    0     6
1   0    3     7
2   1    4     8
3   2    5     9
4  hi  bye  wait
&gt;&gt;&gt; df.case_when(
...     ((df.a == 0) &amp; (df.b != 0)) | (df.c == "wait"), df.a,
...     (df.b == 0) &amp; (df.a == 0), "x",
...     default = df.c,
...     column_name = "value",
... )
    a    b     c value
0   0    0     6     x
1   0    3     7     0
2   1    4     8     8
3   2    5     9     9
4  hi  bye  wait    hi
</code></pre>
<p>Similar to SQL and dplyr's case_when
with inspiration from <code>pydatatable</code> if_else function.</p>
<p>If your scenario requires direct replacement of values,
pandas' <code>replace</code> method or <code>map</code> method should be better
suited and more efficient; if the conditions check
if a value is within a range of values, pandas' <code>cut</code> or <code>qcut</code>
should be more efficient; <code>np.where/np.select</code> are also
performant options.</p>
<p>This function relies on <code>pd.Series.mask</code> method.</p>
<p>When multiple conditions are satisfied, the first one is used.</p>
<p>The variable <code>*args</code> parameters takes arguments of the form :
<code>condition0</code>, <code>value0</code>, <code>condition1</code>, <code>value1</code>, ..., <code>default</code>.
If <code>condition0</code> evaluates to <code>True</code>, then assign <code>value0</code> to
<code>column_name</code>, if <code>condition1</code> evaluates to <code>True</code>, then
assign <code>value1</code> to <code>column_name</code>, and so on. If none of the
conditions evaluate to <code>True</code>, assign <code>default</code> to
<code>column_name</code>.</p>
<p>This function can be likened to SQL's <code>case_when</code>:</p>
<pre><code class="language-sql">CASE WHEN condition0 THEN value0
    WHEN condition1 THEN value1
    --- more conditions
    ELSE default
    END AS column_name
</code></pre>
<p>compared to python's <code>if-elif-else</code>:</p>
<pre><code class="language-python">if condition0:
    value0
elif condition1:
    value1
# more elifs
else:
    default
</code></pre>
<div class="admonition abstract">
<p class="admonition-title">Version Changed</p>
<ul>
<li>0.24.0<ul>
<li>Added <code>default</code> parameter.</li>
</ul>
</li>
</ul>
</div>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A pandas DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>args</code></td>
        <td></td>
        <td><p>Variable argument of conditions and expected values. Takes the form <code>condition0</code>, <code>value0</code>, <code>condition1</code>, <code>value1</code>, ... . <code>condition</code> can be a 1-D boolean array, a callable, or a string. If <code>condition</code> is a callable, it should evaluate to a 1-D boolean array. The array should have the same length as the DataFrame. If it is a string, it is computed on the dataframe, via <code>df.eval</code>, and should return a 1-D boolean array. <code>result</code> can be a scalar, a 1-D array, or a callable. If <code>result</code> is a callable, it should evaluate to a 1-D array. For a 1-D array, it should have the same length as the DataFrame.</p></td>
        <td><code>()</code></td>
      </tr>
      <tr>
        <td><code>default</code></td>
        <td><code>Any</code></td>
        <td><p>scalar, 1-D array or callable. This is the element inserted in the output when all conditions evaluate to False. If callable, it should evaluate to a 1-D array. The 1-D array should be the same length as the DataFrame.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>column_name</code></td>
        <td><code>str</code></td>
        <td><p>Name of column to assign results to. A new column is created, if it does not already exist in the DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame.</p></td>
    </tr>
  </tbody>
</table>
<p><strong>Exceptions:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>ValueError</code></td>
        <td><p>if condition/value fails to evaluate.</p></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/case_when.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
def case_when(
    df: pd.DataFrame, *args, default: Any = None, column_name: str
) -&gt; pd.DataFrame:
    """
    Create a column based on a condition or multiple conditions.

    Example usage:

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame(
        ...     {
        ...         "a": [0, 0, 1, 2, "hi"],
        ...         "b": [0, 3, 4, 5, "bye"],
        ...         "c": [6, 7, 8, 9, "wait"],
        ...     }
        ... )
        &gt;&gt;&gt; df
            a    b     c
        0   0    0     6
        1   0    3     7
        2   1    4     8
        3   2    5     9
        4  hi  bye  wait
        &gt;&gt;&gt; df.case_when(
        ...     ((df.a == 0) &amp; (df.b != 0)) | (df.c == "wait"), df.a,
        ...     (df.b == 0) &amp; (df.a == 0), "x",
        ...     default = df.c,
        ...     column_name = "value",
        ... )
            a    b     c value
        0   0    0     6     x
        1   0    3     7     0
        2   1    4     8     8
        3   2    5     9     9
        4  hi  bye  wait    hi

    Similar to SQL and dplyr's case_when
    with inspiration from `pydatatable` if_else function.

    If your scenario requires direct replacement of values,
    pandas' `replace` method or `map` method should be better
    suited and more efficient; if the conditions check
    if a value is within a range of values, pandas' `cut` or `qcut`
    should be more efficient; `np.where/np.select` are also
    performant options.

    This function relies on `pd.Series.mask` method.

    When multiple conditions are satisfied, the first one is used.

    The variable `*args` parameters takes arguments of the form :
    `condition0`, `value0`, `condition1`, `value1`, ..., `default`.
    If `condition0` evaluates to `True`, then assign `value0` to
    `column_name`, if `condition1` evaluates to `True`, then
    assign `value1` to `column_name`, and so on. If none of the
    conditions evaluate to `True`, assign `default` to
    `column_name`.

    This function can be likened to SQL's `case_when`:

    ```sql
    CASE WHEN condition0 THEN value0
        WHEN condition1 THEN value1
        --- more conditions
        ELSE default
        END AS column_name
    ```

    compared to python's `if-elif-else`:

    ```python
    if condition0:
        value0
    elif condition1:
        value1
    # more elifs
    else:
        default
    ```
    !!! abstract "Version Changed"

        - 0.24.0
            - Added `default` parameter.


    :param df: A pandas DataFrame.
    :param args: Variable argument of conditions and expected values.
        Takes the form
        `condition0`, `value0`, `condition1`, `value1`, ... .
        `condition` can be a 1-D boolean array, a callable, or a string.
        If `condition` is a callable, it should evaluate
        to a 1-D boolean array. The array should have the same length
        as the DataFrame. If it is a string, it is computed on the dataframe,
        via `df.eval`, and should return a 1-D boolean array.
        `result` can be a scalar, a 1-D array, or a callable.
        If `result` is a callable, it should evaluate to a 1-D array.
        For a 1-D array, it should have the same length as the DataFrame.
    :param default: scalar, 1-D array or callable.
        This is the element inserted in the output
        when all conditions evaluate to False.
        If callable, it should evaluate to a 1-D array.
        The 1-D array should be the same length as the DataFrame.

    :param column_name: Name of column to assign results to. A new column
        is created, if it does not already exist in the DataFrame.
    :raises ValueError: if condition/value fails to evaluate.
    :returns: A pandas DataFrame.
    """
    # Preliminary checks on the case_when function.
    # The bare minimum checks are done; the remaining checks
    # are done within `pd.Series.mask`.
    check("column_name", column_name, [str])
    len_args = len(args)
    if len_args &lt; 2:
        raise ValueError(
            "At least two arguments are required for the `args` parameter"
        )

    if len_args % 2:
        if default is None:
            warnings.warn(
                "The last argument in the variable arguments "
                "has been assigned as the default. "
                "Note however that this will be deprecated "
                "in a future release; use an even number "
                "of boolean conditions and values, "
                "and pass the default argument to the `default` "
                "parameter instead.",
                DeprecationWarning,
                stacklevel=2,
            )
            *args, default = args
        else:
            raise ValueError(
                "The number of conditions and values do not match. "
                f"There are {len_args - len_args//2} conditions "
                f"and {len_args//2} values."
            )

    booleans = []
    replacements = []

    for index, value in enumerate(args):
        if index % 2:
            if callable(value):
                value = apply_if_callable(value, df)
            replacements.append(value)
        else:
            if callable(value):
                value = apply_if_callable(value, df)
            elif isinstance(value, str):
                value = df.eval(value)
            booleans.append(value)

    if callable(default):
        default = apply_if_callable(default, df)
    if is_scalar(default):
        default = pd.Series([default]).repeat(len(df))
    if not hasattr(default, "shape"):
        default = pd.Series([*default])
    if isinstance(default, pd.Index):
        arr_ndim = default.nlevels
    else:
        arr_ndim = default.ndim
    if arr_ndim != 1:
        raise ValueError(
            "The argument for the `default` parameter "
            "should either be a 1-D array, a scalar, "
            "or a callable that can evaluate to a 1-D array."
        )
    if not isinstance(default, pd.Series):
        default = pd.Series(default)
    default.index = df.index
    # actual computation
    # ensures value assignment is on a first come basis
    booleans = booleans[::-1]
    replacements = replacements[::-1]
    for index, (condition, value) in enumerate(zip(booleans, replacements)):
        try:
            default = default.mask(condition, value)
        # error `feedoff` idea from SO
        # https://stackoverflow.com/a/46091127/7175713
        except Exception as error:
            raise ValueError(
                f"condition{index} and value{index} failed to evaluate. "
                f"Original error message: {error}"
            ) from error

    return df.assign(**{column_name: default})
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.change_type" class="doc doc-heading">
        <code>change_type</code>



</h2>

    <div class="doc doc-contents ">




  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.change_type.change_type" class="doc doc-heading">
<code class="highlight language-python">change_type(df, column_name, dtype, ignore_exception=False)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Change the type of a column.</p>
<p>This method does not mutate the original DataFrame.</p>
<p>Exceptions that are raised can be ignored. For example, if one has a mixed
dtype column that has non-integer strings and integers, and you want to
coerce everything to integers, you can optionally ignore the non-integer
strings and replace them with <code>NaN</code> or keep the original value.</p>
<p>Intended to be the method-chaining alternative to:</p>
<pre><code class="language-python">df[col] = df[col].astype(dtype)
</code></pre>
<p>Example: Change the type of a column.</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({"col1": range(3), "col2": ["m", 5, True]})
&gt;&gt;&gt; df
   col1  col2
0     0     m
1     1     5
2     2  True
&gt;&gt;&gt; df.change_type(
...     "col1", dtype=str,
... ).change_type(
...     "col2", dtype=float, ignore_exception="fillna",
... )
  col1  col2
0    0   NaN
1    1   5.0
2    2   1.0
</code></pre>
<p>Example: Change the type of multiple columns.</p>
<p>Change the type of all columns, please use <code>DataFrame.astype</code> instead.</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({"col1": range(3), "col2": ["m", 5, True]})
&gt;&gt;&gt; df.change_type(['col1', 'col2'], str)
  col1  col2
0    0     m
1    1     5
2    2  True


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>pd.DataFrame</code></td>
        <td><p>A pandas DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>column_name</code></td>
        <td><code>Hashable | list[Hashable] | pd.Index</code></td>
        <td><p>The column(s) in the dataframe.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>dtype</code></td>
        <td><code>type</code></td>
        <td><p>The datatype to convert to. Should be one of the standard Python types, or a numpy datatype.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>ignore_exception</code></td>
        <td><code>bool</code></td>
        <td><p>one of <code>{False, "fillna", "keep_values"}</code>.</p></td>
        <td><code>False</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>pd.DataFrame</code></td>
      <td><p>A pandas DataFrame with changed column types.</p></td>
    </tr>
  </tbody>
</table>
<p><strong>Exceptions:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>ValueError</code></td>
        <td><p>If unknown option provided for <code>ignore_exception</code>.</p></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/change_type.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
@deprecated_alias(column="column_name")
def change_type(
    df: pd.DataFrame,
    column_name: Hashable | list[Hashable] | pd.Index,
    dtype: type,
    ignore_exception: bool = False,
) -&gt; pd.DataFrame:
    """Change the type of a column.

    This method does not mutate the original DataFrame.

    Exceptions that are raised can be ignored. For example, if one has a mixed
    dtype column that has non-integer strings and integers, and you want to
    coerce everything to integers, you can optionally ignore the non-integer
    strings and replace them with `NaN` or keep the original value.

    Intended to be the method-chaining alternative to:

    ```python
    df[col] = df[col].astype(dtype)
    ```

    Example: Change the type of a column.

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({"col1": range(3), "col2": ["m", 5, True]})
        &gt;&gt;&gt; df
           col1  col2
        0     0     m
        1     1     5
        2     2  True
        &gt;&gt;&gt; df.change_type(
        ...     "col1", dtype=str,
        ... ).change_type(
        ...     "col2", dtype=float, ignore_exception="fillna",
        ... )
          col1  col2
        0    0   NaN
        1    1   5.0
        2    2   1.0

    Example: Change the type of multiple columns.

    Change the type of all columns, please use `DataFrame.astype` instead.

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({"col1": range(3), "col2": ["m", 5, True]})
        &gt;&gt;&gt; df.change_type(['col1', 'col2'], str)
          col1  col2
        0    0     m
        1    1     5
        2    2  True

    :param df: A pandas DataFrame.
    :param column_name: The column(s) in the dataframe.
    :param dtype: The datatype to convert to. Should be one of the standard
        Python types, or a numpy datatype.
    :param ignore_exception: one of `{False, "fillna", "keep_values"}`.
    :returns: A pandas DataFrame with changed column types.
    :raises ValueError: If unknown option provided for
        `ignore_exception`.
    """

    df = df.copy()  # avoid mutating the original DataFrame
    if not ignore_exception:
        df[column_name] = df[column_name].astype(dtype)
    elif ignore_exception == "keep_values":
        df[column_name] = df[column_name].astype(dtype, errors="ignore")
    elif ignore_exception == "fillna":
        if isinstance(column_name, Hashable):
            column_name = [column_name]
        df[column_name] = df[column_name].applymap(_convert, dtype=dtype)
    else:
        raise ValueError("Unknown option for ignore_exception")

    return df
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.clean_names" class="doc doc-heading">
        <code>clean_names</code>



</h2>

    <div class="doc doc-contents ">

      <p>Functions for cleaning columns names.</p>



  <div class="doc doc-children">









  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.clean_names.clean_names" class="doc doc-heading">
<code class="highlight language-python">clean_names(df, strip_underscores=None, case_type='lower', remove_special=False, strip_accents=True, preserve_original_columns=True, enforce_string=True, truncate_limit=None)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Clean column names.</p>
<p>Takes all column names, converts them to lowercase,
then replaces all spaces with underscores.</p>
<p>By default, column names are converted to string types.
This can be switched off by passing in <code>enforce_string=False</code>.</p>
<p>This method does not mutate the original DataFrame.</p>
<p>Example usage:</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame(
...     {
...         "Aloha": range(3),
...         "Bell Chart": range(3),
...         "Animals@#$%^": range(3)
...     }
... )
&gt;&gt;&gt; df
   Aloha  Bell Chart  Animals@#$%^
0      0           0             0
1      1           1             1
2      2           2             2
&gt;&gt;&gt; df.clean_names()
   aloha  bell_chart  animals@#$%^
0      0           0             0
1      1           1             1
2      2           2             2
&gt;&gt;&gt; df.clean_names(remove_special=True)
   aloha  bell_chart  animals
0      0           0        0
1      1           1        1
2      2           2        2


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>The pandas DataFrame object.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>strip_underscores</code></td>
        <td><code>Union[str, bool]</code></td>
        <td><p>(optional) Removes the outer underscores from all column names. Default None keeps outer underscores. Values can be either 'left', 'right' or 'both' or the respective shorthand 'l', 'r' and True.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>case_type</code></td>
        <td><code>str</code></td>
        <td><p>(optional) Whether to make columns lower or uppercase. Current case may be preserved with 'preserve', while snake case conversion (from CamelCase or camelCase only) can be turned on using "snake". Default 'lower' makes all characters lowercase.</p></td>
        <td><code>&#39;lower&#39;</code></td>
      </tr>
      <tr>
        <td><code>remove_special</code></td>
        <td><code>bool</code></td>
        <td><p>(optional) Remove special characters from columns. Only letters, numbers and underscores are preserved.</p></td>
        <td><code>False</code></td>
      </tr>
      <tr>
        <td><code>strip_accents</code></td>
        <td><code>bool</code></td>
        <td><p>Whether or not to remove accents from columns names.</p></td>
        <td><code>True</code></td>
      </tr>
      <tr>
        <td><code>preserve_original_columns</code></td>
        <td><code>bool</code></td>
        <td><p>(optional) Preserve original names. This is later retrievable using <code>df.original_columns</code>.</p></td>
        <td><code>True</code></td>
      </tr>
      <tr>
        <td><code>enforce_string</code></td>
        <td><code>bool</code></td>
        <td><p>Whether or not to convert all column names to string type. Defaults to True, but can be turned off. Columns with &gt;1 levels will not be converted by default.</p></td>
        <td><code>True</code></td>
      </tr>
      <tr>
        <td><code>truncate_limit</code></td>
        <td><code>int</code></td>
        <td><p>(optional) Truncates formatted column names to the specified length. Default None does not truncate.</p></td>
        <td><code>None</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/clean_names.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
def clean_names(
    df: pd.DataFrame,
    strip_underscores: Optional[Union[str, bool]] = None,
    case_type: str = "lower",
    remove_special: bool = False,
    strip_accents: bool = True,
    preserve_original_columns: bool = True,
    enforce_string: bool = True,
    truncate_limit: int = None,
) -&gt; pd.DataFrame:
    """
    Clean column names.

    Takes all column names, converts them to lowercase,
    then replaces all spaces with underscores.

    By default, column names are converted to string types.
    This can be switched off by passing in `enforce_string=False`.

    This method does not mutate the original DataFrame.

    Example usage:

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame(
        ...     {
        ...         "Aloha": range(3),
        ...         "Bell Chart": range(3),
        ...         "Animals@#$%^": range(3)
        ...     }
        ... )
        &gt;&gt;&gt; df
           Aloha  Bell Chart  Animals@#$%^
        0      0           0             0
        1      1           1             1
        2      2           2             2
        &gt;&gt;&gt; df.clean_names()
           aloha  bell_chart  animals@#$%^
        0      0           0             0
        1      1           1             1
        2      2           2             2
        &gt;&gt;&gt; df.clean_names(remove_special=True)
           aloha  bell_chart  animals
        0      0           0        0
        1      1           1        1
        2      2           2        2

    :param df: The pandas DataFrame object.
    :param strip_underscores: (optional) Removes the outer underscores from all
        column names. Default None keeps outer underscores. Values can be
        either 'left', 'right' or 'both' or the respective shorthand 'l', 'r'
        and True.
    :param case_type: (optional) Whether to make columns lower or uppercase.
        Current case may be preserved with 'preserve',
        while snake case conversion (from CamelCase or camelCase only)
        can be turned on using "snake".
        Default 'lower' makes all characters lowercase.
    :param remove_special: (optional) Remove special characters from columns.
        Only letters, numbers and underscores are preserved.
    :param strip_accents: Whether or not to remove accents from
        columns names.
    :param preserve_original_columns: (optional) Preserve original names.
        This is later retrievable using `df.original_columns`.
    :param enforce_string: Whether or not to convert all column names
        to string type. Defaults to True, but can be turned off.
        Columns with &gt;1 levels will not be converted by default.
    :param truncate_limit: (optional) Truncates formatted column names to
        the specified length. Default None does not truncate.
    :returns: A pandas DataFrame.
    """
    original_column_names = list(df.columns)

    if enforce_string:
        df = df.rename(columns=str)

    df = df.rename(columns=lambda x: _change_case(x, case_type))

    df = df.rename(columns=_normalize_1)

    if remove_special:
        df = df.rename(columns=_remove_special)

    if strip_accents:
        df = df.rename(columns=_strip_accents)

    df = df.rename(columns=lambda x: re.sub("_+", "_", x))  # noqa: PD005
    df = _strip_underscores(df, strip_underscores)

    df = df.rename(columns=lambda x: x[:truncate_limit])

    # Store the original column names, if enabled by user
    if preserve_original_columns:
        df.__dict__["original_columns"] = original_column_names
    return df
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.coalesce" class="doc doc-heading">
        <code>coalesce</code>



</h2>

    <div class="doc doc-contents ">

      <p>Function for performing coalesce.</p>



  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.coalesce.coalesce" class="doc doc-heading">
<code class="highlight language-python">coalesce(df, *column_names, *, target_column_name=None, default_value=None)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Coalesce two or more columns of data in order of column names provided.</p>
<p>Given the variable arguments of column names,
<code>coalesce</code> finds and returns the first non-missing value
from these columns, for every row in the input dataframe.
If all the column values are null for a particular row,
then the <code>default_value</code> will be filled in.</p>
<p>If <code>target_column_name</code> is not provided,
then the first column is coalesced.</p>
<p>This method does not mutate the original DataFrame.</p>
<p>Example: Use <code>coalesce</code> with 3 columns, "a", "b" and "c".</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({
...     "a": [np.nan, 1, np.nan],
...     "b": [2, 3, np.nan],
...     "c": [4, np.nan, np.nan],
... })
&gt;&gt;&gt; df.coalesce("a", "b", "c")
     a    b    c
0  2.0  2.0  4.0
1  1.0  3.0  NaN
2  NaN  NaN  NaN
</code></pre>
<p>Example: Provide a target_column_name.</p>
<pre class="highlight"><code>&gt;&gt;&gt; df.coalesce("a", "b", "c", target_column_name="new_col")
     a    b    c  new_col
0  NaN  2.0  4.0      2.0
1  1.0  3.0  NaN      1.0
2  NaN  NaN  NaN      NaN
</code></pre>
<p>Example: Provide a default value.</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({
...     "a": [1, np.nan, np.nan],
...     "b": [2, 3, np.nan],
... })
&gt;&gt;&gt; df.coalesce(
...     "a", "b",
...     target_column_name="new_col",
...     default_value=-1,
... )
     a    b  new_col
0  1.0  2.0      1.0
1  NaN  3.0      3.0
2  NaN  NaN     -1.0
</code></pre>
<p>This is more syntactic diabetes! For R users, this should look familiar to
<code>dplyr</code>'s <code>coalesce</code> function; for Python users, the interface
should be more intuitive than the <code>pandas.Series.combine_first</code>
method.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A pandas DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>column_names</code></td>
        <td></td>
        <td><p>A list of column names.</p></td>
        <td><code>()</code></td>
      </tr>
      <tr>
        <td><code>target_column_name</code></td>
        <td><code>Optional[str]</code></td>
        <td><p>The new column name after combining. If <code>None</code>, then the first column in <code>column_names</code> is updated, with the Null values replaced.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>default_value</code></td>
        <td><code>Union[int, float, str]</code></td>
        <td><p>A scalar to replace any remaining nulls after coalescing.</p></td>
        <td><code>None</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame with coalesced columns.</p></td>
    </tr>
  </tbody>
</table>
<p><strong>Exceptions:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>ValueError</code></td>
        <td><p>if length of <code>column_names</code> is less than 2.</p></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/coalesce.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
@deprecated_alias(columns="column_names", new_column_name="target_column_name")
def coalesce(
    df: pd.DataFrame,
    *column_names,
    target_column_name: Optional[str] = None,
    default_value: Optional[Union[int, float, str]] = None,
) -&gt; pd.DataFrame:
    """Coalesce two or more columns of data in order of column names provided.

    Given the variable arguments of column names,
    `coalesce` finds and returns the first non-missing value
    from these columns, for every row in the input dataframe.
    If all the column values are null for a particular row,
    then the `default_value` will be filled in.

    If `target_column_name` is not provided,
    then the first column is coalesced.

    This method does not mutate the original DataFrame.

    Example: Use `coalesce` with 3 columns, "a", "b" and "c".

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import numpy as np
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({
        ...     "a": [np.nan, 1, np.nan],
        ...     "b": [2, 3, np.nan],
        ...     "c": [4, np.nan, np.nan],
        ... })
        &gt;&gt;&gt; df.coalesce("a", "b", "c")
             a    b    c
        0  2.0  2.0  4.0
        1  1.0  3.0  NaN
        2  NaN  NaN  NaN

    Example: Provide a target_column_name.

        &gt;&gt;&gt; df.coalesce("a", "b", "c", target_column_name="new_col")
             a    b    c  new_col
        0  NaN  2.0  4.0      2.0
        1  1.0  3.0  NaN      1.0
        2  NaN  NaN  NaN      NaN

    Example: Provide a default value.

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import numpy as np
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({
        ...     "a": [1, np.nan, np.nan],
        ...     "b": [2, 3, np.nan],
        ... })
        &gt;&gt;&gt; df.coalesce(
        ...     "a", "b",
        ...     target_column_name="new_col",
        ...     default_value=-1,
        ... )
             a    b  new_col
        0  1.0  2.0      1.0
        1  NaN  3.0      3.0
        2  NaN  NaN     -1.0

    This is more syntactic diabetes! For R users, this should look familiar to
    `dplyr`'s `coalesce` function; for Python users, the interface
    should be more intuitive than the `pandas.Series.combine_first`
    method.

    :param df: A pandas DataFrame.
    :param column_names: A list of column names.
    :param target_column_name: The new column name after combining.
        If `None`, then the first column in `column_names` is updated,
        with the Null values replaced.
    :param default_value: A scalar to replace any remaining nulls
        after coalescing.
    :returns: A pandas DataFrame with coalesced columns.
    :raises ValueError: if length of `column_names` is less than 2.
    """

    if not column_names:
        return df

    if len(column_names) &lt; 2:
        raise ValueError(
            "The number of columns to coalesce should be a minimum of 2."
        )

    indices = _select_index([*column_names], df, axis="columns")
    column_names = df.columns[indices]

    if target_column_name:
        check("target_column_name", target_column_name, [str])

    if default_value:
        check("default_value", default_value, [int, float, str])

    if target_column_name is None:
        target_column_name = column_names[0]

    outcome = df.loc(axis=1)[column_names].bfill(axis="columns").iloc[:, 0]
    if outcome.hasnans and (default_value is not None):
        outcome = outcome.fillna(default_value)

    return df.assign(**{target_column_name: outcome})
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.collapse_levels" class="doc doc-heading">
        <code>collapse_levels</code>



</h2>

    <div class="doc doc-contents ">

      <p>Implementation of the <code>collapse_levels</code> function.</p>



  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.collapse_levels.collapse_levels" class="doc doc-heading">
<code class="highlight language-python">collapse_levels(df, sep='_')</code>


</h3>

    <div class="doc doc-contents ">

      <p>Flatten multi-level column dataframe to a single level.</p>
<p>This method mutates the original DataFrame.</p>
<p>Given a DataFrame containing multi-level columns, flatten to single-level
by string-joining the column labels in each level.</p>
<p>After a <code>groupby</code> / <code>aggregate</code> operation where <code>.agg()</code> is passed a
list of multiple aggregation functions, a multi-level DataFrame is
returned with the name of the function applied in the second level.</p>
<p>It is sometimes convenient for later indexing to flatten out this
multi-level configuration back into a single level. This function does
this through a simple string-joining of all the names across different
levels in a single column.</p>
<p>Example:</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({
...     "class": ["bird", "bird", "bird", "mammal", "mammal"],
...     "max_speed": [389, 389, 24, 80, 21],
...     "type": ["falcon", "falcon", "parrot", "Lion", "Monkey"],
... })
&gt;&gt;&gt; df
    class  max_speed    type
0    bird        389  falcon
1    bird        389  falcon
2    bird         24  parrot
3  mammal         80    Lion
4  mammal         21  Monkey
&gt;&gt;&gt; grouped_df = df.groupby("class").agg(["mean", "median"])
&gt;&gt;&gt; grouped_df  # doctest: +NORMALIZE_WHITESPACE
         max_speed
              mean median
class
bird    267.333333  389.0
mammal   50.500000   50.5
&gt;&gt;&gt; grouped_df.collapse_levels(sep="_")  # doctest: +NORMALIZE_WHITESPACE
        max_speed_mean  max_speed_median
class
bird        267.333333             389.0
mammal       50.500000              50.5
</code></pre>
<p>Before applying <code>.collapse_levels</code>, the <code>.agg</code> operation returns a
multi-level column DataFrame whose columns are <code>(level 1, level 2)</code>:</p>
<pre class="highlight"><code>[("max_speed", "mean"), ("max_speed", "median")]
</code></pre>
<p><code>.collapse_levels</code> then flattens the column MultiIndex into a single
level index with names:</p>
<pre class="highlight"><code>["max_speed_mean", "max_speed_median"]


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A pandas DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>sep</code></td>
        <td><code>str</code></td>
        <td><p>String separator used to join the column level names.</p></td>
        <td><code>&#39;_&#39;</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame with single-level column index.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/collapse_levels.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
def collapse_levels(df: pd.DataFrame, sep: str = "_") -&gt; pd.DataFrame:
    """Flatten multi-level column dataframe to a single level.

    This method mutates the original DataFrame.

    Given a DataFrame containing multi-level columns, flatten to single-level
    by string-joining the column labels in each level.

    After a `groupby` / `aggregate` operation where `.agg()` is passed a
    list of multiple aggregation functions, a multi-level DataFrame is
    returned with the name of the function applied in the second level.

    It is sometimes convenient for later indexing to flatten out this
    multi-level configuration back into a single level. This function does
    this through a simple string-joining of all the names across different
    levels in a single column.

    Example:

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({
        ...     "class": ["bird", "bird", "bird", "mammal", "mammal"],
        ...     "max_speed": [389, 389, 24, 80, 21],
        ...     "type": ["falcon", "falcon", "parrot", "Lion", "Monkey"],
        ... })
        &gt;&gt;&gt; df
            class  max_speed    type
        0    bird        389  falcon
        1    bird        389  falcon
        2    bird         24  parrot
        3  mammal         80    Lion
        4  mammal         21  Monkey
        &gt;&gt;&gt; grouped_df = df.groupby("class").agg(["mean", "median"])
        &gt;&gt;&gt; grouped_df  # doctest: +NORMALIZE_WHITESPACE
                 max_speed
                      mean median
        class
        bird    267.333333  389.0
        mammal   50.500000   50.5
        &gt;&gt;&gt; grouped_df.collapse_levels(sep="_")  # doctest: +NORMALIZE_WHITESPACE
                max_speed_mean  max_speed_median
        class
        bird        267.333333             389.0
        mammal       50.500000              50.5

    Before applying `.collapse_levels`, the `.agg` operation returns a
    multi-level column DataFrame whose columns are `(level 1, level 2)`:

        [("max_speed", "mean"), ("max_speed", "median")]

    `.collapse_levels` then flattens the column MultiIndex into a single
    level index with names:

        ["max_speed_mean", "max_speed_median"]

    :param df: A pandas DataFrame.
    :param sep: String separator used to join the column level names.
    :returns: A pandas DataFrame with single-level column index.
    """  # noqa: E501
    check("sep", sep, [str])

    # if already single-level, just return the DataFrame
    if not isinstance(df.columns, pd.MultiIndex):
        return df

    df.columns = [
        sep.join(str(el) for el in tup if str(el) != "")
        for tup in df  # noqa: PD011
    ]

    return df
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.complete" class="doc doc-heading">
        <code>complete</code>



</h2>

    <div class="doc doc-contents ">




  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.complete.complete" class="doc doc-heading">
<code class="highlight language-python">complete(df, *columns, *, sort=False, by=None, fill_value=None, explicit=True)</code>


</h3>

    <div class="doc doc-contents ">

      <p>It is modeled after tidyr's <code>complete</code> function, and is a wrapper around
<a class="autorefs autorefs-internal" href="#janitor.functions.expand_grid.expand_grid"><code>expand_grid</code></a>, <code>pd.merge</code>
and <code>pd.fillna</code>. In a way, it is the inverse of <code>pd.dropna</code>, as it exposes
implicitly missing rows.</p>
<p>Combinations of column names or a list/tuple of column names, or even a
dictionary of column names and new values are possible.</p>
<p>MultiIndex columns are not supported.</p>
<p>Example:</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; df = pd.DataFrame(
...     {
...         "Year": [1999, 2000, 2004, 1999, 2004],
...         "Taxon": [
...             "Saccharina",
...             "Saccharina",
...             "Saccharina",
...             "Agarum",
...             "Agarum",
...         ],
...         "Abundance": [4, 5, 2, 1, 8],
...     }
... )
&gt;&gt;&gt; df
   Year       Taxon  Abundance
0  1999  Saccharina          4
1  2000  Saccharina          5
2  2004  Saccharina          2
3  1999      Agarum          1
4  2004      Agarum          8
</code></pre>
<p>Expose missing pairings of <code>Year</code> and <code>Taxon</code>:</p>
<pre class="highlight"><code>&gt;&gt;&gt; df.complete("Year", "Taxon", sort=True)
   Year       Taxon  Abundance
0  1999      Agarum        1.0
1  1999  Saccharina        4.0
2  2000      Agarum        NaN
3  2000  Saccharina        5.0
4  2004      Agarum        8.0
5  2004  Saccharina        2.0
</code></pre>
<p>Expose missing years from 1999 to 2004 :</p>
<pre class="highlight"><code>&gt;&gt;&gt; df.complete(
...     {"Year": range(df.Year.min(), df.Year.max() + 1)},
...     "Taxon",
...     sort=True
... )
    Year       Taxon  Abundance
0   1999      Agarum        1.0
1   1999  Saccharina        4.0
2   2000      Agarum        NaN
3   2000  Saccharina        5.0
4   2001      Agarum        NaN
5   2001  Saccharina        NaN
6   2002      Agarum        NaN
7   2002  Saccharina        NaN
8   2003      Agarum        NaN
9   2003  Saccharina        NaN
10  2004      Agarum        8.0
11  2004  Saccharina        2.0
</code></pre>
<p>Fill missing values:</p>
<pre class="highlight"><code>&gt;&gt;&gt; df = pd.DataFrame(
...     dict(
...         group=(1, 2, 1, 2),
...         item_id=(1, 2, 2, 3),
...         item_name=("a", "a", "b", "b"),
...         value1=(1, np.nan, 3, 4),
...         value2=range(4, 8),
...     )
... )
&gt;&gt;&gt; df
   group  item_id item_name  value1  value2
0      1        1         a     1.0       4
1      2        2         a     NaN       5
2      1        2         b     3.0       6
3      2        3         b     4.0       7
&gt;&gt;&gt; df.complete(
...     "group",
...     ("item_id", "item_name"),
...     fill_value={"value1": 0, "value2": 99},
...     sort=True
... )
   group  item_id item_name  value1  value2
0      1        1         a       1       4
1      1        2         a       0      99
2      1        2         b       3       6
3      1        3         b       0      99
4      2        1         a       0      99
5      2        2         a       0       5
6      2        2         b       0      99
7      2        3         b       4       7
</code></pre>
<p>Limit the fill to only implicit missing values
by setting explicit to <code>False</code>:</p>
<pre class="highlight"><code>&gt;&gt;&gt; df.complete(
...     "group",
...     ("item_id", "item_name"),
...     fill_value={"value1": 0, "value2": 99},
...     explicit=False,
...     sort=True
... )
   group  item_id item_name  value1  value2
0      1        1         a     1.0     4.0
1      1        2         a     0.0    99.0
2      1        2         b     3.0     6.0
3      1        3         b     0.0    99.0
4      2        1         a     0.0    99.0
5      2        2         a     NaN     5.0
6      2        2         b     0.0    99.0
7      2        3         b     4.0     7.0


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A pandas DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>*columns</code></td>
        <td></td>
        <td><p>This refers to the columns to be completed. It could be column labels (string type), a list/tuple of column labels, or a dictionary that pairs column labels with new values.</p></td>
        <td><code>()</code></td>
      </tr>
      <tr>
        <td><code>sort</code></td>
        <td><code>bool</code></td>
        <td><p>Sort DataFrame based on *columns. Default is <code>False</code>.</p></td>
        <td><code>False</code></td>
      </tr>
      <tr>
        <td><code>by</code></td>
        <td><code>Union[list, str]</code></td>
        <td><p>label or list of labels to group by. The explicit missing rows are returned per group.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>fill_value</code></td>
        <td><code>Union[Dict, Any]</code></td>
        <td><p>Scalar value to use instead of NaN for missing combinations. A dictionary, mapping columns names to a scalar value is also accepted.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>explicit</code></td>
        <td><code>bool</code></td>
        <td><p>Determines if only implicitly missing values should be filled (<code>False</code>), or all nulls existing in the dataframe (<code>True</code>). Default is <code>True</code>. <code>explicit</code> is applicable only if <code>fill_value</code> is not <code>None</code>.</p></td>
        <td><code>True</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame with explicit missing rows, if any.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/complete.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
def complete(
    df: pd.DataFrame,
    *columns,
    sort: bool = False,
    by: Optional[Union[list, str]] = None,
    fill_value: Optional[Union[Dict, Any]] = None,
    explicit: bool = True,
) -&gt; pd.DataFrame:
    """
    It is modeled after tidyr's `complete` function, and is a wrapper around
    [`expand_grid`][janitor.functions.expand_grid.expand_grid], `pd.merge`
    and `pd.fillna`. In a way, it is the inverse of `pd.dropna`, as it exposes
    implicitly missing rows.

    Combinations of column names or a list/tuple of column names, or even a
    dictionary of column names and new values are possible.

    MultiIndex columns are not supported.

    Example:

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; import numpy as np
        &gt;&gt;&gt; df = pd.DataFrame(
        ...     {
        ...         "Year": [1999, 2000, 2004, 1999, 2004],
        ...         "Taxon": [
        ...             "Saccharina",
        ...             "Saccharina",
        ...             "Saccharina",
        ...             "Agarum",
        ...             "Agarum",
        ...         ],
        ...         "Abundance": [4, 5, 2, 1, 8],
        ...     }
        ... )
        &gt;&gt;&gt; df
           Year       Taxon  Abundance
        0  1999  Saccharina          4
        1  2000  Saccharina          5
        2  2004  Saccharina          2
        3  1999      Agarum          1
        4  2004      Agarum          8

    Expose missing pairings of `Year` and `Taxon`:

        &gt;&gt;&gt; df.complete("Year", "Taxon", sort=True)
           Year       Taxon  Abundance
        0  1999      Agarum        1.0
        1  1999  Saccharina        4.0
        2  2000      Agarum        NaN
        3  2000  Saccharina        5.0
        4  2004      Agarum        8.0
        5  2004  Saccharina        2.0

    Expose missing years from 1999 to 2004 :

        &gt;&gt;&gt; df.complete(
        ...     {"Year": range(df.Year.min(), df.Year.max() + 1)},
        ...     "Taxon",
        ...     sort=True
        ... )
            Year       Taxon  Abundance
        0   1999      Agarum        1.0
        1   1999  Saccharina        4.0
        2   2000      Agarum        NaN
        3   2000  Saccharina        5.0
        4   2001      Agarum        NaN
        5   2001  Saccharina        NaN
        6   2002      Agarum        NaN
        7   2002  Saccharina        NaN
        8   2003      Agarum        NaN
        9   2003  Saccharina        NaN
        10  2004      Agarum        8.0
        11  2004  Saccharina        2.0

    Fill missing values:

        &gt;&gt;&gt; df = pd.DataFrame(
        ...     dict(
        ...         group=(1, 2, 1, 2),
        ...         item_id=(1, 2, 2, 3),
        ...         item_name=("a", "a", "b", "b"),
        ...         value1=(1, np.nan, 3, 4),
        ...         value2=range(4, 8),
        ...     )
        ... )
        &gt;&gt;&gt; df
           group  item_id item_name  value1  value2
        0      1        1         a     1.0       4
        1      2        2         a     NaN       5
        2      1        2         b     3.0       6
        3      2        3         b     4.0       7
        &gt;&gt;&gt; df.complete(
        ...     "group",
        ...     ("item_id", "item_name"),
        ...     fill_value={"value1": 0, "value2": 99},
        ...     sort=True
        ... )
           group  item_id item_name  value1  value2
        0      1        1         a       1       4
        1      1        2         a       0      99
        2      1        2         b       3       6
        3      1        3         b       0      99
        4      2        1         a       0      99
        5      2        2         a       0       5
        6      2        2         b       0      99
        7      2        3         b       4       7

    Limit the fill to only implicit missing values
    by setting explicit to `False`:

        &gt;&gt;&gt; df.complete(
        ...     "group",
        ...     ("item_id", "item_name"),
        ...     fill_value={"value1": 0, "value2": 99},
        ...     explicit=False,
        ...     sort=True
        ... )
           group  item_id item_name  value1  value2
        0      1        1         a     1.0     4.0
        1      1        2         a     0.0    99.0
        2      1        2         b     3.0     6.0
        3      1        3         b     0.0    99.0
        4      2        1         a     0.0    99.0
        5      2        2         a     NaN     5.0
        6      2        2         b     0.0    99.0
        7      2        3         b     4.0     7.0

    :param df: A pandas DataFrame.
    :param *columns: This refers to the columns to be
        completed. It could be column labels (string type),
        a list/tuple of column labels, or a dictionary that pairs
        column labels with new values.
    :param sort: Sort DataFrame based on *columns. Default is `False`.
    :param by: label or list of labels to group by.
        The explicit missing rows are returned per group.
    :param fill_value: Scalar value to use instead of NaN
        for missing combinations. A dictionary, mapping columns names
        to a scalar value is also accepted.
    :param explicit: Determines if only implicitly missing values
        should be filled (`False`), or all nulls existing in the dataframe
        (`True`). Default is `True`. `explicit` is applicable only
        if `fill_value` is not `None`.
    :returns: A pandas DataFrame with explicit missing rows, if any.
    """

    if not columns:
        return df

    df = df.copy()

    return _computations_complete(df, columns, sort, by, fill_value, explicit)
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.concatenate_columns" class="doc doc-heading">
        <code>concatenate_columns</code>



</h2>

    <div class="doc doc-contents ">




  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.concatenate_columns.concatenate_columns" class="doc doc-heading">
<code class="highlight language-python">concatenate_columns(df, column_names, new_column_name, sep='-', ignore_empty=True)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Concatenates the set of columns into a single column.</p>
<p>Used to quickly generate an index based on a group of columns.</p>
<p>This method mutates the original DataFrame.</p>
<p>Example: Concatenate two columns row-wise.</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({"a": [1, 3, 5], "b": list("xyz")})
&gt;&gt;&gt; df
   a  b
0  1  x
1  3  y
2  5  z
&gt;&gt;&gt; df.concatenate_columns(
...     column_names=["a", "b"], new_column_name="m",
... )
   a  b    m
0  1  x  1-x
1  3  y  3-y
2  5  z  5-z


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A pandas DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>column_names</code></td>
        <td><code>List[Hashable]</code></td>
        <td><p>A list of columns to concatenate together.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>new_column_name</code></td>
        <td><code>Hashable</code></td>
        <td><p>The name of the new column.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>sep</code></td>
        <td><code>str</code></td>
        <td><p>The separator between each column's data.</p></td>
        <td><code>&#39;-&#39;</code></td>
      </tr>
      <tr>
        <td><code>ignore_empty</code></td>
        <td><code>bool</code></td>
        <td><p>Ignore null values if exists.</p></td>
        <td><code>True</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame with concatenated columns.</p></td>
    </tr>
  </tbody>
</table>
<p><strong>Exceptions:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>JanitorError</code></td>
        <td><p>If at least two columns are not provided within <code>column_names</code>.</p></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/concatenate_columns.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
@deprecated_alias(columns="column_names")
def concatenate_columns(
    df: pd.DataFrame,
    column_names: List[Hashable],
    new_column_name: Hashable,
    sep: str = "-",
    ignore_empty: bool = True,
) -&gt; pd.DataFrame:
    """Concatenates the set of columns into a single column.

    Used to quickly generate an index based on a group of columns.

    This method mutates the original DataFrame.

    Example: Concatenate two columns row-wise.

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({"a": [1, 3, 5], "b": list("xyz")})
        &gt;&gt;&gt; df
           a  b
        0  1  x
        1  3  y
        2  5  z
        &gt;&gt;&gt; df.concatenate_columns(
        ...     column_names=["a", "b"], new_column_name="m",
        ... )
           a  b    m
        0  1  x  1-x
        1  3  y  3-y
        2  5  z  5-z

    :param df: A pandas DataFrame.
    :param column_names: A list of columns to concatenate together.
    :param new_column_name: The name of the new column.
    :param sep: The separator between each column's data.
    :param ignore_empty: Ignore null values if exists.
    :returns: A pandas DataFrame with concatenated columns.
    :raises JanitorError: If at least two columns are not provided
        within `column_names`.
    """
    if len(column_names) &lt; 2:
        raise JanitorError("At least two columns must be specified")

    df[new_column_name] = (
        df[column_names].astype(str).fillna("").agg(sep.join, axis=1)
    )

    if ignore_empty:

        def remove_empty_string(x):
            """Ignore empty/null string values from the concatenated output."""
            return sep.join(x for x in x.split(sep) if x)

        df[new_column_name] = df[new_column_name].transform(
            remove_empty_string
        )

    return df
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.conditional_join" class="doc doc-heading">
        <code>conditional_join</code>



</h2>

    <div class="doc doc-contents ">




  <div class="doc doc-children">











  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.conditional_join.conditional_join" class="doc doc-heading">
<code class="highlight language-python">conditional_join(df, right, *conditions, *, how='inner', sort_by_appearance=False, df_columns=None, right_columns=None, keep='all', use_numba=False)</code>


</h3>

    <div class="doc doc-contents ">

      <p>The conditional_join function operates similarly to <code>pd.merge</code>,
but allows joins on inequality operators,
or a combination of equi and non-equi joins.</p>
<p>Joins solely on equality are not supported.</p>
<p>If the join is solely on equality, <code>pd.merge</code> function
covers that; if you are interested in nearest joins, or rolling joins,
then <code>pd.merge_asof</code> covers that.
There is also pandas' IntervalIndex, which is efficient for range joins,
especially if the intervals do not overlap.</p>
<p>Column selection in <code>df_columns</code> and <code>right_columns</code> is possible using the
<a class="autorefs autorefs-internal" href="#janitor.functions.select.select_columns"><code>select_columns</code></a> syntax.</p>
<p>For strictly non-equi joins,
involving either <code>&gt;</code>, <code>&lt;</code>, <code>&gt;=</code>, <code>&lt;=</code> operators,
performance could be improved by setting <code>use_numba</code> to <code>True</code>.
This assumes that <code>numba</code> is installed.</p>
<p>To preserve row order, set <code>sort_by_appearance</code> to <code>True</code>.</p>
<p>This function returns rows, if any, where values from <code>df</code> meet the
condition(s) for values from <code>right</code>. The conditions are passed in
as a variable argument of tuples, where the tuple is of
the form <code>(left_on, right_on, op)</code>; <code>left_on</code> is the column
label from <code>df</code>, <code>right_on</code> is the column label from <code>right</code>,
while <code>op</code> is the operator. For multiple conditions, the and(<code>&amp;</code>)
operator is used to combine the results of the individual conditions.</p>
<p>The operator can be any of <code>==</code>, <code>!=</code>, <code>&lt;=</code>, <code>&lt;</code>, <code>&gt;=</code>, <code>&gt;</code>.</p>
<p>The join is done only on the columns.
MultiIndex columns are not supported.</p>
<p>For non-equi joins, only numeric and date columns are supported.</p>
<p>Only <code>inner</code>, <code>left</code>, and <code>right</code> joins are supported.</p>
<p>If the columns from <code>df</code> and <code>right</code> have nothing in common,
a single index column is returned; else, a MultiIndex column
is returned.</p>
<p>Example:</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df1 = pd.DataFrame({"value_1": [2, 5, 7, 1, 3, 4]})
&gt;&gt;&gt; df2 = pd.DataFrame({"value_2A": [0, 3, 7, 12, 0, 2, 3, 1],
...                     "value_2B": [1, 5, 9, 15, 1, 4, 6, 3],
...                    })
&gt;&gt;&gt; df1
   value_1
0        2
1        5
2        7
3        1
4        3
5        4
&gt;&gt;&gt; df2
   value_2A  value_2B
0         0         1
1         3         5
2         7         9
3        12        15
4         0         1
5         2         4
6         3         6
7         1         3
&gt;&gt;&gt; df1.conditional_join(
...     df2,
...     ("value_1", "value_2A", "&gt;"),
...     ("value_1", "value_2B", "&lt;")
... )
   value_1  value_2A  value_2B
0        2         1         3
1        5         3         6
2        3         2         4
3        4         3         5
4        4         3         6
</code></pre>
<div class="admonition abstract">
<p class="admonition-title">Version Changed</p>
<ul>
<li>0.24.0<ul>
<li>Added <code>df_columns</code>, <code>right_columns</code>, <code>keep</code> and <code>use_numba</code> parameters.</li>
</ul>
</li>
</ul>
</div>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A pandas DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>right</code></td>
        <td><code>Union[pandas.core.frame.DataFrame, pandas.core.series.Series]</code></td>
        <td><p>Named Series or DataFrame to join to.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>conditions</code></td>
        <td></td>
        <td><p>Variable argument of tuple(s) of the form <code>(left_on, right_on, op)</code>, where <code>left_on</code> is the column label from <code>df</code>, <code>right_on</code> is the column label from <code>right</code>, while <code>op</code> is the operator. The operator can be any of <code>==</code>, <code>!=</code>, <code>&lt;=</code>, <code>&lt;</code>, <code>&gt;=</code>, <code>&gt;</code>. For multiple conditions, the and(<code>&amp;</code>) operator is used to combine the results of the individual conditions.</p></td>
        <td><code>()</code></td>
      </tr>
      <tr>
        <td><code>how</code></td>
        <td><code>Literal[&#39;inner&#39;, &#39;left&#39;, &#39;right&#39;]</code></td>
        <td><p>Indicates the type of join to be performed. It can be one of <code>inner</code>, <code>left</code>, <code>right</code>. Full outer join is not supported. Defaults to <code>inner</code>.</p></td>
        <td><code>&#39;inner&#39;</code></td>
      </tr>
      <tr>
        <td><code>sort_by_appearance</code></td>
        <td><code>bool</code></td>
        <td><p>Default is <code>False</code>. This is useful for scenarios where the user wants the original order maintained. If <code>True</code> and <code>how = left</code>, the row order from the left dataframe is preserved; if <code>True</code> and <code>how = right</code>, the row order from the right dataframe is preserved.</p></td>
        <td><code>False</code></td>
      </tr>
      <tr>
        <td><code>df_columns</code></td>
        <td><code>Optional[Any]</code></td>
        <td><p>Columns to select from <code>df</code>. It can be a single column or a list of columns. It is also possible to rename the output columns via a dictionary.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>right_columns</code></td>
        <td><code>Optional[Any]</code></td>
        <td><p>Columns to select from <code>right</code>. It can be a single column or a list of columns. It is also possible to rename the output columns via a dictionary.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>keep</code></td>
        <td><code>Literal[&#39;first&#39;, &#39;last&#39;, &#39;all&#39;]</code></td>
        <td><p>Choose whether to return the first match, last match or all matches. Default is <code>all</code>.</p></td>
        <td><code>&#39;all&#39;</code></td>
      </tr>
      <tr>
        <td><code>use_numba</code></td>
        <td><code>bool</code></td>
        <td><p>Use numba, if installed, to accelerate the computation. Applicable only to strictly non-equi joins. Default is <code>False</code>.</p></td>
        <td><code>False</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame of the two merged Pandas objects.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/conditional_join.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
def conditional_join(
    df: pd.DataFrame,
    right: Union[pd.DataFrame, pd.Series],
    *conditions,
    how: Literal["inner", "left", "right"] = "inner",
    sort_by_appearance: bool = False,
    df_columns: Optional[Any] = None,
    right_columns: Optional[Any] = None,
    keep: Literal["first", "last", "all"] = "all",
    use_numba: bool = False,
) -&gt; pd.DataFrame:
    """

    The conditional_join function operates similarly to `pd.merge`,
    but allows joins on inequality operators,
    or a combination of equi and non-equi joins.

    Joins solely on equality are not supported.

    If the join is solely on equality, `pd.merge` function
    covers that; if you are interested in nearest joins, or rolling joins,
    then `pd.merge_asof` covers that.
    There is also pandas' IntervalIndex, which is efficient for range joins,
    especially if the intervals do not overlap.

    Column selection in `df_columns` and `right_columns` is possible using the
    [`select_columns`][janitor.functions.select.select_columns] syntax.

    For strictly non-equi joins,
    involving either `&gt;`, `&lt;`, `&gt;=`, `&lt;=` operators,
    performance could be improved by setting `use_numba` to `True`.
    This assumes that `numba` is installed.

    To preserve row order, set `sort_by_appearance` to `True`.

    This function returns rows, if any, where values from `df` meet the
    condition(s) for values from `right`. The conditions are passed in
    as a variable argument of tuples, where the tuple is of
    the form `(left_on, right_on, op)`; `left_on` is the column
    label from `df`, `right_on` is the column label from `right`,
    while `op` is the operator. For multiple conditions, the and(`&amp;`)
    operator is used to combine the results of the individual conditions.

    The operator can be any of `==`, `!=`, `&lt;=`, `&lt;`, `&gt;=`, `&gt;`.

    The join is done only on the columns.
    MultiIndex columns are not supported.

    For non-equi joins, only numeric and date columns are supported.

    Only `inner`, `left`, and `right` joins are supported.

    If the columns from `df` and `right` have nothing in common,
    a single index column is returned; else, a MultiIndex column
    is returned.

    Example:

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df1 = pd.DataFrame({"value_1": [2, 5, 7, 1, 3, 4]})
        &gt;&gt;&gt; df2 = pd.DataFrame({"value_2A": [0, 3, 7, 12, 0, 2, 3, 1],
        ...                     "value_2B": [1, 5, 9, 15, 1, 4, 6, 3],
        ...                    })
        &gt;&gt;&gt; df1
           value_1
        0        2
        1        5
        2        7
        3        1
        4        3
        5        4
        &gt;&gt;&gt; df2
           value_2A  value_2B
        0         0         1
        1         3         5
        2         7         9
        3        12        15
        4         0         1
        5         2         4
        6         3         6
        7         1         3
        &gt;&gt;&gt; df1.conditional_join(
        ...     df2,
        ...     ("value_1", "value_2A", "&gt;"),
        ...     ("value_1", "value_2B", "&lt;")
        ... )
           value_1  value_2A  value_2B
        0        2         1         3
        1        5         3         6
        2        3         2         4
        3        4         3         5
        4        4         3         6

    !!! abstract "Version Changed"

        - 0.24.0
            - Added `df_columns`, `right_columns`, `keep` and `use_numba` parameters.



    :param df: A pandas DataFrame.
    :param right: Named Series or DataFrame to join to.
    :param conditions: Variable argument of tuple(s) of the form
        `(left_on, right_on, op)`, where `left_on` is the column
        label from `df`, `right_on` is the column label from `right`,
        while `op` is the operator. The operator can be any of
        `==`, `!=`, `&lt;=`, `&lt;`, `&gt;=`, `&gt;`. For multiple conditions,
        the and(`&amp;`) operator is used to combine the results
        of the individual conditions.
    :param how: Indicates the type of join to be performed.
        It can be one of `inner`, `left`, `right`.
        Full outer join is not supported. Defaults to `inner`.
    :param sort_by_appearance: Default is `False`.
        This is useful for scenarios where the user wants
        the original order maintained.
        If `True` and `how = left`, the row order from the left dataframe
        is preserved; if `True` and `how = right`, the row order
        from the right dataframe is preserved.
    :param df_columns: Columns to select from `df`.
        It can be a single column or a list of columns.
        It is also possible to rename the output columns via a dictionary.
    :param right_columns: Columns to select from `right`.
        It can be a single column or a list of columns.
        It is also possible to rename the output columns via a dictionary.
    :param keep: Choose whether to return the first match,
        last match or all matches. Default is `all`.
    :param use_numba: Use numba, if installed, to accelerate the computation.
        Applicable only to strictly non-equi joins. Default is `False`.
    :returns: A pandas DataFrame of the two merged Pandas objects.
    """  # noqa: E501

    return _conditional_join_compute(
        df,
        right,
        conditions,
        how,
        sort_by_appearance,
        df_columns,
        right_columns,
        keep,
        use_numba,
    )
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.convert_date" class="doc doc-heading">
        <code>convert_date</code>



</h2>

    <div class="doc doc-contents ">




  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.convert_date.convert_excel_date" class="doc doc-heading">
<code class="highlight language-python">convert_excel_date(df, column_name)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Convert Excel's serial date format into Python datetime format.</p>
<p>This method mutates the original DataFrame.</p>
<p>Implementation is also from
<a href="https://stackoverflow.com/questions/38454403/convert-excel-style-date-with-pandas">Stack Overflow</a></p>
<p>Method chaining syntax:</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({"date": [39690, 39690, 37118]})
&gt;&gt;&gt; df
    date
0  39690
1  39690
2  37118
&gt;&gt;&gt; df.convert_excel_date('date')
        date
0 2008-08-30
1 2008-08-30
2 2001-08-15


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A pandas DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>column_name</code></td>
        <td><code>Hashable</code></td>
        <td><p>A column name.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame with corrected dates.</p></td>
    </tr>
  </tbody>
</table>
<p><strong>Exceptions:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>ValueError</code></td>
        <td><p>if there are non numeric values in the column.</p></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/convert_date.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
@deprecated_alias(column="column_name")
def convert_excel_date(
    df: pd.DataFrame, column_name: Hashable
) -&gt; pd.DataFrame:
    """
    Convert Excel's serial date format into Python datetime format.

    This method mutates the original DataFrame.

    Implementation is also from
    [Stack Overflow](https://stackoverflow.com/questions/38454403/convert-excel-style-date-with-pandas)

    Method chaining syntax:

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({"date": [39690, 39690, 37118]})
        &gt;&gt;&gt; df
            date
        0  39690
        1  39690
        2  37118
        &gt;&gt;&gt; df.convert_excel_date('date')
                date
        0 2008-08-30
        1 2008-08-30
        2 2001-08-15

    :param df: A pandas DataFrame.
    :param column_name: A column name.
    :returns: A pandas DataFrame with corrected dates.
    :raises ValueError: if there are non numeric values in the column.
    """  # noqa: E501

    if not is_numeric_dtype(df[column_name]):
        raise ValueError(
            "There are non-numeric values in the column. \
    All values must be numeric"
        )

    df[column_name] = pd.TimedeltaIndex(
        df[column_name], unit="d"
    ) + dt.datetime(
        1899, 12, 30
    )  # noqa: W503
    return df
</code></pre>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.convert_date.convert_matlab_date" class="doc doc-heading">
<code class="highlight language-python">convert_matlab_date(df, column_name)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Convert Matlab's serial date number into Python datetime format.</p>
<p>Implementation is also from
<a href="https://stackoverflow.com/questions/13965740/converting-matlabs-datenum-format-to-python">Stack Overflow</a></p>
<p>This method mutates the original DataFrame.</p>
<p>Method chaining syntax:</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({"date": [737125.0, 737124.815863, 737124.4985, 737124]})
&gt;&gt;&gt; df
            date
0  737125.000000
1  737124.815863
2  737124.498500
3  737124.000000
&gt;&gt;&gt; df.convert_matlab_date('date')
                        date
0 2018-03-06 00:00:00.000000
1 2018-03-05 19:34:50.563200
2 2018-03-05 11:57:50.399999
3 2018-03-05 00:00:00.000000


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A pandas DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>column_name</code></td>
        <td><code>Hashable</code></td>
        <td><p>A column name.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame with corrected dates.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/convert_date.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
@deprecated_alias(column="column_name")
def convert_matlab_date(
    df: pd.DataFrame, column_name: Hashable
) -&gt; pd.DataFrame:
    """
    Convert Matlab's serial date number into Python datetime format.

    Implementation is also from
    [Stack Overflow](https://stackoverflow.com/questions/13965740/converting-matlabs-datenum-format-to-python)

    This method mutates the original DataFrame.

    Method chaining syntax:

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({"date": [737125.0, 737124.815863, 737124.4985, 737124]})
        &gt;&gt;&gt; df
                    date
        0  737125.000000
        1  737124.815863
        2  737124.498500
        3  737124.000000
        &gt;&gt;&gt; df.convert_matlab_date('date')
                                date
        0 2018-03-06 00:00:00.000000
        1 2018-03-05 19:34:50.563200
        2 2018-03-05 11:57:50.399999
        3 2018-03-05 00:00:00.000000

    :param df: A pandas DataFrame.
    :param column_name: A column name.
    :returns: A pandas DataFrame with corrected dates.
    """  # noqa: E501
    days = pd.Series([dt.timedelta(v % 1) for v in df[column_name]])
    df[column_name] = (
        df[column_name].astype(int).apply(dt.datetime.fromordinal)
        + days
        - dt.timedelta(days=366)
    )
    return df
</code></pre>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.convert_date.convert_unix_date" class="doc doc-heading">
<code class="highlight language-python">convert_unix_date(df, column_name)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Convert unix epoch time into Python datetime format.</p>
<p>Note that this ignores local tz and convert all timestamps to naive
datetime based on UTC!</p>
<p>This method mutates the original DataFrame.</p>
<p>Method chaining syntax:</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({"date": [1651510462, 53394822, 1126233195]})
&gt;&gt;&gt; df
         date
0  1651510462
1    53394822
2  1126233195
&gt;&gt;&gt; df.convert_unix_date('date')
                 date
0 2022-05-02 16:54:22
1 1971-09-10 23:53:42
2 2005-09-09 02:33:15


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A pandas DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>column_name</code></td>
        <td><code>Hashable</code></td>
        <td><p>A column name.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame with corrected dates.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/convert_date.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
@deprecated_alias(column="column_name")
def convert_unix_date(df: pd.DataFrame, column_name: Hashable) -&gt; pd.DataFrame:
    """
    Convert unix epoch time into Python datetime format.

    Note that this ignores local tz and convert all timestamps to naive
    datetime based on UTC!

    This method mutates the original DataFrame.

    Method chaining syntax:

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({"date": [1651510462, 53394822, 1126233195]})
        &gt;&gt;&gt; df
                 date
        0  1651510462
        1    53394822
        2  1126233195
        &gt;&gt;&gt; df.convert_unix_date('date')
                         date
        0 2022-05-02 16:54:22
        1 1971-09-10 23:53:42
        2 2005-09-09 02:33:15

    :param df: A pandas DataFrame.
    :param column_name: A column name.
    :returns: A pandas DataFrame with corrected dates.
    """

    try:
        df[column_name] = pd.to_datetime(df[column_name], unit="s")
    except OutOfBoundsDatetime:  # Indicates time is in milliseconds.
        df[column_name] = pd.to_datetime(df[column_name], unit="ms")
    return df
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.count_cumulative_unique" class="doc doc-heading">
        <code>count_cumulative_unique</code>



</h2>

    <div class="doc doc-contents ">

      <p>Implementation of count_cumulative_unique.</p>



  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.count_cumulative_unique.count_cumulative_unique" class="doc doc-heading">
<code class="highlight language-python">count_cumulative_unique(df, column_name, dest_column_name, case_sensitive=True)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Generates a running total of cumulative unique values in a given column.</p>
<p>A new column will be created containing a running
count of unique values in the specified column.
If <code>case_sensitive</code> is <code>True</code>, then the case of
any letters will matter (i.e., <code>a != A</code>);
otherwise, the case of any letters will not matter.</p>
<p>This method does not mutate the original DataFrame.</p>
<p>Examples:</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({
...     "letters": list("aabABb"),
...     "numbers": range(4, 10),
... })
&gt;&gt;&gt; df
  letters  numbers
0       a        4
1       a        5
2       b        6
3       A        7
4       B        8
5       b        9
&gt;&gt;&gt; df.count_cumulative_unique(
...     column_name="letters",
...     dest_column_name="letters_unique_count",
... )
  letters  numbers  letters_unique_count
0       a        4                     1
1       a        5                     1
2       b        6                     2
3       A        7                     3
4       B        8                     4
5       b        9                     4
</code></pre>
<p>Example: Cumulative counts, ignoring casing.</p>
<pre class="highlight"><code>&gt;&gt;&gt; df.count_cumulative_unique(
...     column_name="letters",
...     dest_column_name="letters_unique_count",
...     case_sensitive=False,
... )
  letters  numbers  letters_unique_count
0       a        4                     1
1       a        5                     1
2       b        6                     2
3       A        7                     2
4       B        8                     2
5       b        9                     2


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A pandas DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>column_name</code></td>
        <td><code>Hashable</code></td>
        <td><p>Name of the column containing values from which a running count of unique values will be created.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>dest_column_name</code></td>
        <td><code>str</code></td>
        <td><p>The name of the new column containing the cumulative count of unique values that will be created.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>case_sensitive</code></td>
        <td><code>bool</code></td>
        <td><p>Whether or not uppercase and lowercase letters will be considered equal. Only valid with string-like columns.</p></td>
        <td><code>True</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame with a new column containing a cumulative count of unique values from another column.</p></td>
    </tr>
  </tbody>
</table>
<p><strong>Exceptions:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>TypeError</code></td>
        <td><p>If <code>case_sensitive</code> is False when counting a non-string <code>column_name</code>.</p></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/count_cumulative_unique.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
def count_cumulative_unique(
    df: pd.DataFrame,
    column_name: Hashable,
    dest_column_name: str,
    case_sensitive: bool = True,
) -&gt; pd.DataFrame:
    """Generates a running total of cumulative unique values in a given column.

    A new column will be created containing a running
    count of unique values in the specified column.
    If `case_sensitive` is `True`, then the case of
    any letters will matter (i.e., `a != A`);
    otherwise, the case of any letters will not matter.

    This method does not mutate the original DataFrame.

    Examples:

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({
        ...     "letters": list("aabABb"),
        ...     "numbers": range(4, 10),
        ... })
        &gt;&gt;&gt; df
          letters  numbers
        0       a        4
        1       a        5
        2       b        6
        3       A        7
        4       B        8
        5       b        9
        &gt;&gt;&gt; df.count_cumulative_unique(
        ...     column_name="letters",
        ...     dest_column_name="letters_unique_count",
        ... )
          letters  numbers  letters_unique_count
        0       a        4                     1
        1       a        5                     1
        2       b        6                     2
        3       A        7                     3
        4       B        8                     4
        5       b        9                     4

    Example: Cumulative counts, ignoring casing.

        &gt;&gt;&gt; df.count_cumulative_unique(
        ...     column_name="letters",
        ...     dest_column_name="letters_unique_count",
        ...     case_sensitive=False,
        ... )
          letters  numbers  letters_unique_count
        0       a        4                     1
        1       a        5                     1
        2       b        6                     2
        3       A        7                     2
        4       B        8                     2
        5       b        9                     2

    :param df: A pandas DataFrame.
    :param column_name: Name of the column containing values from which a
        running count of unique values will be created.
    :param dest_column_name: The name of the new column containing the
        cumulative count of unique values that will be created.
    :param case_sensitive: Whether or not uppercase and lowercase letters
        will be considered equal. Only valid with string-like columns.
    :returns: A pandas DataFrame with a new column containing a cumulative
        count of unique values from another column.
    :raises TypeError: If `case_sensitive` is False when counting a non-string
        `column_name`.
    """
    check_column(df, column_name)
    check_column(df, dest_column_name, present=False)

    counter = df[column_name]
    if not case_sensitive:
        try:
            # Make it so that the the same uppercase and lowercase
            # letter are treated as one unique value
            counter = counter.str.lower()
        except (AttributeError, TypeError) as e:
            # AttributeError is raised by pandas when .str is used on
            # non-string types, e.g. int.
            # TypeError is raised by pandas when .str.lower is used on a
            # forbidden string type, e.g. bytes.
            raise TypeError(
                "case_sensitive=False can only be used with a string-like "
                f"type. Column {column_name} is {counter.dtype} type."
            ) from e

    counter = (
        counter.groupby(counter, sort=False).cumcount().to_numpy(copy=False)
    )
    counter = np.cumsum(counter == 0)

    return df.assign(**{dest_column_name: counter})
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.currency_column_to_numeric" class="doc doc-heading">
        <code>currency_column_to_numeric</code>



</h2>

    <div class="doc doc-contents ">




  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.currency_column_to_numeric.currency_column_to_numeric" class="doc doc-heading">
<code class="highlight language-python">currency_column_to_numeric(df, column_name, cleaning_style=None, cast_non_numeric=None, fill_all_non_numeric=None, remove_non_numeric=False)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Convert currency column to numeric.</p>
<p>This method does not mutate the original DataFrame.</p>
<p>This method allows one to take a column containing currency values,
inadvertently imported as a string, and cast it as a float. This is
usually the case when reading CSV files that were modified in Excel.
Empty strings (i.e. <code>''</code>) are retained as <code>NaN</code> values.</p>
<p>Example:</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({
...     "a_col": [" 24.56", "-", "(12.12)", "1,000,000"],
...     "d_col": ["", "foo", "1.23 dollars", "-1,000 yen"],
... })
&gt;&gt;&gt; df  # doctest: +NORMALIZE_WHITESPACE
       a_col         d_col
0      24.56
1          -           foo
2    (12.12)  1.23 dollars
3  1,000,000    -1,000 yen
</code></pre>
<p>The default cleaning style.</p>
<pre class="highlight"><code>&gt;&gt;&gt; df.currency_column_to_numeric("d_col")
       a_col    d_col
0      24.56      NaN
1          -      NaN
2    (12.12)     1.23
3  1,000,000 -1000.00
</code></pre>
<p>The accounting cleaning style.</p>
<pre class="highlight"><code>&gt;&gt;&gt; df.currency_column_to_numeric("a_col", cleaning_style="accounting")  # doctest: +NORMALIZE_WHITESPACE
        a_col         d_col
0       24.56
1        0.00           foo
2      -12.12  1.23 dollars
3  1000000.00    -1,000 yen
</code></pre>
<p>Valid cleaning styles are:</p>
<ul>
<li><code>None</code>: Default cleaning is applied. Empty strings are always retained as
    <code>NaN</code>. Numbers, <code>-</code>, <code>.</code> are extracted and the resulting string
    is cast to a float.</li>
<li><code>'accounting'</code>: Replaces numbers in parentheses with negatives, removes commas.</li>
</ul>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>The pandas DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>column_name</code></td>
        <td><code>str</code></td>
        <td><p>The column containing currency values to modify.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>cleaning_style</code></td>
        <td><code>Optional[str]</code></td>
        <td><p>What style of cleaning to perform.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>cast_non_numeric</code></td>
        <td><code>Optional[dict]</code></td>
        <td><p>A dict of how to coerce certain strings to numeric type. For example, if there are values of 'REORDER' in the DataFrame, <code>{'REORDER': 0}</code> will cast all instances of 'REORDER' to 0. Only takes effect in the default cleaning style.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>fill_all_non_numeric</code></td>
        <td><code>Union[float, int]</code></td>
        <td><p>Similar to <code>cast_non_numeric</code>, but fills all strings to the same value. For example, <code>fill_all_non_numeric=1</code>, will make everything that doesn't coerce to a currency <code>1</code>. Only takes effect in the default cleaning style.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>remove_non_numeric</code></td>
        <td><code>bool</code></td>
        <td><p>If set to True, rows of <code>df</code> that contain non-numeric values in the <code>column_name</code> column will be removed. Only takes effect in the default cleaning style.</p></td>
        <td><code>False</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame.</p></td>
    </tr>
  </tbody>
</table>
<p><strong>Exceptions:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>ValueError</code></td>
        <td><p>If <code>cleaning_style</code> is not one of the accepted styles.</p></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/currency_column_to_numeric.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
@deprecated_alias(col_name="column_name", type="cleaning_style")
def currency_column_to_numeric(
    df: pd.DataFrame,
    column_name: str,
    cleaning_style: Optional[str] = None,
    cast_non_numeric: Optional[dict] = None,
    fill_all_non_numeric: Optional[Union[float, int]] = None,
    remove_non_numeric: bool = False,
) -&gt; pd.DataFrame:
    """Convert currency column to numeric.

    This method does not mutate the original DataFrame.

    This method allows one to take a column containing currency values,
    inadvertently imported as a string, and cast it as a float. This is
    usually the case when reading CSV files that were modified in Excel.
    Empty strings (i.e. `''`) are retained as `NaN` values.

    Example:

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({
        ...     "a_col": [" 24.56", "-", "(12.12)", "1,000,000"],
        ...     "d_col": ["", "foo", "1.23 dollars", "-1,000 yen"],
        ... })
        &gt;&gt;&gt; df  # doctest: +NORMALIZE_WHITESPACE
               a_col         d_col
        0      24.56
        1          -           foo
        2    (12.12)  1.23 dollars
        3  1,000,000    -1,000 yen

    The default cleaning style.

        &gt;&gt;&gt; df.currency_column_to_numeric("d_col")
               a_col    d_col
        0      24.56      NaN
        1          -      NaN
        2    (12.12)     1.23
        3  1,000,000 -1000.00

    The accounting cleaning style.

        &gt;&gt;&gt; df.currency_column_to_numeric("a_col", cleaning_style="accounting")  # doctest: +NORMALIZE_WHITESPACE
                a_col         d_col
        0       24.56
        1        0.00           foo
        2      -12.12  1.23 dollars
        3  1000000.00    -1,000 yen

    Valid cleaning styles are:

    - `None`: Default cleaning is applied. Empty strings are always retained as
        `NaN`. Numbers, `-`, `.` are extracted and the resulting string
        is cast to a float.
    - `'accounting'`: Replaces numbers in parentheses with negatives, removes commas.

    :param df: The pandas DataFrame.
    :param column_name: The column containing currency values to modify.
    :param cleaning_style: What style of cleaning to perform.
    :param cast_non_numeric: A dict of how to coerce certain strings to numeric
        type. For example, if there are values of 'REORDER' in the DataFrame,
        `{'REORDER': 0}` will cast all instances of 'REORDER' to 0.
        Only takes effect in the default cleaning style.
    :param fill_all_non_numeric: Similar to `cast_non_numeric`, but fills all
        strings to the same value. For example, `fill_all_non_numeric=1`, will
        make everything that doesn't coerce to a currency `1`.
        Only takes effect in the default cleaning style.
    :param remove_non_numeric: If set to True, rows of `df` that contain
        non-numeric values in the `column_name` column will be removed.
        Only takes effect in the default cleaning style.
    :raises ValueError: If `cleaning_style` is not one of the accepted styles.
    :returns: A pandas DataFrame.
    """  # noqa: E501

    check("column_name", column_name, [str])
    check_column(df, column_name)

    column_series = df[column_name]
    if cleaning_style == "accounting":
        df.loc[:, column_name] = df[column_name].apply(
            _clean_accounting_column
        )
        return df
    if cleaning_style is not None:
        raise ValueError(
            "`cleaning_style` is expected to be one of ('accounting', None). "
            f"Got {cleaning_style!r} instead."
        )

    if cast_non_numeric:
        check("cast_non_numeric", cast_non_numeric, [dict])

    _make_cc_patrial = partial(
        _currency_column_to_numeric,
        cast_non_numeric=cast_non_numeric,
    )
    column_series = column_series.apply(_make_cc_patrial)

    if remove_non_numeric:
        df = df.loc[column_series != "", :]

    # _replace_empty_string_with_none is applied here after the check on
    # remove_non_numeric since "" is our indicator that a string was coerced
    # in the original column
    column_series = _replace_empty_string_with_none(column_series)

    if fill_all_non_numeric is not None:
        check("fill_all_non_numeric", fill_all_non_numeric, [int, float])
        column_series = column_series.fillna(fill_all_non_numeric)

    column_series = _replace_original_empty_string_with_none(column_series)

    df = df.assign(**{column_name: pd.to_numeric(column_series)})

    return df
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.deconcatenate_column" class="doc doc-heading">
        <code>deconcatenate_column</code>



</h2>

    <div class="doc doc-contents ">

      <p>Implementation of deconcatenating columns.</p>



  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.deconcatenate_column.deconcatenate_column" class="doc doc-heading">
<code class="highlight language-python">deconcatenate_column(df, column_name, sep=None, new_column_names=None, autoname=None, preserve_position=False)</code>


</h3>

    <div class="doc doc-contents ">

      <p>De-concatenates a single column into multiple columns.</p>
<p>The column to de-concatenate can be either a collection (list, tuple, ...)
which can be separated out with <code>pd.Series.tolist()</code>,
or a string to slice based on <code>sep</code>.</p>
<p>To determine this behaviour automatically,
the first element in the column specified is inspected.</p>
<p>If it is a string, then <code>sep</code> must be specified.
Else, the function assumes that it is an iterable type
(e.g. <code>list</code> or <code>tuple</code>),
and will attempt to deconcatenate by splitting the list.</p>
<p>Given a column with string values, this is the inverse of the
<a class="autorefs autorefs-internal" href="#janitor.functions.concatenate_columns.concatenate_columns"><code>concatenate_columns</code></a>
function.</p>
<p>Used to quickly split columns out of a single column.</p>
<p>Example:</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({"m": ["1-x", "2-y", "3-z"]})
&gt;&gt;&gt; df
     m
0  1-x
1  2-y
2  3-z
&gt;&gt;&gt; df.deconcatenate_column("m", sep="-", autoname="col")
     m col1 col2
0  1-x    1    x
1  2-y    2    y
2  3-z    3    z
</code></pre>
<p>The keyword argument <code>preserve_position</code>
takes <code>True</code> or <code>False</code> boolean
that controls whether the <code>new_column_names</code>
will take the original position
of the to-be-deconcatenated <code>column_name</code>:</p>
<ul>
<li>When <code>preserve_position=False</code> (default), <code>df.columns</code> change from
  <code>[..., column_name, ...]</code> to <code>[..., column_name, ..., new_column_names]</code>.
  In other words, the deconcatenated new columns are appended to the right
  of the original dataframe and the original <code>column_name</code> is NOT dropped.</li>
<li>When <code>preserve_position=True</code>, <code>df.column</code> change from
  <code>[..., column_name, ...]</code> to <code>[..., new_column_names, ...]</code>.
  In other words, the deconcatenated new column will REPLACE the original
  <code>column_name</code> at its original position, and <code>column_name</code> itself
  is dropped.</li>
</ul>
<p>The keyword argument <code>autoname</code> accepts a base string
and then automatically creates numbered column names
based off the base string.
For example, if <code>col</code> is passed in as the argument to <code>autoname</code>,
and 4 columns are created, then the resulting columns will be named
<code>col1, col2, col3, col4</code>.
Numbering is always 1-indexed, not 0-indexed,
in order to make the column names human-friendly.</p>
<p>This method does not mutate the original DataFrame.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A pandas DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>column_name</code></td>
        <td><code>Hashable</code></td>
        <td><p>The column to split.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>sep</code></td>
        <td><code>Optional[str]</code></td>
        <td><p>The separator delimiting the column's data.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>new_column_names</code></td>
        <td><code>Union[List[str], Tuple[str]]</code></td>
        <td><p>A list of new column names post-splitting.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>autoname</code></td>
        <td><code>str</code></td>
        <td><p>A base name for automatically naming the new columns. Takes precedence over <code>new_column_names</code> if both are provided.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>preserve_position</code></td>
        <td><code>bool</code></td>
        <td><p>Boolean for whether or not to preserve original position of the column upon de-concatenation.</p></td>
        <td><code>False</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame with a deconcatenated column.</p></td>
    </tr>
  </tbody>
</table>
<p><strong>Exceptions:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>ValueError</code></td>
        <td><p>If <code>column_name</code> is not present in the DataFrame.</p></td>
      </tr>
      <tr>
        <td><code>ValueError</code></td>
        <td><p>If <code>sep</code> is not provided and the column values are of type <code>str</code>.</p></td>
      </tr>
      <tr>
        <td><code>ValueError</code></td>
        <td><p>If either <code>new_column_names</code> or <code>autoname</code> is not supplied.</p></td>
      </tr>
      <tr>
        <td><code>JanitorError</code></td>
        <td><p>If incorrect number of names is provided within <code>new_column_names</code>.</p></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/deconcatenate_column.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
@deprecated_alias(column="column_name")
def deconcatenate_column(
    df: pd.DataFrame,
    column_name: Hashable,
    sep: Optional[str] = None,
    new_column_names: Optional[Union[List[str], Tuple[str]]] = None,
    autoname: str = None,
    preserve_position: bool = False,
) -&gt; pd.DataFrame:
    """De-concatenates a single column into multiple columns.

    The column to de-concatenate can be either a collection (list, tuple, ...)
    which can be separated out with `pd.Series.tolist()`,
    or a string to slice based on `sep`.

    To determine this behaviour automatically,
    the first element in the column specified is inspected.

    If it is a string, then `sep` must be specified.
    Else, the function assumes that it is an iterable type
    (e.g. `list` or `tuple`),
    and will attempt to deconcatenate by splitting the list.

    Given a column with string values, this is the inverse of the
    [`concatenate_columns`][janitor.functions.concatenate_columns.concatenate_columns]
    function.

    Used to quickly split columns out of a single column.

    Example:

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({"m": ["1-x", "2-y", "3-z"]})
        &gt;&gt;&gt; df
             m
        0  1-x
        1  2-y
        2  3-z
        &gt;&gt;&gt; df.deconcatenate_column("m", sep="-", autoname="col")
             m col1 col2
        0  1-x    1    x
        1  2-y    2    y
        2  3-z    3    z

    The keyword argument `preserve_position`
    takes `True` or `False` boolean
    that controls whether the `new_column_names`
    will take the original position
    of the to-be-deconcatenated `column_name`:

    - When `preserve_position=False` (default), `df.columns` change from
      `[..., column_name, ...]` to `[..., column_name, ..., new_column_names]`.
      In other words, the deconcatenated new columns are appended to the right
      of the original dataframe and the original `column_name` is NOT dropped.
    - When `preserve_position=True`, `df.column` change from
      `[..., column_name, ...]` to `[..., new_column_names, ...]`.
      In other words, the deconcatenated new column will REPLACE the original
      `column_name` at its original position, and `column_name` itself
      is dropped.

    The keyword argument `autoname` accepts a base string
    and then automatically creates numbered column names
    based off the base string.
    For example, if `col` is passed in as the argument to `autoname`,
    and 4 columns are created, then the resulting columns will be named
    `col1, col2, col3, col4`.
    Numbering is always 1-indexed, not 0-indexed,
    in order to make the column names human-friendly.

    This method does not mutate the original DataFrame.

    :param df: A pandas DataFrame.
    :param column_name: The column to split.
    :param sep: The separator delimiting the column's data.
    :param new_column_names: A list of new column names post-splitting.
    :param autoname: A base name for automatically naming the new columns.
        Takes precedence over `new_column_names` if both are provided.
    :param preserve_position: Boolean for whether or not to preserve original
        position of the column upon de-concatenation.
    :returns: A pandas DataFrame with a deconcatenated column.
    :raises ValueError: If `column_name` is not present in the
        DataFrame.
    :raises ValueError: If `sep` is not provided and the column values
        are of type `str`.
    :raises ValueError: If either `new_column_names` or `autoname`
        is not supplied.
    :raises JanitorError: If incorrect number of names is provided
        within `new_column_names`.
    """  # noqa: E501

    if column_name not in df.columns:
        raise ValueError(f"column name {column_name} not present in DataFrame")

    if isinstance(df[column_name].iloc[0], str):
        if sep is None:
            raise ValueError(
                "`sep` must be specified if the column values "
                "are of type `str`."
            )
        df_deconcat = df[column_name].str.split(sep, expand=True)
    else:
        df_deconcat = pd.DataFrame(
            df[column_name].to_list(), columns=new_column_names, index=df.index
        )

    if new_column_names is None and autoname is None:
        raise ValueError(
            "One of `new_column_names` or `autoname` must be supplied."
        )

    if autoname:
        new_column_names = [
            f"{autoname}{i}" for i in range(1, df_deconcat.shape[1] + 1)
        ]

    if not len(new_column_names) == df_deconcat.shape[1]:
        raise JanitorError(
            f"You need to provide {len(df_deconcat.shape[1])} names "
            "to `new_column_names`"
        )

    df_deconcat.columns = new_column_names
    df_new = pd.concat([df, df_deconcat], axis=1)

    if preserve_position:
        df_original = df.copy()
        cols = list(df_original.columns)
        index_original = cols.index(column_name)

        for i, col_new in enumerate(new_column_names):
            cols.insert(index_original + i, col_new)

        df_new = df_new.select_columns(cols).drop(columns=column_name)

    return df_new
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.drop_constant_columns" class="doc doc-heading">
        <code>drop_constant_columns</code>



</h2>

    <div class="doc doc-contents ">

      <p>Implementation of drop_constant_columns.</p>



  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.drop_constant_columns.drop_constant_columns" class="doc doc-heading">
<code class="highlight language-python">drop_constant_columns(df)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Finds and drops the constant columns from a Pandas DataFrame.</p>
<p>Example:</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; data_dict = {
...     "a": [1, 1, 1],
...     "b": [1, 2, 3],
...     "c": [1, 1, 1],
...     "d": ["rabbit", "leopard", "lion"],
...     "e": ["Cambridge", "Shanghai", "Basel"]
... }
&gt;&gt;&gt; df = pd.DataFrame(data_dict)
&gt;&gt;&gt; df
   a  b  c        d          e
0  1  1  1   rabbit  Cambridge
1  1  2  1  leopard   Shanghai
2  1  3  1     lion      Basel
&gt;&gt;&gt; df.drop_constant_columns()
   b        d          e
0  1   rabbit  Cambridge
1  2  leopard   Shanghai
2  3     lion      Basel


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>Input Pandas DataFrame</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>The Pandas DataFrame with the constant columns dropped.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/drop_constant_columns.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
def drop_constant_columns(df: pd.DataFrame) -&gt; pd.DataFrame:
    """
    Finds and drops the constant columns from a Pandas DataFrame.

    Example:

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; data_dict = {
        ...     "a": [1, 1, 1],
        ...     "b": [1, 2, 3],
        ...     "c": [1, 1, 1],
        ...     "d": ["rabbit", "leopard", "lion"],
        ...     "e": ["Cambridge", "Shanghai", "Basel"]
        ... }
        &gt;&gt;&gt; df = pd.DataFrame(data_dict)
        &gt;&gt;&gt; df
           a  b  c        d          e
        0  1  1  1   rabbit  Cambridge
        1  1  2  1  leopard   Shanghai
        2  1  3  1     lion      Basel
        &gt;&gt;&gt; df.drop_constant_columns()
           b        d          e
        0  1   rabbit  Cambridge
        1  2  leopard   Shanghai
        2  3     lion      Basel

    :param df: Input Pandas DataFrame
    :returns: The Pandas DataFrame with the constant columns dropped.
    """
    # Find the constant columns
    constant_columns = []
    for col in df.columns:
        if len(df[col].unique()) == 1:
            constant_columns.append(col)

    # Drop constant columns from df and return it
    return df.drop(labels=constant_columns, axis=1)
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.drop_duplicate_columns" class="doc doc-heading">
        <code>drop_duplicate_columns</code>



</h2>

    <div class="doc doc-contents ">

      <p>Implementation for drop_duplicate_columns.</p>



  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.drop_duplicate_columns.drop_duplicate_columns" class="doc doc-heading">
<code class="highlight language-python">drop_duplicate_columns(df, column_name, nth_index=0)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Remove a duplicated column specified by <code>column_name</code>.</p>
<p>Specifying <code>nth_index=0</code> will remove the first column,
<code>nth_index=1</code> will remove the second column,
and so on and so forth.</p>
<p>The corresponding tidyverse R's library is:
<code>select(-&lt;column_name&gt;_&lt;nth_index + 1&gt;)</code></p>
<p>Example:</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({
...     "a": range(2, 5),
...     "b": range(3, 6),
...     "A": range(4, 7),
...     "a*": range(6, 9),
... }).clean_names(remove_special=True)
&gt;&gt;&gt; df
   a  b  a  a
0  2  3  4  6
1  3  4  5  7
2  4  5  6  8
&gt;&gt;&gt; df.drop_duplicate_columns(column_name="a", nth_index=1)
   a  b  a
0  2  3  6
1  3  4  7
2  4  5  8


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A pandas DataFrame</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>column_name</code></td>
        <td><code>Hashable</code></td>
        <td><p>Name of duplicated columns.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>nth_index</code></td>
        <td><code>int</code></td>
        <td><p>Among the duplicated columns, select the nth column to drop.</p></td>
        <td><code>0</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/drop_duplicate_columns.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
def drop_duplicate_columns(
    df: pd.DataFrame, column_name: Hashable, nth_index: int = 0
) -&gt; pd.DataFrame:
    """Remove a duplicated column specified by `column_name`.

    Specifying `nth_index=0` will remove the first column,
    `nth_index=1` will remove the second column,
    and so on and so forth.

    The corresponding tidyverse R's library is:
    `select(-&lt;column_name&gt;_&lt;nth_index + 1&gt;)`

    Example:

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({
        ...     "a": range(2, 5),
        ...     "b": range(3, 6),
        ...     "A": range(4, 7),
        ...     "a*": range(6, 9),
        ... }).clean_names(remove_special=True)
        &gt;&gt;&gt; df
           a  b  a  a
        0  2  3  4  6
        1  3  4  5  7
        2  4  5  6  8
        &gt;&gt;&gt; df.drop_duplicate_columns(column_name="a", nth_index=1)
           a  b  a
        0  2  3  6
        1  3  4  7
        2  4  5  8

    :param df: A pandas DataFrame
    :param column_name: Name of duplicated columns.
    :param nth_index: Among the duplicated columns,
        select the nth column to drop.
    :return: A pandas DataFrame
    """
    col_indexes = [
        col_idx
        for col_idx, col_name in enumerate(df.columns)
        if col_name == column_name
    ]

    # Select the column to remove based on nth_index.
    removed_col_idx = col_indexes[nth_index]
    # Filter out columns except for the one to be removed.
    filtered_cols = [
        c_i for c_i, _ in enumerate(df.columns) if c_i != removed_col_idx
    ]

    return df.iloc[:, filtered_cols]
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.dropnotnull" class="doc doc-heading">
        <code>dropnotnull</code>



</h2>

    <div class="doc doc-contents ">




  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.dropnotnull.dropnotnull" class="doc doc-heading">
<code class="highlight language-python">dropnotnull(df, column_name)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Drop rows that do <em>not</em> have null values in the given column.</p>
<p>This method does not mutate the original DataFrame.</p>
<p>Example:</p>
<pre class="highlight"><code>&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({"a": [1., np.NaN, 3.], "b": [None, "y", "z"]})
&gt;&gt;&gt; df
     a     b
0  1.0  None
1  NaN     y
2  3.0     z
&gt;&gt;&gt; df.dropnotnull("a")
    a  b
1 NaN  y
&gt;&gt;&gt; df.dropnotnull("b")
     a     b
0  1.0  None


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A pandas DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>column_name</code></td>
        <td><code>Hashable</code></td>
        <td><p>The column name to drop rows from.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame with dropped rows.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/dropnotnull.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
@deprecated_alias(column="column_name")
def dropnotnull(df: pd.DataFrame, column_name: Hashable) -&gt; pd.DataFrame:
    """Drop rows that do *not* have null values in the given column.

    This method does not mutate the original DataFrame.

    Example:

        &gt;&gt;&gt; import numpy as np
        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({"a": [1., np.NaN, 3.], "b": [None, "y", "z"]})
        &gt;&gt;&gt; df
             a     b
        0  1.0  None
        1  NaN     y
        2  3.0     z
        &gt;&gt;&gt; df.dropnotnull("a")
            a  b
        1 NaN  y
        &gt;&gt;&gt; df.dropnotnull("b")
             a     b
        0  1.0  None

    :param df: A pandas DataFrame.
    :param column_name: The column name to drop rows from.
    :returns: A pandas DataFrame with dropped rows.
    """
    return df[pd.isna(df[column_name])]
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.encode_categorical" class="doc doc-heading">
        <code>encode_categorical</code>



</h2>

    <div class="doc doc-contents ">




  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.encode_categorical.encode_categorical" class="doc doc-heading">
<code class="highlight language-python">encode_categorical(df, column_names=None, **kwargs)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Encode the specified columns with Pandas' <a href="http://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html">category dtype</a>.</p>
<p>It is syntactic sugar around <code>pd.Categorical</code>.</p>
<p>This method does not mutate the original DataFrame.</p>
<p>Simply pass a string, or a sequence of column names to <code>column_names</code>;
alternatively, you can pass kwargs, where the keys are the column names
and the values can either be None, <code>sort</code>, <code>appearance</code>
or a 1-D array-like object.</p>
<ul>
<li>None: column is cast to an unordered categorical.</li>
<li><code>sort</code>: column is cast to an ordered categorical,
          with the order defined by the sort-order of the categories.</li>
<li><code>appearance</code>: column is cast to an ordered categorical,
                with the order defined by the order of appearance
                in the original column.</li>
<li>1d-array-like object: column is cast to an ordered categorical,
                        with the categories and order as specified
                        in the input array.</li>
</ul>
<p><code>column_names</code> and <code>kwargs</code> parameters cannot be used at the same time.</p>
<p>Example: Using <code>column_names</code></p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({
...     "foo": ["b", "b", "a", "c", "b"],
...     "bar": range(4, 9),
... })
&gt;&gt;&gt; df
  foo  bar
0   b    4
1   b    5
2   a    6
3   c    7
4   b    8
&gt;&gt;&gt; df.dtypes
foo    object
bar     int64
dtype: object
&gt;&gt;&gt; enc_df = df.encode_categorical(column_names="foo")
&gt;&gt;&gt; enc_df.dtypes
foo    category
bar       int64
dtype: object
&gt;&gt;&gt; enc_df["foo"].cat.categories
Index(['a', 'b', 'c'], dtype='object')
&gt;&gt;&gt; enc_df["foo"].cat.ordered
False
</code></pre>
<p>Example: Using <code>kwargs</code> to specify an ordered categorical.</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({
...     "foo": ["b", "b", "a", "c", "b"],
...     "bar": range(4, 9),
... })
&gt;&gt;&gt; df.dtypes
foo    object
bar     int64
dtype: object
&gt;&gt;&gt; enc_df = df.encode_categorical(foo="appearance")
&gt;&gt;&gt; enc_df.dtypes
foo    category
bar       int64
dtype: object
&gt;&gt;&gt; enc_df["foo"].cat.categories
Index(['b', 'a', 'c'], dtype='object')
&gt;&gt;&gt; enc_df["foo"].cat.ordered
True


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A pandas DataFrame object.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>column_names</code></td>
        <td><code>Union[str, Iterable[str], Hashable]</code></td>
        <td><p>A column name or an iterable (list or tuple) of column names.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>**kwargs</code></td>
        <td></td>
        <td><p>A mapping from column name to either <code>None</code>, <code>'sort'</code> or <code>'appearance'</code>, or a 1-D array. This is useful in creating categorical columns that are ordered, or if the user needs to explicitly specify the categories.</p></td>
        <td><code>{}</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame.</p></td>
    </tr>
  </tbody>
</table>
<p><strong>Exceptions:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>ValueError</code></td>
        <td><p>If both <code>column_names</code> and <code>kwargs</code> are provided.</p></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/encode_categorical.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
@deprecated_alias(columns="column_names")
def encode_categorical(
    df: pd.DataFrame,
    column_names: Union[str, Iterable[str], Hashable] = None,
    **kwargs,
) -&gt; pd.DataFrame:
    """Encode the specified columns with Pandas' [category dtype][cat].

    [cat]: http://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html

    It is syntactic sugar around `pd.Categorical`.

    This method does not mutate the original DataFrame.

    Simply pass a string, or a sequence of column names to `column_names`;
    alternatively, you can pass kwargs, where the keys are the column names
    and the values can either be None, `sort`, `appearance`
    or a 1-D array-like object.

    - None: column is cast to an unordered categorical.
    - `sort`: column is cast to an ordered categorical,
              with the order defined by the sort-order of the categories.
    - `appearance`: column is cast to an ordered categorical,
                    with the order defined by the order of appearance
                    in the original column.
    - 1d-array-like object: column is cast to an ordered categorical,
                            with the categories and order as specified
                            in the input array.

    `column_names` and `kwargs` parameters cannot be used at the same time.

    Example: Using `column_names`

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({
        ...     "foo": ["b", "b", "a", "c", "b"],
        ...     "bar": range(4, 9),
        ... })
        &gt;&gt;&gt; df
          foo  bar
        0   b    4
        1   b    5
        2   a    6
        3   c    7
        4   b    8
        &gt;&gt;&gt; df.dtypes
        foo    object
        bar     int64
        dtype: object
        &gt;&gt;&gt; enc_df = df.encode_categorical(column_names="foo")
        &gt;&gt;&gt; enc_df.dtypes
        foo    category
        bar       int64
        dtype: object
        &gt;&gt;&gt; enc_df["foo"].cat.categories
        Index(['a', 'b', 'c'], dtype='object')
        &gt;&gt;&gt; enc_df["foo"].cat.ordered
        False

    Example: Using `kwargs` to specify an ordered categorical.

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({
        ...     "foo": ["b", "b", "a", "c", "b"],
        ...     "bar": range(4, 9),
        ... })
        &gt;&gt;&gt; df.dtypes
        foo    object
        bar     int64
        dtype: object
        &gt;&gt;&gt; enc_df = df.encode_categorical(foo="appearance")
        &gt;&gt;&gt; enc_df.dtypes
        foo    category
        bar       int64
        dtype: object
        &gt;&gt;&gt; enc_df["foo"].cat.categories
        Index(['b', 'a', 'c'], dtype='object')
        &gt;&gt;&gt; enc_df["foo"].cat.ordered
        True

    :param df: A pandas DataFrame object.
    :param column_names: A column name or an iterable (list or tuple)
        of column names.
    :param **kwargs: A mapping from column name to either `None`,
        `'sort'` or `'appearance'`, or a 1-D array. This is useful
        in creating categorical columns that are ordered, or
        if the user needs to explicitly specify the categories.
    :returns: A pandas DataFrame.
    :raises ValueError: If both `column_names` and `kwargs` are provided.
    """  # noqa: E501

    if all((column_names, kwargs)):
        raise ValueError(
            "Only one of `column_names` or `kwargs` can be provided."
        )
    # column_names deal with only category dtype (unordered)
    # kwargs takes care of scenarios where user wants an ordered category
    # or user supplies specific categories to create the categorical
    if column_names is not None:
        check("column_names", column_names, [list, tuple, Hashable])
        if isinstance(column_names, Hashable):
            column_names = [column_names]
        check_column(df, column_names)
        dtypes = {col: "category" for col in column_names}
        return df.astype(dtypes)

    return _computations_as_categorical(df, **kwargs)
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.expand_column" class="doc doc-heading">
        <code>expand_column</code>



</h2>

    <div class="doc doc-contents ">

      <p>Implementation for expand_column.</p>



  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.expand_column.expand_column" class="doc doc-heading">
<code class="highlight language-python">expand_column(df, column_name, sep='|', concat=True)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Expand a categorical column with multiple labels into dummy-coded columns.</p>
<p>Super sugary syntax that wraps :py:meth:<code>pandas.Series.str.get_dummies</code>.</p>
<p>This method does not mutate the original DataFrame.</p>
<p>Functional usage syntax:</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; df = pd.DataFrame(
...     {
...         "col1": ["A, B", "B, C, D", "E, F", "A, E, F"],
...         "col2": [1, 2, 3, 4],
...     }
... )
&gt;&gt;&gt; df = expand_column(
...     df,
...     column_name="col1",
...     sep=", "  # note space in sep
... )
&gt;&gt;&gt; df
      col1  col2  A  B  C  D  E  F
0     A, B     1  1  1  0  0  0  0
1  B, C, D     2  0  1  1  1  0  0
2     E, F     3  0  0  0  0  1  1
3  A, E, F     4  1  0  0  0  1  1
</code></pre>
<p>Method chaining syntax:</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = (
...     pd.DataFrame(
...         {
...             "col1": ["A, B", "B, C, D", "E, F", "A, E, F"],
...             "col2": [1, 2, 3, 4],
...         }
...     )
...     .expand_column(
...         column_name='col1',
...         sep=', '
...     )
... )
&gt;&gt;&gt; df
      col1  col2  A  B  C  D  E  F
0     A, B     1  1  1  0  0  0  0
1  B, C, D     2  0  1  1  1  0  0
2     E, F     3  0  0  0  0  1  1
3  A, E, F     4  1  0  0  0  1  1


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A pandas DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>column_name</code></td>
        <td><code>Hashable</code></td>
        <td><p>Which column to expand.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>sep</code></td>
        <td><code>str</code></td>
        <td><p>The delimiter, same to :py:meth:<code>~pandas.Series.str.get_dummies</code>'s <code>sep</code>, default as <code>|</code>.</p></td>
        <td><code>&#39;|&#39;</code></td>
      </tr>
      <tr>
        <td><code>concat</code></td>
        <td><code>bool</code></td>
        <td><p>Whether to return the expanded column concatenated to the original dataframe (<code>concat=True</code>), or to return it standalone (<code>concat=False</code>).</p></td>
        <td><code>True</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame with an expanded column.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/expand_column.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
@deprecated_alias(column="column_name")
def expand_column(
    df: pd.DataFrame,
    column_name: Hashable,
    sep: str = "|",
    concat: bool = True,
) -&gt; pd.DataFrame:
    """Expand a categorical column with multiple labels into dummy-coded columns.

    Super sugary syntax that wraps :py:meth:`pandas.Series.str.get_dummies`.

    This method does not mutate the original DataFrame.

    Functional usage syntax:

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; df = pd.DataFrame(
        ...     {
        ...         "col1": ["A, B", "B, C, D", "E, F", "A, E, F"],
        ...         "col2": [1, 2, 3, 4],
        ...     }
        ... )
        &gt;&gt;&gt; df = expand_column(
        ...     df,
        ...     column_name="col1",
        ...     sep=", "  # note space in sep
        ... )
        &gt;&gt;&gt; df
              col1  col2  A  B  C  D  E  F
        0     A, B     1  1  1  0  0  0  0
        1  B, C, D     2  0  1  1  1  0  0
        2     E, F     3  0  0  0  0  1  1
        3  A, E, F     4  1  0  0  0  1  1

    Method chaining syntax:

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = (
        ...     pd.DataFrame(
        ...         {
        ...             "col1": ["A, B", "B, C, D", "E, F", "A, E, F"],
        ...             "col2": [1, 2, 3, 4],
        ...         }
        ...     )
        ...     .expand_column(
        ...         column_name='col1',
        ...         sep=', '
        ...     )
        ... )
        &gt;&gt;&gt; df
              col1  col2  A  B  C  D  E  F
        0     A, B     1  1  1  0  0  0  0
        1  B, C, D     2  0  1  1  1  0  0
        2     E, F     3  0  0  0  0  1  1
        3  A, E, F     4  1  0  0  0  1  1

    :param df: A pandas DataFrame.
    :param column_name: Which column to expand.
    :param sep: The delimiter, same to
        :py:meth:`~pandas.Series.str.get_dummies`'s `sep`, default as `|`.
    :param concat: Whether to return the expanded column concatenated to
        the original dataframe (`concat=True`), or to return it standalone
        (`concat=False`).
    :returns: A pandas DataFrame with an expanded column.
    """  # noqa: E501
    expanded_df = df[column_name].str.get_dummies(sep=sep)
    if concat:
        df = df.join(expanded_df)
        return df
    return expanded_df
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.expand_grid" class="doc doc-heading">
        <code>expand_grid</code>



</h2>

    <div class="doc doc-contents ">




  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.expand_grid.expand_grid" class="doc doc-heading">
<code class="highlight language-python">expand_grid(df=None, df_key=None, *, others=None)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Creates a DataFrame from a cartesian combination of all inputs.</p>
<p>It is not restricted to DataFrame;
it can work with any list-like structure
that is 1 or 2 dimensional.</p>
<p>If method-chaining to a DataFrame, a string argument
to <code>df_key</code> parameter must be provided.</p>
<p>Data types are preserved in this function,
including pandas' extension array dtypes.</p>
<p>The output will always be a DataFrame, usually with a MultiIndex column,
with the keys of the <code>others</code> dictionary serving as the top level columns.</p>
<p>If a DataFrame with MultiIndex columns
is part of the arguments in <code>others</code>,
the columns are flattened, before the final DataFrame is generated.</p>
<p>If a pandas Series/DataFrame is passed, and has a labeled index, or
a MultiIndex index, the index is discarded; the final DataFrame
will have a RangeIndex.</p>
<p>The MultiIndexed DataFrame can be flattened using pyjanitor's
<a class="autorefs autorefs-internal" href="#janitor.functions.collapse_levels.collapse_levels"><code>collapse_levels</code></a>
method; the user can also decide to drop any of the levels, via pandas'
<code>droplevel</code> method.</p>
<p>Example:</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor as jn
&gt;&gt;&gt; df = pd.DataFrame({"x": [1, 2], "y": [2, 1]})
&gt;&gt;&gt; data = {"z": [1, 2, 3]}
&gt;&gt;&gt; df.expand_grid(df_key="df", others=data)
  df     z
   x  y  0
0  1  2  1
1  1  2  2
2  1  2  3
3  2  1  1
4  2  1  2
5  2  1  3
</code></pre>
<p>Expand_grid works with non-pandas objects:</p>
<pre class="highlight"><code>&gt;&gt;&gt; data = {"x": [1, 2, 3], "y": [1, 2]}
&gt;&gt;&gt; jn.expand_grid(others=data)
   x  y
   0  0
0  1  1
1  1  2
2  2  1
3  2  2
4  3  1
5  3  2


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>Optional[pandas.core.frame.DataFrame]</code></td>
        <td><p>A pandas DataFrame.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>df_key</code></td>
        <td><code>Optional[str]</code></td>
        <td><p>name of key for the dataframe. It becomes part of the column names of the dataframe.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>others</code></td>
        <td><code>Optional[Dict]</code></td>
        <td><p>A dictionary that contains the data to be combined with the dataframe. If no dataframe exists, all inputs in <code>others</code> will be combined to create a DataFrame.</p></td>
        <td><code>None</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame of the cartesian product.</p></td>
    </tr>
  </tbody>
</table>
<p><strong>Exceptions:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>KeyError</code></td>
        <td><p>if there is a DataFrame and <code>df_key</code> is not provided.</p></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/expand_grid.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
def expand_grid(
    df: Optional[pd.DataFrame] = None,
    df_key: Optional[str] = None,
    *,
    others: Optional[Dict] = None,
) -&gt; pd.DataFrame:
    """
    Creates a DataFrame from a cartesian combination of all inputs.

    It is not restricted to DataFrame;
    it can work with any list-like structure
    that is 1 or 2 dimensional.

    If method-chaining to a DataFrame, a string argument
    to `df_key` parameter must be provided.


    Data types are preserved in this function,
    including pandas' extension array dtypes.

    The output will always be a DataFrame, usually with a MultiIndex column,
    with the keys of the `others` dictionary serving as the top level columns.

    If a DataFrame with MultiIndex columns
    is part of the arguments in `others`,
    the columns are flattened, before the final DataFrame is generated.

    If a pandas Series/DataFrame is passed, and has a labeled index, or
    a MultiIndex index, the index is discarded; the final DataFrame
    will have a RangeIndex.

    The MultiIndexed DataFrame can be flattened using pyjanitor's
    [`collapse_levels`][janitor.functions.collapse_levels.collapse_levels]
    method; the user can also decide to drop any of the levels, via pandas'
    `droplevel` method.

    Example:

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor as jn
        &gt;&gt;&gt; df = pd.DataFrame({"x": [1, 2], "y": [2, 1]})
        &gt;&gt;&gt; data = {"z": [1, 2, 3]}
        &gt;&gt;&gt; df.expand_grid(df_key="df", others=data)
          df     z
           x  y  0
        0  1  2  1
        1  1  2  2
        2  1  2  3
        3  2  1  1
        4  2  1  2
        5  2  1  3

    Expand_grid works with non-pandas objects:

        &gt;&gt;&gt; data = {"x": [1, 2, 3], "y": [1, 2]}
        &gt;&gt;&gt; jn.expand_grid(others=data)
           x  y
           0  0
        0  1  1
        1  1  2
        2  2  1
        3  2  2
        4  3  1
        5  3  2

    :param df: A pandas DataFrame.
    :param df_key: name of key for the dataframe.
        It becomes part of the column names of the dataframe.
    :param others: A dictionary that contains the data
        to be combined with the dataframe.
        If no dataframe exists, all inputs
        in `others` will be combined to create a DataFrame.
    :returns: A pandas DataFrame of the cartesian product.
    :raises KeyError: if there is a DataFrame and `df_key` is not provided.
    """

    if not others:
        if df is not None:
            return df
        return

    check("others", others, [dict])

    # if there is a DataFrame, for the method chaining,
    # it must have a key, to create a name value pair
    if df is not None:
        df = df.copy()

        if not df_key:
            raise KeyError(
                "Using `expand_grid` as part of a "
                "DataFrame method chain requires that "
                "a string argument be provided for "
                "the `df_key` parameter. "
            )

        check("df_key", df_key, [str])

        others = {**{df_key: df}, **others}

    return _computations_expand_grid(others)
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.factorize_columns" class="doc doc-heading">
        <code>factorize_columns</code>



</h2>

    <div class="doc doc-contents ">

      <p>Implementation of the <code>factorize_columns</code> function</p>



  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.factorize_columns.factorize_columns" class="doc doc-heading">
<code class="highlight language-python">factorize_columns(df, column_names, suffix='_enc', **kwargs)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Converts labels into numerical data.</p>
<p>This method will create a new column with the string <code>_enc</code> appended
after the original column's name.
This can be overriden with the suffix parameter.</p>
<p>Internally, this method uses pandas <code>factorize</code> method.
It takes in an optional suffix and keyword arguments also.
An empty string as suffix will override the existing column.</p>
<p>This method does not mutate the original DataFrame.</p>
<p>Example:</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({
...     "foo": ["b", "b", "a", "c", "b"],
...     "bar": range(4, 9),
... })
&gt;&gt;&gt; df
  foo  bar
0   b    4
1   b    5
2   a    6
3   c    7
4   b    8
&gt;&gt;&gt; df.factorize_columns(column_names="foo")
  foo  bar  foo_enc
0   b    4        0
1   b    5        0
2   a    6        1
3   c    7        2
4   b    8        0


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>The pandas DataFrame object.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>column_names</code></td>
        <td><code>Union[str, Iterable[str], Hashable]</code></td>
        <td><p>A column name or an iterable (list or tuple) of column names.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>suffix</code></td>
        <td><code>str</code></td>
        <td><p>Suffix to be used for the new column. An empty string suffix means, it will override the existing column.</p></td>
        <td><code>&#39;_enc&#39;</code></td>
      </tr>
      <tr>
        <td><code>**kwargs</code></td>
        <td></td>
        <td><p>Keyword arguments. It takes any of the keyword arguments, which the pandas factorize method takes like <code>sort</code>, <code>na_sentinel</code>, <code>size_hint</code>.</p></td>
        <td><code>{}</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/factorize_columns.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
def factorize_columns(
    df: pd.DataFrame,
    column_names: Union[str, Iterable[str], Hashable],
    suffix: str = "_enc",
    **kwargs,
) -&gt; pd.DataFrame:
    """
    Converts labels into numerical data.

    This method will create a new column with the string `_enc` appended
    after the original column's name.
    This can be overriden with the suffix parameter.

    Internally, this method uses pandas `factorize` method.
    It takes in an optional suffix and keyword arguments also.
    An empty string as suffix will override the existing column.

    This method does not mutate the original DataFrame.

    Example:

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({
        ...     "foo": ["b", "b", "a", "c", "b"],
        ...     "bar": range(4, 9),
        ... })
        &gt;&gt;&gt; df
          foo  bar
        0   b    4
        1   b    5
        2   a    6
        3   c    7
        4   b    8
        &gt;&gt;&gt; df.factorize_columns(column_names="foo")
          foo  bar  foo_enc
        0   b    4        0
        1   b    5        0
        2   a    6        1
        3   c    7        2
        4   b    8        0

    :param df: The pandas DataFrame object.
    :param column_names: A column name or an iterable (list or tuple) of
        column names.
    :param suffix: Suffix to be used for the new column.
        An empty string suffix means, it will override the existing column.
    :param **kwargs: Keyword arguments. It takes any of the keyword arguments,
        which the pandas factorize method takes like `sort`, `na_sentinel`,
        `size_hint`.

    :returns: A pandas DataFrame.
    """
    df = _factorize(df.copy(), column_names, suffix, **kwargs)
    return df
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.fill" class="doc doc-heading">
        <code>fill</code>



</h2>

    <div class="doc doc-contents ">




  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.fill.fill_direction" class="doc doc-heading">
<code class="highlight language-python">fill_direction(df, **kwargs)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Provide a method-chainable function for filling missing values
in selected columns.</p>
<p>It is a wrapper for <code>pd.Series.ffill</code> and <code>pd.Series.bfill</code>,
and pairs the column name with one of <code>up</code>, <code>down</code>, <code>updown</code>,
and <code>downup</code>.</p>
<p>Example:</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor as jn
&gt;&gt;&gt; df = pd.DataFrame(
...    {
...        'col1': [1, 2, 3, 4],
...        'col2': [None, 5, 6, 7],
...        'col3': [8, 9, 10, None],
...        'col4': [None, None, 11, None],
...        'col5': [None, 12, 13, None]
...    }
... )
&gt;&gt;&gt; df
   col1  col2  col3  col4  col5
0     1   NaN   8.0   NaN   NaN
1     2   5.0   9.0   NaN  12.0
2     3   6.0  10.0  11.0  13.0
3     4   7.0   NaN   NaN   NaN
&gt;&gt;&gt; df.fill_direction(
... col2 = 'up',
... col3 = 'down',
... col4 = 'downup',
... col5 = 'updown'
... )
   col1  col2  col3  col4  col5
0     1   5.0   8.0  11.0  12.0
1     2   5.0   9.0  11.0  12.0
2     3   6.0  10.0  11.0  13.0
3     4   7.0  10.0  11.0  13.0


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A pandas DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>kwargs</code></td>
        <td></td>
        <td><p>Key - value pairs of columns and directions. Directions can be either <code>down</code>, <code>up</code>, <code>updown</code> (fill up then down) and <code>downup</code> (fill down then up).</p></td>
        <td><code>{}</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame with modified column(s).</p></td>
    </tr>
  </tbody>
</table>
<p><strong>Exceptions:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>ValueError</code></td>
        <td><p>if direction supplied is not one of <code>down</code>, <code>up</code>, <code>updown</code>, or <code>downup</code>.</p></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/fill.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
def fill_direction(df: pd.DataFrame, **kwargs) -&gt; pd.DataFrame:
    """
    Provide a method-chainable function for filling missing values
    in selected columns.

    It is a wrapper for `pd.Series.ffill` and `pd.Series.bfill`,
    and pairs the column name with one of `up`, `down`, `updown`,
    and `downup`.


    Example:

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor as jn
        &gt;&gt;&gt; df = pd.DataFrame(
        ...    {
        ...        'col1': [1, 2, 3, 4],
        ...        'col2': [None, 5, 6, 7],
        ...        'col3': [8, 9, 10, None],
        ...        'col4': [None, None, 11, None],
        ...        'col5': [None, 12, 13, None]
        ...    }
        ... )
        &gt;&gt;&gt; df
           col1  col2  col3  col4  col5
        0     1   NaN   8.0   NaN   NaN
        1     2   5.0   9.0   NaN  12.0
        2     3   6.0  10.0  11.0  13.0
        3     4   7.0   NaN   NaN   NaN
        &gt;&gt;&gt; df.fill_direction(
        ... col2 = 'up',
        ... col3 = 'down',
        ... col4 = 'downup',
        ... col5 = 'updown'
        ... )
           col1  col2  col3  col4  col5
        0     1   5.0   8.0  11.0  12.0
        1     2   5.0   9.0  11.0  12.0
        2     3   6.0  10.0  11.0  13.0
        3     4   7.0  10.0  11.0  13.0

    :param df: A pandas DataFrame.
    :param kwargs: Key - value pairs of columns and directions.
        Directions can be either `down`, `up`, `updown`
        (fill up then down) and `downup` (fill down then up).
    :returns: A pandas DataFrame with modified column(s).
    :raises ValueError: if direction supplied is not one of `down`, `up`,
        `updown`, or `downup`.
    """

    if not kwargs:
        return df

    fill_types = {fill.name for fill in _FILLTYPE}
    for column_name, fill_type in kwargs.items():
        check("column_name", column_name, [str])
        check("fill_type", fill_type, [str])
        if fill_type.upper() not in fill_types:
            raise ValueError(
                """
                fill_type should be one of
                up, down, updown, or downup.
                """
            )

    check_column(df, kwargs)

    new_values = {}
    for column_name, fill_type in kwargs.items():
        direction = _FILLTYPE[f"{fill_type.upper()}"].value
        if len(direction) == 1:
            direction = methodcaller(direction[0])
            output = direction(df[column_name])
        else:
            direction = [methodcaller(entry) for entry in direction]
            output = _chain_func(df[column_name], *direction)
        new_values[column_name] = output

    return df.assign(**new_values)
</code></pre>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.fill.fill_empty" class="doc doc-heading">
<code class="highlight language-python">fill_empty(df, column_names, value)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Fill <code>NaN</code> values in specified columns with a given value.</p>
<p>Super sugary syntax that wraps <code>pandas.DataFrame.fillna</code>.</p>
<p>This method mutates the original DataFrame.</p>
<p>Example:</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame(
...        {
...            'col1': [1, 2, 3],
...            'col2': [None, 4, None ],
...            'col3': [None, 5, 6]
...        }
...    )
&gt;&gt;&gt; df
   col1  col2  col3
0     1   NaN   NaN
1     2   4.0   5.0
2     3   NaN   6.0
&gt;&gt;&gt; df.fill_empty(column_names = 'col2', value = 0)
   col1  col2  col3
0     1   0.0   NaN
1     2   4.0   5.0
2     3   0.0   6.0
&gt;&gt;&gt; df.fill_empty(column_names = ['col2', 'col3'], value = 0)
   col1  col2  col3
0     1   0.0   0.0
1     2   4.0   5.0
2     3   0.0   6.0


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A pandas DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>column_names</code></td>
        <td><code>Union[str, Iterable[str], Hashable]</code></td>
        <td><p>column_names: A column name or an iterable (list or tuple) of column names. If a single column name is passed in, then only that column will be filled; if a list or tuple is passed in, then those columns will all be filled with the same value.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>value</code></td>
        <td></td>
        <td><p>The value that replaces the <code>NaN</code> values.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame with <code>NaN</code> values filled.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/fill.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
@deprecated_alias(columns="column_names")
def fill_empty(
    df: pd.DataFrame, column_names: Union[str, Iterable[str], Hashable], value
) -&gt; pd.DataFrame:
    """
    Fill `NaN` values in specified columns with a given value.

    Super sugary syntax that wraps `pandas.DataFrame.fillna`.

    This method mutates the original DataFrame.

    Example:

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame(
        ...        {
        ...            'col1': [1, 2, 3],
        ...            'col2': [None, 4, None ],
        ...            'col3': [None, 5, 6]
        ...        }
        ...    )
        &gt;&gt;&gt; df
           col1  col2  col3
        0     1   NaN   NaN
        1     2   4.0   5.0
        2     3   NaN   6.0
        &gt;&gt;&gt; df.fill_empty(column_names = 'col2', value = 0)
           col1  col2  col3
        0     1   0.0   NaN
        1     2   4.0   5.0
        2     3   0.0   6.0
        &gt;&gt;&gt; df.fill_empty(column_names = ['col2', 'col3'], value = 0)
           col1  col2  col3
        0     1   0.0   0.0
        1     2   4.0   5.0
        2     3   0.0   6.0


    :param df: A pandas DataFrame.
    :param column_names: column_names: A column name or an iterable (list
        or tuple) of column names. If a single column name is passed in, then
        only that column will be filled; if a list or tuple is passed in, then
        those columns will all be filled with the same value.
    :param value: The value that replaces the `NaN` values.
    :returns: A pandas DataFrame with `NaN` values filled.
    """
    check_column(df, column_names)
    return _fill_empty(df, column_names, value=value)
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.filter" class="doc doc-heading">
        <code>filter</code>



</h2>

    <div class="doc doc-contents ">




  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.filter.filter_column_isin" class="doc doc-heading">
<code class="highlight language-python">filter_column_isin(df, column_name, iterable, complement=False)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Filter a dataframe for values in a column that exist in the given iterable.</p>
<p>This method does not mutate the original DataFrame.</p>
<p>Assumes exact matching; fuzzy matching not implemented.</p>
<p>Example: Filter the dataframe to retain rows for which <code>names</code>
    are exactly <code>James</code> or <code>John</code>.</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({"names": ["Jane", "Jeremy", "John"], "foo": list("xyz")})
&gt;&gt;&gt; df
    names foo
0    Jane   x
1  Jeremy   y
2    John   z
&gt;&gt;&gt; df.filter_column_isin(column_name="names", iterable=["James", "John"])
  names foo
2  John   z
</code></pre>
<p>This is the method-chaining alternative to:</p>
<pre><code class="language-python">df = df[df[&quot;names&quot;].isin([&quot;James&quot;, &quot;John&quot;])]
</code></pre>
<p>If <code>complement=True</code>, then we will only get rows for which the names
are neither <code>James</code> nor <code>John</code>.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A pandas DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>column_name</code></td>
        <td><code>Hashable</code></td>
        <td><p>The column on which to filter.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>iterable</code></td>
        <td><code>Iterable</code></td>
        <td><p>An iterable. Could be a list, tuple, another pandas Series.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>complement</code></td>
        <td><code>bool</code></td>
        <td><p>Whether to return the complement of the selection or not.</p></td>
        <td><code>False</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A filtered pandas DataFrame.</p></td>
    </tr>
  </tbody>
</table>
<p><strong>Exceptions:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>ValueError</code></td>
        <td><p>If <code>iterable</code> does not have a length of <code>1</code> or greater.</p></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/filter.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
@deprecated_alias(column="column_name")
def filter_column_isin(
    df: pd.DataFrame,
    column_name: Hashable,
    iterable: Iterable,
    complement: bool = False,
) -&gt; pd.DataFrame:
    """Filter a dataframe for values in a column that exist in the given iterable.

    This method does not mutate the original DataFrame.

    Assumes exact matching; fuzzy matching not implemented.

    Example: Filter the dataframe to retain rows for which `names`
        are exactly `James` or `John`.

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({"names": ["Jane", "Jeremy", "John"], "foo": list("xyz")})
        &gt;&gt;&gt; df
            names foo
        0    Jane   x
        1  Jeremy   y
        2    John   z
        &gt;&gt;&gt; df.filter_column_isin(column_name="names", iterable=["James", "John"])
          names foo
        2  John   z

    This is the method-chaining alternative to:

    ```python
    df = df[df["names"].isin(["James", "John"])]
    ```

    If `complement=True`, then we will only get rows for which the names
    are neither `James` nor `John`.

    :param df: A pandas DataFrame.
    :param column_name: The column on which to filter.
    :param iterable: An iterable. Could be a list, tuple, another pandas
        Series.
    :param complement: Whether to return the complement of the selection or
        not.
    :returns: A filtered pandas DataFrame.
    :raises ValueError: If `iterable` does not have a length of `1`
        or greater.
    """  # noqa: E501
    if len(iterable) == 0:
        raise ValueError(
            "`iterable` kwarg must be given an iterable of length 1 "
            "or greater."
        )
    criteria = df[column_name].isin(iterable)

    if complement:
        return df[~criteria]
    return df[criteria]
</code></pre>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.filter.filter_date" class="doc doc-heading">
<code class="highlight language-python">filter_date(df, column_name, start_date=None, end_date=None, years=None, months=None, days=None, column_date_options=None, format=None)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Filter a date-based column based on certain criteria.</p>
<p>This method does not mutate the original DataFrame.</p>
<p>Dates may be finicky and this function builds on top of the <em>magic</em> from
the pandas <code>to_datetime</code> function that is able to parse dates well.</p>
<p>Additional options to parse the date type of your column may be found at
the official pandas <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html">documentation</a>.</p>
<p>Example:</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({
...     "a": range(5, 9),
...     "dt": ["2021-11-12", "2021-12-15", "2022-01-03", "2022-01-09"],
... })
&gt;&gt;&gt; df
   a          dt
0  5  2021-11-12
1  6  2021-12-15
2  7  2022-01-03
3  8  2022-01-09
&gt;&gt;&gt; df.filter_date("dt", start_date="2021-12-01", end_date="2022-01-05")
   a         dt
1  6 2021-12-15
2  7 2022-01-03
&gt;&gt;&gt; df.filter_date("dt", years=[2021], months=[12])
   a         dt
1  6 2021-12-15
</code></pre>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method will cast your column to a Timestamp!</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This only affects the format of the <code>start_date</code> and <code>end_date</code>
parameters. If there's an issue with the format of the DataFrame being
parsed, you would pass <code>{'format': your_format}</code> to <code>column_date_options</code>.</p>
</div>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>The dataframe to filter on.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>column_name</code></td>
        <td><code>Hashable</code></td>
        <td><p>The column which to apply the fraction transformation.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>start_date</code></td>
        <td><code>Optional[datetime.date]</code></td>
        <td><p>The beginning date to use to filter the DataFrame.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>end_date</code></td>
        <td><code>Optional[datetime.date]</code></td>
        <td><p>The end date to use to filter the DataFrame.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>years</code></td>
        <td><code>Optional[List]</code></td>
        <td><p>The years to use to filter the DataFrame.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>months</code></td>
        <td><code>Optional[List]</code></td>
        <td><p>The months to use to filter the DataFrame.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>days</code></td>
        <td><code>Optional[List]</code></td>
        <td><p>The days to use to filter the DataFrame.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>column_date_options</code></td>
        <td><code>Optional[Dict]</code></td>
        <td><p>Special options to use when parsing the date column in the original DataFrame. The options may be found at the official Pandas documentation.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>format</code></td>
        <td><code>Optional[str]</code></td>
        <td><p>If you're using a format for <code>start_date</code> or <code>end_date</code> that is not recognized natively by pandas' <code>to_datetime</code> function, you may supply the format yourself. Python date and time formats may be found <a href="http://strftime.org/">here</a>.</p></td>
        <td><code>None</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A filtered pandas DataFrame.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/filter.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
@deprecated_alias(column="column_name", start="start_date", end="end_date")
def filter_date(
    df: pd.DataFrame,
    column_name: Hashable,
    start_date: Optional[dt.date] = None,
    end_date: Optional[dt.date] = None,
    years: Optional[List] = None,
    months: Optional[List] = None,
    days: Optional[List] = None,
    column_date_options: Optional[Dict] = None,
    format: Optional[str] = None,  # skipcq: PYL-W0622
) -&gt; pd.DataFrame:
    """Filter a date-based column based on certain criteria.

    This method does not mutate the original DataFrame.

    Dates may be finicky and this function builds on top of the *magic* from
    the pandas `to_datetime` function that is able to parse dates well.

    Additional options to parse the date type of your column may be found at
    the official pandas [documentation][datetime].

    [datetime]: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html

    Example:

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({
        ...     "a": range(5, 9),
        ...     "dt": ["2021-11-12", "2021-12-15", "2022-01-03", "2022-01-09"],
        ... })
        &gt;&gt;&gt; df
           a          dt
        0  5  2021-11-12
        1  6  2021-12-15
        2  7  2022-01-03
        3  8  2022-01-09
        &gt;&gt;&gt; df.filter_date("dt", start_date="2021-12-01", end_date="2022-01-05")
           a         dt
        1  6 2021-12-15
        2  7 2022-01-03
        &gt;&gt;&gt; df.filter_date("dt", years=[2021], months=[12])
           a         dt
        1  6 2021-12-15

    !!!note

        This method will cast your column to a Timestamp!

    !!!note

        This only affects the format of the `start_date` and `end_date`
        parameters. If there's an issue with the format of the DataFrame being
        parsed, you would pass `{'format': your_format}` to `column_date_options`.

    :param df: The dataframe to filter on.
    :param column_name: The column which to apply the fraction transformation.
    :param start_date: The beginning date to use to filter the DataFrame.
    :param end_date: The end date to use to filter the DataFrame.
    :param years: The years to use to filter the DataFrame.
    :param months: The months to use to filter the DataFrame.
    :param days: The days to use to filter the DataFrame.
    :param column_date_options: Special options to use when parsing the date
        column in the original DataFrame. The options may be found at the
        official Pandas documentation.
    :param format: If you're using a format for `start_date` or `end_date`
        that is not recognized natively by pandas' `to_datetime` function, you
        may supply the format yourself. Python date and time formats may be
        found [here](http://strftime.org/).
    :returns: A filtered pandas DataFrame.
    """  # noqa: E501

    def _date_filter_conditions(conditions):
        """Taken from: https://stackoverflow.com/a/13616382."""
        return reduce(np.logical_and, conditions)

    if column_date_options:
        df.loc[:, column_name] = pd.to_datetime(
            df.loc[:, column_name], **column_date_options
        )
    else:
        df.loc[:, column_name] = pd.to_datetime(df.loc[:, column_name])

    _filter_list = []

    if start_date:
        start_date = pd.to_datetime(start_date, format=format)
        _filter_list.append(df.loc[:, column_name] &gt;= start_date)

    if end_date:
        end_date = pd.to_datetime(end_date, format=format)
        _filter_list.append(df.loc[:, column_name] &lt;= end_date)

    if years:
        _filter_list.append(df.loc[:, column_name].dt.year.isin(years))

    if months:
        _filter_list.append(df.loc[:, column_name].dt.month.isin(months))

    if days:
        _filter_list.append(df.loc[:, column_name].dt.day.isin(days))

    if start_date and end_date and start_date &gt; end_date:
        warnings.warn(
            f"Your start date of {start_date} is after your end date of "
            f"{end_date}. Is this intended?"
        )

    return df.loc[_date_filter_conditions(_filter_list), :]
</code></pre>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.filter.filter_on" class="doc doc-heading">
<code class="highlight language-python">filter_on(df, criteria, complement=False)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Return a dataframe filtered on a particular criteria.</p>
<p>This method does not mutate the original DataFrame.</p>
<p>This is super-sugary syntax that wraps the pandas <code>.query()</code> API, enabling
users to use strings to quickly specify filters for filtering their
dataframe. The intent is that <code>filter_on</code> as a verb better matches the
intent of a pandas user than the verb <code>query</code>.</p>
<p>This is intended to be the method-chaining equivalent of the following:</p>
<pre><code class="language-python">df = df[df[&quot;score&quot;] &lt; 3]
</code></pre>
<p>Example: Filter students who failed an exam (scored less than 50).</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({
...     "student_id": ["S1", "S2", "S3"],
...     "score": [40, 60, 85],
... })
&gt;&gt;&gt; df
  student_id  score
0         S1     40
1         S2     60
2         S3     85
&gt;&gt;&gt; df.filter_on("score &lt; 50", complement=False)
  student_id  score
0         S1     40
</code></pre>
<p>Credit to Brant Peterson for the name.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A pandas DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>criteria</code></td>
        <td><code>str</code></td>
        <td><p>A filtering criteria that returns an array or Series of booleans, on which pandas can filter on.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>complement</code></td>
        <td><code>bool</code></td>
        <td><p>Whether to return the complement of the filter or not. If set to True, then the rows for which the criteria is False are retained instead.</p></td>
        <td><code>False</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A filtered pandas DataFrame.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/filter.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
def filter_on(
    df: pd.DataFrame,
    criteria: str,
    complement: bool = False,
) -&gt; pd.DataFrame:
    """Return a dataframe filtered on a particular criteria.

    This method does not mutate the original DataFrame.

    This is super-sugary syntax that wraps the pandas `.query()` API, enabling
    users to use strings to quickly specify filters for filtering their
    dataframe. The intent is that `filter_on` as a verb better matches the
    intent of a pandas user than the verb `query`.

    This is intended to be the method-chaining equivalent of the following:
    ```python
    df = df[df["score"] &lt; 3]
    ```

    Example: Filter students who failed an exam (scored less than 50).

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({
        ...     "student_id": ["S1", "S2", "S3"],
        ...     "score": [40, 60, 85],
        ... })
        &gt;&gt;&gt; df
          student_id  score
        0         S1     40
        1         S2     60
        2         S3     85
        &gt;&gt;&gt; df.filter_on("score &lt; 50", complement=False)
          student_id  score
        0         S1     40

    Credit to Brant Peterson for the name.

    :param df: A pandas DataFrame.
    :param criteria: A filtering criteria that returns an array or Series of
        booleans, on which pandas can filter on.
    :param complement: Whether to return the complement of the filter or not.
        If set to True, then the rows for which the criteria is False are
        retained instead.
    :returns: A filtered pandas DataFrame.
    """
    if complement:
        return df.query(f"not ({criteria})")
    return df.query(criteria)
</code></pre>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.filter.filter_string" class="doc doc-heading">
<code class="highlight language-python">filter_string(df, column_name, search_string, complement=False, case=True, flags=0, na=None, regex=True)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Filter a string-based column according to whether it contains a substring.</p>
<p>This is super sugary syntax that builds on top of <code>pandas.Series.str.contains</code>.
It is meant to be the method-chaining equivalent of the following:</p>
<pre><code class="language-python">df = df[df[column_name].str.contains(search_string)]]
</code></pre>
<p>This method does not mutate the original DataFrame.</p>
<p>Example: Retain rows whose column values contain a particular substring.</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({"a": range(3, 6), "b": ["bear", "peeL", "sail"]})
&gt;&gt;&gt; df
   a     b
0  3  bear
1  4  peeL
2  5  sail
&gt;&gt;&gt; df.filter_string(column_name="b", search_string="ee")
   a     b
1  4  peeL
&gt;&gt;&gt; df.filter_string(column_name="b", search_string="L", case=False)
   a     b
1  4  peeL
2  5  sail
</code></pre>
<p>Example: Filter names does not contain <code>'.'</code> (disable regex mode).</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.Series(["JoseChen", "Brian.Salvi"], name="Name").to_frame()
&gt;&gt;&gt; df
          Name
0     JoseChen
1  Brian.Salvi
&gt;&gt;&gt; df.filter_string(column_name="Name", search_string=".", regex=False, complement=True)
       Name
0  JoseChen


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A pandas DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>column_name</code></td>
        <td><code>Hashable</code></td>
        <td><p>The column to filter. The column should contain strings.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>search_string</code></td>
        <td><code>str</code></td>
        <td><p>A regex pattern or a (sub-)string to search.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>complement</code></td>
        <td><code>bool</code></td>
        <td><p>Whether to return the complement of the filter or not. If set to True, then the rows for which the string search fails are retained instead.</p></td>
        <td><code>False</code></td>
      </tr>
      <tr>
        <td><code>case</code></td>
        <td><code>bool</code></td>
        <td><p>If True, case sensitive.</p></td>
        <td><code>True</code></td>
      </tr>
      <tr>
        <td><code>flags</code></td>
        <td><code>int</code></td>
        <td><p>Flags to pass through to the re module, e.g. re.IGNORECASE.</p></td>
        <td><code>0</code></td>
      </tr>
      <tr>
        <td><code>na</code></td>
        <td></td>
        <td><p>Fill value for missing values. The default depends on dtype of the array. For object-dtype, <code>numpy.nan</code> is used. For <code>StringDtype</code>, <code>pandas.NA</code> is used.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>regex</code></td>
        <td><code>bool</code></td>
        <td><p>If True, assumes <code>search_string</code> is a regular expression. If False, treats the <code>search_string</code> as a literal string.</p></td>
        <td><code>True</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A filtered pandas DataFrame.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/filter.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
@deprecated_alias(column="column_name")
def filter_string(
    df: pd.DataFrame,
    column_name: Hashable,
    search_string: str,
    complement: bool = False,
    case: bool = True,
    flags: int = 0,
    na=None,
    regex: bool = True,
) -&gt; pd.DataFrame:
    """Filter a string-based column according to whether it contains a substring.

    This is super sugary syntax that builds on top of `pandas.Series.str.contains`.
    It is meant to be the method-chaining equivalent of the following:

    ```python
    df = df[df[column_name].str.contains(search_string)]]
    ```

    This method does not mutate the original DataFrame.

    Example: Retain rows whose column values contain a particular substring.

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({"a": range(3, 6), "b": ["bear", "peeL", "sail"]})
        &gt;&gt;&gt; df
           a     b
        0  3  bear
        1  4  peeL
        2  5  sail
        &gt;&gt;&gt; df.filter_string(column_name="b", search_string="ee")
           a     b
        1  4  peeL
        &gt;&gt;&gt; df.filter_string(column_name="b", search_string="L", case=False)
           a     b
        1  4  peeL
        2  5  sail

    Example: Filter names does not contain `'.'` (disable regex mode).

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.Series(["JoseChen", "Brian.Salvi"], name="Name").to_frame()
        &gt;&gt;&gt; df
                  Name
        0     JoseChen
        1  Brian.Salvi
        &gt;&gt;&gt; df.filter_string(column_name="Name", search_string=".", regex=False, complement=True)
               Name
        0  JoseChen

    :param df: A pandas DataFrame.
    :param column_name: The column to filter. The column should contain strings.
    :param search_string: A regex pattern or a (sub-)string to search.
    :param complement: Whether to return the complement of the filter or not. If
        set to True, then the rows for which the string search fails are retained
        instead.
    :param case: If True, case sensitive.
    :param flags: Flags to pass through to the re module, e.g. re.IGNORECASE.
    :param na: Fill value for missing values. The default depends on dtype of
        the array. For object-dtype, `numpy.nan` is used. For `StringDtype`,
        `pandas.NA` is used.
    :param regex: If True, assumes `search_string` is a regular expression. If False,
        treats the `search_string` as a literal string.
    :returns: A filtered pandas DataFrame.
    """  # noqa: E501

    criteria = df[column_name].str.contains(
        pat=search_string,
        case=case,
        flags=flags,
        na=na,
        regex=regex,
    )

    if complement:
        return df[~criteria]

    return df[criteria]
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.find_replace" class="doc doc-heading">
        <code>find_replace</code>



</h2>

    <div class="doc doc-contents ">

      <p>Implementation for find_replace.</p>



  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.find_replace.find_replace" class="doc doc-heading">
<code class="highlight language-python">find_replace(df, match='exact', **mappings)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Perform a find-and-replace action on provided columns.</p>
<p>Depending on use case, users can choose either exact, full-value matching,
or regular-expression-based fuzzy matching
(hence allowing substring matching in the latter case).
For strings, the matching is always case sensitive.</p>
<p>For instance, given a DataFrame containing orders at a coffee shop:</p>
<pre class="highlight"><code>&gt;&gt;&gt; df = pd.DataFrame({
...     "customer": ["Mary", "Tom", "Lila"],
...     "order": ["ice coffee", "lemonade", "regular coffee"]
... })
&gt;&gt;&gt; df
  customer           order
0     Mary      ice coffee
1      Tom        lemonade
2     Lila  regular coffee
</code></pre>
<p>Our task is to replace values <code>ice coffee</code> and <code>regular coffee</code>
of the <code>order</code> column into <code>latte</code>.</p>
<p>Example 1 - exact matching (functional usage):</p>
<pre class="highlight"><code>&gt;&gt;&gt; df = find_replace(
...     df,
...     match="exact",
...     order={"ice coffee": "latte", "regular coffee": "latte"},
... )
&gt;&gt;&gt; df
  customer     order
0     Mary     latte
1      Tom  lemonade
2     Lila     latte
</code></pre>
<p>Example 1 - exact matching (method chaining):</p>
<pre class="highlight"><code>&gt;&gt;&gt; df = df.find_replace(
...     match="exact",
...     order={"ice coffee": "latte", "regular coffee": "latte"},
... )
&gt;&gt;&gt; df
  customer     order
0     Mary     latte
1      Tom  lemonade
2     Lila     latte
</code></pre>
<p>Example 2 - Regular-expression-based matching (functional usage):</p>
<pre class="highlight"><code>&gt;&gt;&gt; df = find_replace(
...     df,
...     match='regex',
...     order={'coffee$': 'latte'},
... )
&gt;&gt;&gt; df
  customer     order
0     Mary     latte
1      Tom  lemonade
2     Lila     latte
</code></pre>
<p>Example 2 - Regular-expression-based matching (method chaining usage):</p>
<pre class="highlight"><code>&gt;&gt;&gt; df = df.find_replace(
...     match='regex',
...     order={'coffee$': 'latte'},
... )
&gt;&gt;&gt; df
  customer     order
0     Mary     latte
1      Tom  lemonade
2     Lila     latte
</code></pre>
<p>To perform a find and replace on the entire DataFrame,
pandas' <code>df.replace()</code> function provides the appropriate functionality.
You can find more detail on the <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.replace.html">replace</a> docs.</p>
<p>This function only works with column names that have no spaces
or punctuation in them.
For example, a column name <code>item_name</code> would work with <code>find_replace</code>,
because it is a contiguous string that can be parsed correctly,
but <code>item name</code> would not be parsed correctly by the Python interpreter.</p>
<p>If you have column names that might not be compatible,
we recommend calling on <code>clean_names()</code> as the first method call.
If, for whatever reason, that is not possible,
then <code>_find_replace</code> is available as a function
that you can do a pandas <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.pipe.html">pipe</a> call on.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A pandas DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>match</code></td>
        <td><code>str</code></td>
        <td><p>Whether or not to perform an exact match or not. Valid values are "exact" or "regex".</p></td>
        <td><code>&#39;exact&#39;</code></td>
      </tr>
      <tr>
        <td><code>mappings</code></td>
        <td></td>
        <td><p>keyword arguments corresponding to column names that have dictionaries passed in indicating what to find (keys) and what to replace with (values).</p></td>
        <td><code>{}</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame with replaced values.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/find_replace.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
def find_replace(
    df: pd.DataFrame, match: str = "exact", **mappings
) -&gt; pd.DataFrame:
    """
    Perform a find-and-replace action on provided columns.

    Depending on use case, users can choose either exact, full-value matching,
    or regular-expression-based fuzzy matching
    (hence allowing substring matching in the latter case).
    For strings, the matching is always case sensitive.

    For instance, given a DataFrame containing orders at a coffee shop:

        &gt;&gt;&gt; df = pd.DataFrame({
        ...     "customer": ["Mary", "Tom", "Lila"],
        ...     "order": ["ice coffee", "lemonade", "regular coffee"]
        ... })
        &gt;&gt;&gt; df
          customer           order
        0     Mary      ice coffee
        1      Tom        lemonade
        2     Lila  regular coffee

    Our task is to replace values `ice coffee` and `regular coffee`
    of the `order` column into `latte`.

    Example 1 - exact matching (functional usage):

        &gt;&gt;&gt; df = find_replace(
        ...     df,
        ...     match="exact",
        ...     order={"ice coffee": "latte", "regular coffee": "latte"},
        ... )
        &gt;&gt;&gt; df
          customer     order
        0     Mary     latte
        1      Tom  lemonade
        2     Lila     latte

    Example 1 - exact matching (method chaining):

        &gt;&gt;&gt; df = df.find_replace(
        ...     match="exact",
        ...     order={"ice coffee": "latte", "regular coffee": "latte"},
        ... )
        &gt;&gt;&gt; df
          customer     order
        0     Mary     latte
        1      Tom  lemonade
        2     Lila     latte

    Example 2 - Regular-expression-based matching (functional usage):

        &gt;&gt;&gt; df = find_replace(
        ...     df,
        ...     match='regex',
        ...     order={'coffee$': 'latte'},
        ... )
        &gt;&gt;&gt; df
          customer     order
        0     Mary     latte
        1      Tom  lemonade
        2     Lila     latte

    Example 2 - Regular-expression-based matching (method chaining usage):

        &gt;&gt;&gt; df = df.find_replace(
        ...     match='regex',
        ...     order={'coffee$': 'latte'},
        ... )
        &gt;&gt;&gt; df
          customer     order
        0     Mary     latte
        1      Tom  lemonade
        2     Lila     latte

    To perform a find and replace on the entire DataFrame,
    pandas' `df.replace()` function provides the appropriate functionality.
    You can find more detail on the [replace] docs.

    [replace]: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.replace.html

    This function only works with column names that have no spaces
    or punctuation in them.
    For example, a column name `item_name` would work with `find_replace`,
    because it is a contiguous string that can be parsed correctly,
    but `item name` would not be parsed correctly by the Python interpreter.

    If you have column names that might not be compatible,
    we recommend calling on `clean_names()` as the first method call.
    If, for whatever reason, that is not possible,
    then `_find_replace` is available as a function
    that you can do a pandas [pipe](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.pipe.html) call on.

    :param df: A pandas DataFrame.
    :param match: Whether or not to perform an exact match or not.
        Valid values are "exact" or "regex".
    :param mappings: keyword arguments corresponding to column names
        that have dictionaries passed in indicating what to find (keys)
        and what to replace with (values).
    :returns: A pandas DataFrame with replaced values.
    """  # noqa: E501
    for column_name, mapper in mappings.items():
        df = _find_replace(df, column_name, mapper, match=match)
    return df
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.flag_nulls" class="doc doc-heading">
        <code>flag_nulls</code>



</h2>

    <div class="doc doc-contents ">




  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.flag_nulls.flag_nulls" class="doc doc-heading">
<code class="highlight language-python">flag_nulls(df, column_name='null_flag', columns=None)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Creates a new column to indicate whether you have null values in a given
row. If the columns parameter is not set, looks across the entire
DataFrame, otherwise will look only in the columns you set.</p>
<p>This method does not mutate the original DataFrame.</p>
<p>Example:</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({
...     "a": ["w", "x", None, "z"], "b": [5, None, 7, 8],
... })
&gt;&gt;&gt; df.flag_nulls()
      a    b  null_flag
0     w  5.0          0
1     x  NaN          1
2  None  7.0          1
3     z  8.0          0
&gt;&gt;&gt; df.flag_nulls(columns="b")
      a    b  null_flag
0     w  5.0          0
1     x  NaN          1
2  None  7.0          0
3     z  8.0          0


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>Input pandas DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>column_name</code></td>
        <td><code>Optional[Hashable]</code></td>
        <td><p>Name for the output column.</p></td>
        <td><code>&#39;null_flag&#39;</code></td>
      </tr>
      <tr>
        <td><code>columns</code></td>
        <td><code>Union[str, Iterable[str], Hashable]</code></td>
        <td><p>List of columns to look at for finding null values. If you only want to look at one column, you can simply give its name. If set to None (default), all DataFrame columns are used.</p></td>
        <td><code>None</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>Input dataframe with the null flag column.</p></td>
    </tr>
  </tbody>
</table>
<p><strong>Exceptions:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>ValueError</code></td>
        <td><p>if <code>column_name</code> is already present in the DataFrame.</p></td>
      </tr>
      <tr>
        <td><code>ValueError</code></td>
        <td><p>if any column within <code>columns</code> is not present in the DataFrame.  <!-- # noqa: DAR402 --></p></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/flag_nulls.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
def flag_nulls(
    df: pd.DataFrame,
    column_name: Optional[Hashable] = "null_flag",
    columns: Optional[Union[str, Iterable[str], Hashable]] = None,
) -&gt; pd.DataFrame:
    """Creates a new column to indicate whether you have null values in a given
    row. If the columns parameter is not set, looks across the entire
    DataFrame, otherwise will look only in the columns you set.

    This method does not mutate the original DataFrame.

    Example:

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({
        ...     "a": ["w", "x", None, "z"], "b": [5, None, 7, 8],
        ... })
        &gt;&gt;&gt; df.flag_nulls()
              a    b  null_flag
        0     w  5.0          0
        1     x  NaN          1
        2  None  7.0          1
        3     z  8.0          0
        &gt;&gt;&gt; df.flag_nulls(columns="b")
              a    b  null_flag
        0     w  5.0          0
        1     x  NaN          1
        2  None  7.0          0
        3     z  8.0          0

    :param df: Input pandas DataFrame.
    :param column_name: Name for the output column.
    :param columns: List of columns to look at for finding null values. If you
        only want to look at one column, you can simply give its name. If set
        to None (default), all DataFrame columns are used.
    :returns: Input dataframe with the null flag column.
    :raises ValueError: if `column_name` is already present in the
        DataFrame.
    :raises ValueError: if any column within `columns` is not present in
        the DataFrame.

    &lt;!--
    # noqa: DAR402
    --&gt;
    """
    # Sort out columns input
    if isinstance(columns, str):
        columns = [columns]
    elif columns is None:
        columns = df.columns
    elif not isinstance(columns, Iterable):
        # catches other hashable types
        columns = [columns]

    # Input sanitation checks
    check_column(df, columns)
    check_column(df, [column_name], present=False)

    # This algorithm works best for n_rows &gt;&gt; n_cols. See issue #501
    null_array = np.zeros(len(df))
    for col in columns:
        null_array = np.logical_or(null_array, pd.isna(df[col]))

    df = df.copy()
    df[column_name] = null_array.astype(int)
    return df
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.get_dupes" class="doc doc-heading">
        <code>get_dupes</code>



</h2>

    <div class="doc doc-contents ">

      <p>Implementation of the <code>get_dupes</code> function</p>



  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.get_dupes.get_dupes" class="doc doc-heading">
<code class="highlight language-python">get_dupes(df, column_names=None)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Return all duplicate rows.</p>
<p>This method does not mutate the original DataFrame.</p>
<p>Method chaining syntax:</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({
...     "item": ["shoe", "shoe", "bag", "shoe", "bag"],
...     "quantity": [100, 100, 75, 200, 75],
... })
&gt;&gt;&gt; df
   item  quantity
0  shoe       100
1  shoe       100
2   bag        75
3  shoe       200
4   bag        75
&gt;&gt;&gt; df.get_dupes()
   item  quantity
0  shoe       100
1  shoe       100
2   bag        75
4   bag        75
</code></pre>
<p>Optional <code>column_names</code> usage:</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({
...     "item": ["shoe", "shoe", "bag", "shoe", "bag"],
...     "quantity": [100, 100, 75, 200, 75],
... })
&gt;&gt;&gt; df
   item  quantity
0  shoe       100
1  shoe       100
2   bag        75
3  shoe       200
4   bag        75
&gt;&gt;&gt; df.get_dupes(column_names=["item"])
   item  quantity
0  shoe       100
1  shoe       100
2   bag        75
3  shoe       200
4   bag        75
&gt;&gt;&gt; df.get_dupes(column_names=["quantity"])
   item  quantity
0  shoe       100
1  shoe       100
2   bag        75
4   bag        75


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>The pandas DataFrame object.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>column_names</code></td>
        <td><code>Union[str, Iterable[str], Hashable]</code></td>
        <td><p>(optional) A column name or an iterable (list or tuple) of column names. Following pandas API, this only considers certain columns for identifying duplicates. Defaults to using all columns.</p></td>
        <td><code>None</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>The duplicate rows, as a pandas DataFrame.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/get_dupes.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
@deprecated_alias(columns="column_names")
def get_dupes(
    df: pd.DataFrame,
    column_names: Optional[Union[str, Iterable[str], Hashable]] = None,
) -&gt; pd.DataFrame:
    """
    Return all duplicate rows.

    This method does not mutate the original DataFrame.

    Method chaining syntax:

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({
        ...     "item": ["shoe", "shoe", "bag", "shoe", "bag"],
        ...     "quantity": [100, 100, 75, 200, 75],
        ... })
        &gt;&gt;&gt; df
           item  quantity
        0  shoe       100
        1  shoe       100
        2   bag        75
        3  shoe       200
        4   bag        75
        &gt;&gt;&gt; df.get_dupes()
           item  quantity
        0  shoe       100
        1  shoe       100
        2   bag        75
        4   bag        75

    Optional `column_names` usage:

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({
        ...     "item": ["shoe", "shoe", "bag", "shoe", "bag"],
        ...     "quantity": [100, 100, 75, 200, 75],
        ... })
        &gt;&gt;&gt; df
           item  quantity
        0  shoe       100
        1  shoe       100
        2   bag        75
        3  shoe       200
        4   bag        75
        &gt;&gt;&gt; df.get_dupes(column_names=["item"])
           item  quantity
        0  shoe       100
        1  shoe       100
        2   bag        75
        3  shoe       200
        4   bag        75
        &gt;&gt;&gt; df.get_dupes(column_names=["quantity"])
           item  quantity
        0  shoe       100
        1  shoe       100
        2   bag        75
        4   bag        75

    :param df: The pandas DataFrame object.
    :param column_names: (optional) A column name or an iterable
        (list or tuple) of column names. Following pandas API, this only
        considers certain columns for identifying duplicates. Defaults to using
        all columns.
    :returns: The duplicate rows, as a pandas DataFrame.
    """
    dupes = df.duplicated(subset=column_names, keep=False)
    return df[dupes == True]  # noqa: E712
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.groupby_agg" class="doc doc-heading">
        <code>groupby_agg</code>



</h2>

    <div class="doc doc-contents ">




  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.groupby_agg.groupby_agg" class="doc doc-heading">
<code class="highlight language-python">groupby_agg(df, by, new_column_name, agg_column_name, agg, dropna=True)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Shortcut for assigning a groupby-transform to a new column.</p>
<p>This method does not mutate the original DataFrame.</p>
<p>Intended to be the method-chaining equivalent of:</p>
<pre><code class="language-python">df = df.assign(...=df.groupby(...)[...].transform(...))
</code></pre>
<p>Example: Basic usage.</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({
...     "item": ["shoe", "shoe", "bag", "shoe", "bag"],
...     "quantity": [100, 120, 75, 200, 25],
... })
&gt;&gt;&gt; df.groupby_agg(
...     by="item",
...     agg="mean",
...     agg_column_name="quantity",
...     new_column_name="avg_quantity",
... )
   item  quantity  avg_quantity
0  shoe       100         140.0
1  shoe       120         140.0
2   bag        75          50.0
3  shoe       200         140.0
4   bag        25          50.0
</code></pre>
<p>Example: Set <code>dropna=False</code> to compute the aggregation, treating the null
values in the <code>by</code> column as an isolated "group".</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({
...     "x": ["a", "a", None, "b"], "y": [9, 9, 9, 9],
... })
&gt;&gt;&gt; df.groupby_agg(
...     by="x",
...     agg="count",
...     agg_column_name="y",
...     new_column_name="y_count",
...     dropna=False,
... )
      x  y  y_count
0     a  9        2
1     a  9        2
2  None  9        1
3     b  9        1


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A pandas DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>by</code></td>
        <td><code>Union[List, Callable, str]</code></td>
        <td><p>Column(s) to groupby on, will be passed into <code>DataFrame.groupby</code>.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>new_column_name</code></td>
        <td><code>str</code></td>
        <td><p>Name of the aggregation output column.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>agg_column_name</code></td>
        <td><code>str</code></td>
        <td><p>Name of the column to aggregate over.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>agg</code></td>
        <td><code>Union[Callable, str]</code></td>
        <td><p>How to aggregate.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>dropna</code></td>
        <td><code>bool</code></td>
        <td><p>Whether or not to include null values, if present in the <code>by</code> column(s). Default is True (null values in <code>by</code> are assigned NaN in the new column).</p></td>
        <td><code>True</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/groupby_agg.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
@deprecated_alias(new_column="new_column_name", agg_column="agg_column_name")
def groupby_agg(
    df: pd.DataFrame,
    by: Union[List, Callable, str],
    new_column_name: str,
    agg_column_name: str,
    agg: Union[Callable, str],
    dropna: bool = True,
) -&gt; pd.DataFrame:
    """Shortcut for assigning a groupby-transform to a new column.

    This method does not mutate the original DataFrame.

    Intended to be the method-chaining equivalent of:

    ```python
    df = df.assign(...=df.groupby(...)[...].transform(...))
    ```

    Example: Basic usage.

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({
        ...     "item": ["shoe", "shoe", "bag", "shoe", "bag"],
        ...     "quantity": [100, 120, 75, 200, 25],
        ... })
        &gt;&gt;&gt; df.groupby_agg(
        ...     by="item",
        ...     agg="mean",
        ...     agg_column_name="quantity",
        ...     new_column_name="avg_quantity",
        ... )
           item  quantity  avg_quantity
        0  shoe       100         140.0
        1  shoe       120         140.0
        2   bag        75          50.0
        3  shoe       200         140.0
        4   bag        25          50.0

    Example: Set `dropna=False` to compute the aggregation, treating the null
    values in the `by` column as an isolated "group".

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({
        ...     "x": ["a", "a", None, "b"], "y": [9, 9, 9, 9],
        ... })
        &gt;&gt;&gt; df.groupby_agg(
        ...     by="x",
        ...     agg="count",
        ...     agg_column_name="y",
        ...     new_column_name="y_count",
        ...     dropna=False,
        ... )
              x  y  y_count
        0     a  9        2
        1     a  9        2
        2  None  9        1
        3     b  9        1

    :param df: A pandas DataFrame.
    :param by: Column(s) to groupby on, will be passed into `DataFrame.groupby`.
    :param new_column_name: Name of the aggregation output column.
    :param agg_column_name: Name of the column to aggregate over.
    :param agg: How to aggregate.
    :param dropna: Whether or not to include null values, if present in the
        `by` column(s). Default is True (null values in `by` are assigned NaN in
        the new column).
    :returns: A pandas DataFrame.
    """  # noqa: E501

    return df.assign(
        **{
            new_column_name: df.groupby(by, dropna=dropna)[
                agg_column_name
            ].transform(agg),
        }
    )
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.groupby_topk" class="doc doc-heading">
        <code>groupby_topk</code>



</h2>

    <div class="doc doc-contents ">

      <p>Implementation of the <code>groupby_topk</code> function</p>



  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.groupby_topk.groupby_topk" class="doc doc-heading">
<code class="highlight language-python">groupby_topk(df, by, column, k, dropna=True, ascending=True, ignore_index=True)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Return top <code>k</code> rows from a groupby of a set of columns.</p>
<p>Returns a DataFrame that has the top <code>k</code> values per <code>column</code>,
grouped by <code>by</code>. Under the hood it uses <code>nlargest/nsmallest</code>,
for numeric columns, which avoids sorting the entire dataframe,
and is usually more performant. For non-numeric columns, <code>pd.sort_values</code>
is used.
No sorting is done to the <code>by</code> column(s); the order is maintained
in the final output.</p>
<p>Example:</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame(
...     {
...         "age": [20, 23, 22, 43, 21],
...         "id": [1, 4, 6, 2, 5],
...         "result": ["pass", "pass", "fail", "pass", "fail"],
...     }
... )
&gt;&gt;&gt; df
   age  id result
0   20   1   pass
1   23   4   pass
2   22   6   fail
3   43   2   pass
4   21   5   fail
</code></pre>
<p>Ascending top 3:</p>
<pre class="highlight"><code>&gt;&gt;&gt; df.groupby_topk(by="result", column="age", k=3)
   age  id result
0   20   1   pass
1   23   4   pass
2   43   2   pass
3   21   5   fail
4   22   6   fail
</code></pre>
<p>Descending top 2:</p>
<pre class="highlight"><code>&gt;&gt;&gt; df.groupby_topk(
...     by="result", column="age", k=2, ascending=False, ignore_index=False
... )
   age  id result
3   43   2   pass
1   23   4   pass
2   22   6   fail
4   21   5   fail


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A pandas DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>by</code></td>
        <td><code>Union[list, Hashable]</code></td>
        <td><p>Column name(s) to group input DataFrame <code>df</code> by.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>column</code></td>
        <td><code>Hashable</code></td>
        <td><p>Name of the column that determines <code>k</code> rows to return.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>k</code></td>
        <td><code>int</code></td>
        <td><p>Number of top rows to return for each group.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>dropna</code></td>
        <td><code>bool</code></td>
        <td><p>If <code>True</code>, and <code>NA</code> values exist in <code>by</code>, the <code>NA</code> values are not used in the groupby computation to get the relevant <code>k</code> rows. If <code>False</code>, and <code>NA</code> values exist in <code>by</code>, then the <code>NA</code> values are used in the groupby computation to get the relevant <code>k</code> rows. The default is <code>True</code>.</p></td>
        <td><code>True</code></td>
      </tr>
      <tr>
        <td><code>ascending</code></td>
        <td><code>bool</code></td>
        <td><p>Default is <code>True</code>. If <code>True</code>, the smallest top <code>k</code> rows, determined by <code>column</code> are returned; if <code>False, the largest top</code>k<code>rows, determined by</code>column` are returned.</p></td>
        <td><code>True</code></td>
      </tr>
      <tr>
        <td><code>ignore_index</code></td>
        <td><code>bool</code></td>
        <td><p>Default <code>True</code>. If <code>True</code>, the original index is ignored. If <code>False</code>, the original index for the top <code>k</code> rows is retained.</p></td>
        <td><code>True</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame with top <code>k</code> rows per <code>column</code>, grouped by <code>by</code>.</p></td>
    </tr>
  </tbody>
</table>
<p><strong>Exceptions:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>ValueError</code></td>
        <td><p>if <code>k</code> is less than 1.</p></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/groupby_topk.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
@deprecated_alias(groupby_column_name="by", sort_column_name="column")
def groupby_topk(
    df: pd.DataFrame,
    by: Union[list, Hashable],
    column: Hashable,
    k: int,
    dropna: bool = True,
    ascending: bool = True,
    ignore_index: bool = True,
) -&gt; pd.DataFrame:
    """
    Return top `k` rows from a groupby of a set of columns.

    Returns a DataFrame that has the top `k` values per `column`,
    grouped by `by`. Under the hood it uses `nlargest/nsmallest`,
    for numeric columns, which avoids sorting the entire dataframe,
    and is usually more performant. For non-numeric columns, `pd.sort_values`
    is used.
    No sorting is done to the `by` column(s); the order is maintained
    in the final output.


    Example:

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame(
        ...     {
        ...         "age": [20, 23, 22, 43, 21],
        ...         "id": [1, 4, 6, 2, 5],
        ...         "result": ["pass", "pass", "fail", "pass", "fail"],
        ...     }
        ... )
        &gt;&gt;&gt; df
           age  id result
        0   20   1   pass
        1   23   4   pass
        2   22   6   fail
        3   43   2   pass
        4   21   5   fail

    Ascending top 3:

        &gt;&gt;&gt; df.groupby_topk(by="result", column="age", k=3)
           age  id result
        0   20   1   pass
        1   23   4   pass
        2   43   2   pass
        3   21   5   fail
        4   22   6   fail

    Descending top 2:

        &gt;&gt;&gt; df.groupby_topk(
        ...     by="result", column="age", k=2, ascending=False, ignore_index=False
        ... )
           age  id result
        3   43   2   pass
        1   23   4   pass
        2   22   6   fail
        4   21   5   fail


    :param df: A pandas DataFrame.
    :param by: Column name(s) to group input DataFrame `df` by.
    :param column: Name of the column that determines `k` rows
        to return.
    :param k: Number of top rows to return for each group.
    :param dropna: If `True`, and `NA` values exist in `by`, the `NA`
        values are not used in the groupby computation to get the relevant
        `k` rows. If `False`, and `NA` values exist in `by`, then the `NA`
        values are used in the groupby computation to get the relevant
        `k` rows. The default is `True`.
    :param ascending: Default is `True`. If `True`, the smallest top `k` rows,
        determined by `column` are returned; if `False, the largest top `k` rows,
        determined by `column` are returned.
    :param ignore_index: Default `True`. If `True`,
        the original index is ignored. If `False`, the original index
        for the top `k` rows is retained.
    :returns: A pandas DataFrame with top `k` rows per `column`, grouped by `by`.
    :raises ValueError: if `k` is less than 1.
    """  # noqa: E501

    if isinstance(by, Hashable):
        by = [by]

    check("by", by, [Hashable, list])

    check_column(df, [column])
    check_column(df, by)

    if k &lt; 1:
        raise ValueError(
            "Numbers of rows per group "
            "to be returned must be greater than 0."
        )

    indices = df.groupby(by=by, dropna=dropna, sort=False, observed=True)
    indices = indices[column]

    try:
        if ascending:
            indices = indices.nsmallest(n=k)
        else:
            indices = indices.nlargest(n=k)
    except TypeError:
        indices = indices.apply(
            lambda d: d.sort_values(ascending=ascending).head(k)
        )

    indices = indices.index.get_level_values(-1)
    if ignore_index:
        return df.loc[indices].reset_index(drop=True)
    return df.loc[indices]
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.impute" class="doc doc-heading">
        <code>impute</code>



</h2>

    <div class="doc doc-contents ">

      <p>Implementation of <code>impute</code> function</p>



  <div class="doc doc-children">









  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.impute.impute" class="doc doc-heading">
<code class="highlight language-python">impute(df, column_name, value=None, statistic_column_name=None)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Method-chainable imputation of values in a column.</p>
<p>This method mutates the original DataFrame.</p>
<p>Underneath the hood, this function calls the <code>.fillna()</code> method available
to every <code>pandas.Series</code> object.</p>
<p>Either one of <code>value</code> or <code>statistic_column_name</code> should be provided.</p>
<p>If <code>value</code> is provided, then all null values in the selected column will
take on the value provided.</p>
<p>If <code>statistic_column_name</code> is provided, then all null values in the
selected column will take on the summary statistic value of other non-null
values.</p>
<p>Currently supported statistics include:</p>
<ul>
<li><code>mean</code> (also aliased by <code>average</code>)</li>
<li><code>median</code></li>
<li><code>mode</code></li>
<li><code>minimum</code> (also aliased by <code>min</code>)</li>
<li><code>maximum</code> (also aliased by <code>max</code>)</li>
</ul>
<p>Example:</p>
<pre class="highlight"><code>&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({
...     "a": [1, 2, 3],
...     "sales": np.nan,
...     "score": [np.nan, 3, 2],
... })
&gt;&gt;&gt; df
   a  sales  score
0  1    NaN    NaN
1  2    NaN    3.0
2  3    NaN    2.0
</code></pre>
<p>Imputing null values with 0 (using the <code>value</code> parameter):</p>
<pre class="highlight"><code>&gt;&gt;&gt; df.impute(column_name="sales", value=0.0)
   a  sales  score
0  1    0.0    NaN
1  2    0.0    3.0
2  3    0.0    2.0
</code></pre>
<p>Imputing null values with median (using the <code>statistic_column_name</code>
parameter):</p>
<pre class="highlight"><code>&gt;&gt;&gt; df.impute(column_name="score", statistic_column_name="median")
   a  sales  score
0  1    0.0    2.5
1  2    0.0    3.0
2  3    0.0    2.0


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A pandas DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>column_name</code></td>
        <td><code>Hashable</code></td>
        <td><p>The name of the column on which to impute values.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>value</code></td>
        <td><code>Optional[Any]</code></td>
        <td><p>The value used for imputation, passed into <code>.fillna</code> method of the underlying pandas Series.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>statistic_column_name</code></td>
        <td><code>Optional[str]</code></td>
        <td><p>The column statistic to impute.</p></td>
        <td><code>None</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>An imputed pandas DataFrame.</p></td>
    </tr>
  </tbody>
</table>
<p><strong>Exceptions:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>ValueError</code></td>
        <td><p>If both <code>value</code> and <code>statistic_column_name</code> are provided.</p></td>
      </tr>
      <tr>
        <td><code>KeyError</code></td>
        <td><p>If <code>statistic_column_name</code> is not one of <code>mean</code>, <code>average</code>, <code>median</code>, <code>mode</code>, <code>minimum</code>, <code>min</code>, <code>maximum</code>, or <code>max</code>.</p></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/impute.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
@deprecated_alias(column="column_name")
@deprecated_alias(statistic="statistic_column_name")
def impute(
    df: pd.DataFrame,
    column_name: Hashable,
    value: Optional[Any] = None,
    statistic_column_name: Optional[str] = None,
) -&gt; pd.DataFrame:
    """
    Method-chainable imputation of values in a column.

    This method mutates the original DataFrame.

    Underneath the hood, this function calls the `.fillna()` method available
    to every `pandas.Series` object.

    Either one of `value` or `statistic_column_name` should be provided.

    If `value` is provided, then all null values in the selected column will
    take on the value provided.

    If `statistic_column_name` is provided, then all null values in the
    selected column will take on the summary statistic value of other non-null
    values.

    Currently supported statistics include:

    - `mean` (also aliased by `average`)
    - `median`
    - `mode`
    - `minimum` (also aliased by `min`)
    - `maximum` (also aliased by `max`)

    Example:

        &gt;&gt;&gt; import numpy as np
        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({
        ...     "a": [1, 2, 3],
        ...     "sales": np.nan,
        ...     "score": [np.nan, 3, 2],
        ... })
        &gt;&gt;&gt; df
           a  sales  score
        0  1    NaN    NaN
        1  2    NaN    3.0
        2  3    NaN    2.0

    Imputing null values with 0 (using the `value` parameter):

        &gt;&gt;&gt; df.impute(column_name="sales", value=0.0)
           a  sales  score
        0  1    0.0    NaN
        1  2    0.0    3.0
        2  3    0.0    2.0

    Imputing null values with median (using the `statistic_column_name`
    parameter):

        &gt;&gt;&gt; df.impute(column_name="score", statistic_column_name="median")
           a  sales  score
        0  1    0.0    2.5
        1  2    0.0    3.0
        2  3    0.0    2.0

    :param df: A pandas DataFrame.
    :param column_name: The name of the column on which to impute values.
    :param value: The value used for imputation, passed into `.fillna` method
        of the underlying pandas Series.
    :param statistic_column_name: The column statistic to impute.
    :returns: An imputed pandas DataFrame.
    :raises ValueError: If both `value` and `statistic_column_name` are
        provided.
    :raises KeyError: If `statistic_column_name` is not one of `mean`,
        `average`, `median`, `mode`, `minimum`, `min`, `maximum`, or `max`.
    """
    # Firstly, we check that only one of `value` or `statistic` are provided.
    if value is not None and statistic_column_name is not None:
        raise ValueError(
            "Only one of `value` or `statistic_column_name` should be "
            "provided."
        )

    # If statistic is provided, then we compute the relevant summary statistic
    # from the other data.
    funcs = {
        "mean": np.mean,
        "average": np.mean,  # aliased
        "median": np.median,
        "mode": ss.mode,
        "minimum": np.min,
        "min": np.min,  # aliased
        "maximum": np.max,
        "max": np.max,  # aliased
    }
    if statistic_column_name is not None:
        # Check that the statistic keyword argument is one of the approved.
        if statistic_column_name not in funcs:
            raise KeyError(
                f"`statistic_column_name` must be one of {funcs.keys()}."
            )

        value = funcs[statistic_column_name](
            df[column_name].dropna().to_numpy()
        )
        # special treatment for mode, because scipy stats mode returns a
        # moderesult object.
        if statistic_column_name == "mode":
            value = value.mode[0]

    # The code is architected this way - if `value` is not provided but
    # statistic is, we then overwrite the None value taken on by `value`, and
    # use it to set the imputation column.
    if value is not None:
        df[column_name] = df[column_name].fillna(value)
    return df
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.jitter" class="doc doc-heading">
        <code>jitter</code>



</h2>

    <div class="doc doc-contents ">

      <p>Implementation of the <code>jitter</code> function.</p>



  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.jitter.jitter" class="doc doc-heading">
<code class="highlight language-python">jitter(df, column_name, dest_column_name, scale, clip=None, random_state=None)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Adds Gaussian noise (jitter) to the values of a column.</p>
<p>Example:</p>
<pre class="highlight"><code>&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({"a": [3, 4, 5, np.nan]})
&gt;&gt;&gt; df
     a
0  3.0
1  4.0
2  5.0
3  NaN
&gt;&gt;&gt; df.jitter("a", dest_column_name="a_jit", scale=1, random_state=42)
     a     a_jit
0  3.0  3.496714
1  4.0  3.861736
2  5.0  5.647689
3  NaN       NaN
</code></pre>
<p>A new column will be created containing the values of the original column
with Gaussian noise added.
For each value in the column, a Gaussian distribution is created
having a location (mean) equal to the value
and a scale (standard deviation) equal to <code>scale</code>.
A random value is then sampled from this distribution,
which is the jittered value.
If a tuple is supplied for <code>clip</code>,
then any values of the new column less than <code>clip[0]</code>
will be set to <code>clip[0]</code>,
and any values greater than <code>clip[1]</code> will be set to <code>clip[1]</code>.
Additionally, if a numeric value is supplied for <code>random_state</code>,
this value will be used to set the random seed used for sampling.
NaN values are ignored in this method.</p>
<p>This method mutates the original DataFrame.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A pandas DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>column_name</code></td>
        <td><code>Hashable</code></td>
        <td><p>Name of the column containing values to add Gaussian jitter to.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>dest_column_name</code></td>
        <td><code>str</code></td>
        <td><p>The name of the new column containing the jittered values that will be created.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>scale</code></td>
        <td><code>number</code></td>
        <td><p>A positive value multiplied by the original column value to determine the scale (standard deviation) of the Gaussian distribution to sample from. (A value of zero results in no jittering.)</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>clip</code></td>
        <td><code>Optional[Iterable[numpy.number]]</code></td>
        <td><p>An iterable of two values (minimum and maximum) to clip the jittered values to, default to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>random_state</code></td>
        <td><code>Optional[numpy.number]</code></td>
        <td><p>An integer or 1-d array value used to set the random seed, default to None.</p></td>
        <td><code>None</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame with a new column containing Gaussian-jittered values from another column.</p></td>
    </tr>
  </tbody>
</table>
<p><strong>Exceptions:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>TypeError</code></td>
        <td><p>If <code>column_name</code> is not numeric.</p></td>
      </tr>
      <tr>
        <td><code>ValueError</code></td>
        <td><p>If <code>scale</code> is not a numerical value greater than <code>0</code>.</p></td>
      </tr>
      <tr>
        <td><code>ValueError</code></td>
        <td><p>If <code>clip</code> is not an iterable of length <code>2</code>.</p></td>
      </tr>
      <tr>
        <td><code>ValueError</code></td>
        <td><p>If <code>clip[0]</code> is greater than <code>clip[1]</code>.</p></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/jitter.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
def jitter(
    df: pd.DataFrame,
    column_name: Hashable,
    dest_column_name: str,
    scale: np.number,
    clip: Optional[Iterable[np.number]] = None,
    random_state: Optional[np.number] = None,
) -&gt; pd.DataFrame:
    """
    Adds Gaussian noise (jitter) to the values of a column.

    Example:

        &gt;&gt;&gt; import numpy as np
        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({"a": [3, 4, 5, np.nan]})
        &gt;&gt;&gt; df
             a
        0  3.0
        1  4.0
        2  5.0
        3  NaN
        &gt;&gt;&gt; df.jitter("a", dest_column_name="a_jit", scale=1, random_state=42)
             a     a_jit
        0  3.0  3.496714
        1  4.0  3.861736
        2  5.0  5.647689
        3  NaN       NaN

    A new column will be created containing the values of the original column
    with Gaussian noise added.
    For each value in the column, a Gaussian distribution is created
    having a location (mean) equal to the value
    and a scale (standard deviation) equal to `scale`.
    A random value is then sampled from this distribution,
    which is the jittered value.
    If a tuple is supplied for `clip`,
    then any values of the new column less than `clip[0]`
    will be set to `clip[0]`,
    and any values greater than `clip[1]` will be set to `clip[1]`.
    Additionally, if a numeric value is supplied for `random_state`,
    this value will be used to set the random seed used for sampling.
    NaN values are ignored in this method.

    This method mutates the original DataFrame.

    :param df: A pandas DataFrame.
    :param column_name: Name of the column containing
        values to add Gaussian jitter to.
    :param dest_column_name: The name of the new column containing the
        jittered values that will be created.
    :param scale: A positive value multiplied by the original
        column value to determine the scale (standard deviation) of the
        Gaussian distribution to sample from. (A value of zero results in
        no jittering.)
    :param clip: An iterable of two values (minimum and maximum) to clip
        the jittered values to, default to None.
    :param random_state: An integer or 1-d array value used to set the random
        seed, default to None.

    :returns: A pandas DataFrame with a new column containing
        Gaussian-jittered values from another column.
    :raises TypeError: If `column_name` is not numeric.
    :raises ValueError: If `scale` is not a numerical value
        greater than `0`.
    :raises ValueError: If `clip` is not an iterable of length `2`.
    :raises ValueError: If `clip[0]` is greater than `clip[1]`.
    """

    # Check types
    check("scale", scale, [int, float])

    # Check that `column_name` is a numeric column
    if not np.issubdtype(df[column_name].dtype, np.number):
        raise TypeError(f"{column_name} must be a numeric column.")

    if scale &lt;= 0:
        raise ValueError("`scale` must be a numeric value greater than 0.")
    values = df[column_name]
    if random_state is not None:
        np.random.seed(random_state)
    result = np.random.normal(loc=values, scale=scale)
    if clip:
        # Ensure `clip` has length 2
        if len(clip) != 2:
            raise ValueError("`clip` must be an iterable of length 2.")
        # Ensure the values in `clip` are ordered as min, max
        if clip[1] &lt; clip[0]:
            raise ValueError(
                "`clip[0]` must be less than or equal to `clip[1]`."
            )
        result = np.clip(result, *clip)
    df[dest_column_name] = result

    return df
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.join_apply" class="doc doc-heading">
        <code>join_apply</code>



</h2>

    <div class="doc doc-contents ">

      <p>Implementation of the <code>join_apply</code> function</p>



  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.join_apply.join_apply" class="doc doc-heading">
<code class="highlight language-python">join_apply(df, func, new_column_name)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Join the result of applying a function across dataframe rows.</p>
<p>This method does not mutate the original DataFrame.</p>
<p>This is a convenience function that allows us to apply arbitrary functions
that take any combination of information from any of the columns. The only
requirement is that the function signature takes in a row from the
DataFrame.</p>
<p>Example: Sum the result of two columns into a new column.</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({"a":[1, 2, 3], "b": [2, 3, 4]})
&gt;&gt;&gt; df
   a  b
0  1  2
1  2  3
2  3  4
&gt;&gt;&gt; df.join_apply(
...     func=lambda x: 2 * x["a"] + x["b"],
...     new_column_name="2a+b",
... )
   a  b  2a+b
0  1  2     4
1  2  3     7
2  3  4    10
</code></pre>
<p>Example: Incorporating conditionals in <code>func</code>.</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({"a": [1, 2, 3], "b": [20, 30, 40]})
&gt;&gt;&gt; df
   a   b
0  1  20
1  2  30
2  3  40
&gt;&gt;&gt; def take_a_if_even(x):
...     if x["a"] % 2 == 0:
...         return x["a"]
...     else:
...         return x["b"]
&gt;&gt;&gt; df.join_apply(take_a_if_even, "a_if_even")
   a   b  a_if_even
0  1  20         20
1  2  30          2
2  3  40         40


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A pandas DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>func</code></td>
        <td><code>Callable</code></td>
        <td><p>A function that is applied elementwise across all rows of the DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>new_column_name</code></td>
        <td><code>str</code></td>
        <td><p>Name of the resulting column.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame with new column appended.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/join_apply.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
def join_apply(
    df: pd.DataFrame,
    func: Callable,
    new_column_name: str,
) -&gt; pd.DataFrame:
    """
    Join the result of applying a function across dataframe rows.

    This method does not mutate the original DataFrame.

    This is a convenience function that allows us to apply arbitrary functions
    that take any combination of information from any of the columns. The only
    requirement is that the function signature takes in a row from the
    DataFrame.

    Example: Sum the result of two columns into a new column.

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({"a":[1, 2, 3], "b": [2, 3, 4]})
        &gt;&gt;&gt; df
           a  b
        0  1  2
        1  2  3
        2  3  4
        &gt;&gt;&gt; df.join_apply(
        ...     func=lambda x: 2 * x["a"] + x["b"],
        ...     new_column_name="2a+b",
        ... )
           a  b  2a+b
        0  1  2     4
        1  2  3     7
        2  3  4    10

    Example: Incorporating conditionals in `func`.

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({"a": [1, 2, 3], "b": [20, 30, 40]})
        &gt;&gt;&gt; df
           a   b
        0  1  20
        1  2  30
        2  3  40
        &gt;&gt;&gt; def take_a_if_even(x):
        ...     if x["a"] % 2 == 0:
        ...         return x["a"]
        ...     else:
        ...         return x["b"]
        &gt;&gt;&gt; df.join_apply(take_a_if_even, "a_if_even")
           a   b  a_if_even
        0  1  20         20
        1  2  30          2
        2  3  40         40

    :param df: A pandas DataFrame.
    :param func: A function that is applied elementwise across all rows of the
        DataFrame.
    :param new_column_name: Name of the resulting column.
    :returns: A pandas DataFrame with new column appended.
    """
    df = df.copy().join(df.apply(func, axis=1).rename(new_column_name))
    return df
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.label_encode" class="doc doc-heading">
        <code>label_encode</code>



</h2>

    <div class="doc doc-contents ">

      <p>Implementation of <code>label_encode</code> function</p>



  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.label_encode.label_encode" class="doc doc-heading">
<code class="highlight language-python">label_encode(df, column_names)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Convert labels into numerical data.</p>
<p>This method will create a new column with the string <code>_enc</code> appended
after the original column's name.
Consider this to be syntactic sugar.
This function uses the <code>factorize</code> pandas function under the hood.</p>
<p>This method behaves differently from
<a class="autorefs autorefs-internal" href="#janitor.functions.encode_categorical.encode_categorical"><code>encode_categorical</code></a>.
This method creates a new column of numeric data.
<a class="autorefs autorefs-internal" href="#janitor.functions.encode_categorical.encode_categorical"><code>encode_categorical</code></a>
replaces the dtype of the original column with a <em>categorical</em> dtype.</p>
<p>This method mutates the original DataFrame.</p>
<p>Example:</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({
...     "foo": ["b", "b", "a", "c", "b"],
...     "bar": range(4, 9),
... })
&gt;&gt;&gt; df
  foo  bar
0   b    4
1   b    5
2   a    6
3   c    7
4   b    8
&gt;&gt;&gt; df.label_encode(column_names="foo")
  foo  bar  foo_enc
0   b    4        0
1   b    5        0
2   a    6        1
3   c    7        2
4   b    8        0
</code></pre>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function will be deprecated in a 1.x release.
Please use <a class="autorefs autorefs-internal" href="#janitor.functions.factorize_columns.factorize_columns"><code>factorize_columns</code></a>
instead.</p>
</div>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>The pandas DataFrame object.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>column_names</code></td>
        <td><code>Union[str, Iterable[str], Hashable]</code></td>
        <td><p>A column name or an iterable (list or tuple) of column names.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/label_encode.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
@deprecated_alias(columns="column_names")
def label_encode(
    df: pd.DataFrame,
    column_names: Union[str, Iterable[str], Hashable],
) -&gt; pd.DataFrame:
    """
    Convert labels into numerical data.

    This method will create a new column with the string `_enc` appended
    after the original column's name.
    Consider this to be syntactic sugar.
    This function uses the `factorize` pandas function under the hood.

    This method behaves differently from
    [`encode_categorical`][janitor.functions.encode_categorical.encode_categorical].
    This method creates a new column of numeric data.
    [`encode_categorical`][janitor.functions.encode_categorical.encode_categorical]
    replaces the dtype of the original column with a *categorical* dtype.

    This method mutates the original DataFrame.

    Example:

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({
        ...     "foo": ["b", "b", "a", "c", "b"],
        ...     "bar": range(4, 9),
        ... })
        &gt;&gt;&gt; df
          foo  bar
        0   b    4
        1   b    5
        2   a    6
        3   c    7
        4   b    8
        &gt;&gt;&gt; df.label_encode(column_names="foo")
          foo  bar  foo_enc
        0   b    4        0
        1   b    5        0
        2   a    6        1
        3   c    7        2
        4   b    8        0

    !!!note

        This function will be deprecated in a 1.x release.
        Please use [`factorize_columns`][janitor.functions.factorize_columns.factorize_columns]
        instead.

    :param df: The pandas DataFrame object.
    :param column_names: A column name or an iterable (list
        or tuple) of column names.
    :returns: A pandas DataFrame.
    """  # noqa: E501
    warnings.warn(
        "`label_encode` will be deprecated in a 1.x release. "
        "Please use `factorize_columns` instead."
    )
    df = _factorize(df, column_names, "_enc")
    return df
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.limit_column_characters" class="doc doc-heading">
        <code>limit_column_characters</code>



</h2>

    <div class="doc doc-contents ">

      <p>Implementation of limit_column_characters.</p>



  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.limit_column_characters.limit_column_characters" class="doc doc-heading">
<code class="highlight language-python">limit_column_characters(df, column_length, col_separator='_')</code>


</h3>

    <div class="doc doc-contents ">

      <p>Truncate column sizes to a specific length.</p>
<p>This method mutates the original DataFrame.</p>
<p>Method chaining will truncate all columns to a given length and append
a given separator character with the index of duplicate columns, except
for the first distinct column name.</p>
<p>Example:</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; data_dict = {
...     "really_long_name": [9, 8, 7],
...     "another_really_long_name": [2, 4, 6],
...     "another_really_longer_name": list("xyz"),
...     "this_is_getting_out_of_hand": list("pqr"),
... }
&gt;&gt;&gt; df = pd.DataFrame(data_dict)
&gt;&gt;&gt; df  # doctest: +SKIP
   really_long_name  another_really_long_name another_really_longer_name this_is_getting_out_of_hand
0                 9                         2                          x                           p
1                 8                         4                          y                           q
2                 7                         6                          z                           r
&gt;&gt;&gt; df.limit_column_characters(7)
   really_  another another_1 this_is
0        9        2         x       p
1        8        4         y       q
2        7        6         z       r


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A pandas DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>column_length</code></td>
        <td><code>int</code></td>
        <td><p>Character length for which to truncate all columns. The column separator value and number for duplicate column name does not contribute. Therefore, if all columns are truncated to 10 characters, the first distinct column will be 10 characters and the remaining will be 12 characters (assuming a column separator of one character).</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>col_separator</code></td>
        <td><code>str</code></td>
        <td><p>The separator to use for counting distinct column values, for example, <code>'_'</code> or <code>'.'</code>. Supply an empty string (i.e. <code>''</code>) to remove the separator.</p></td>
        <td><code>&#39;_&#39;</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame with truncated column lengths.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/limit_column_characters.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
def limit_column_characters(
    df: pd.DataFrame,
    column_length: int,
    col_separator: str = "_",
) -&gt; pd.DataFrame:
    """Truncate column sizes to a specific length.

    This method mutates the original DataFrame.

    Method chaining will truncate all columns to a given length and append
    a given separator character with the index of duplicate columns, except
    for the first distinct column name.

    Example:

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; data_dict = {
        ...     "really_long_name": [9, 8, 7],
        ...     "another_really_long_name": [2, 4, 6],
        ...     "another_really_longer_name": list("xyz"),
        ...     "this_is_getting_out_of_hand": list("pqr"),
        ... }
        &gt;&gt;&gt; df = pd.DataFrame(data_dict)
        &gt;&gt;&gt; df  # doctest: +SKIP
           really_long_name  another_really_long_name another_really_longer_name this_is_getting_out_of_hand
        0                 9                         2                          x                           p
        1                 8                         4                          y                           q
        2                 7                         6                          z                           r
        &gt;&gt;&gt; df.limit_column_characters(7)
           really_  another another_1 this_is
        0        9        2         x       p
        1        8        4         y       q
        2        7        6         z       r

    :param df: A pandas DataFrame.
    :param column_length: Character length for which to truncate all columns.
        The column separator value and number for duplicate column name does
        not contribute. Therefore, if all columns are truncated to 10
        characters, the first distinct column will be 10 characters and the
        remaining will be 12 characters (assuming a column separator of one
        character).
    :param col_separator: The separator to use for counting distinct column
        values, for example, `'_'` or `'.'`.
        Supply an empty string (i.e. `''`) to remove the separator.
    :returns: A pandas DataFrame with truncated column lengths.
    """  # noqa: E501

    check("column_length", column_length, [int])
    check("col_separator", col_separator, [str])

    col_names = df.columns
    col_names = [col_name[:column_length] for col_name in col_names]

    col_name_set = set(col_names)
    col_name_count = {}

    # If no columns are duplicates, we can skip the loops below.
    if len(col_name_set) == len(col_names):
        df.columns = col_names
        return df

    for col_name_to_check in col_name_set:
        count = 0
        for idx, col_name in enumerate(col_names):
            if col_name_to_check == col_name:
                col_name_count[idx] = count
                count += 1

    final_col_names = []
    for idx, col_name in enumerate(col_names):
        if col_name_count[idx] &gt; 0:
            col_name_to_append = (
                col_name + col_separator + str(col_name_count[idx])
            )
            final_col_names.append(col_name_to_append)
        else:
            final_col_names.append(col_name)

    df.columns = final_col_names
    return df
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.min_max_scale" class="doc doc-heading">
        <code>min_max_scale</code>



</h2>

    <div class="doc doc-contents ">




  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.min_max_scale.min_max_scale" class="doc doc-heading">
<code class="highlight language-python">min_max_scale(df, feature_range=(0, 1), column_name=None, jointly=False)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Scales DataFrame to between a minimum and maximum value.</p>
<p>One can optionally set a new target <strong>minimum</strong> and <strong>maximum</strong> value
using the <code>feature_range</code> keyword argument.</p>
<p>If <code>column_name</code> is specified, then only that column(s) of data is scaled.
Otherwise, the entire dataframe is scaled.
If <code>jointly</code> is <code>True</code>, the <code>column_names</code> provided entire dataframe will
be regnozied as the one to jointly scale. Otherwise, each column of data
will be scaled separately.</p>
<p>Example: Basic usage.</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({'a':[1, 2], 'b':[0, 1]})
&gt;&gt;&gt; df.min_max_scale()
     a    b
0  0.0  0.0
1  1.0  1.0
&gt;&gt;&gt; df.min_max_scale(jointly=True)
     a    b
0  0.5  0.0
1  1.0  0.5
</code></pre>
<p>Example: Setting custom minimum and maximum.</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({'a':[1, 2], 'b':[0, 1]})
&gt;&gt;&gt; df.min_max_scale(feature_range=(0, 100))
       a      b
0    0.0    0.0
1  100.0  100.0
&gt;&gt;&gt; df.min_max_scale(feature_range=(0, 100), jointly=True)
       a     b
0   50.0   0.0
1  100.0  50.0
</code></pre>
<p>Example: Apply min-max to the selected columns.</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({'a':[1, 2], 'b':[0, 1], 'c': [1, 0]})
&gt;&gt;&gt; df.min_max_scale(
...     feature_range=(0, 100),
...     column_name=["a", "c"],
... )
       a  b      c
0    0.0  0  100.0
1  100.0  1    0.0
&gt;&gt;&gt; df.min_max_scale(
...     feature_range=(0, 100),
...     column_name=["a", "c"],
...     jointly=True,
... )
       a  b     c
0   50.0  0  50.0
1  100.0  1   0.0
&gt;&gt;&gt; df.min_max_scale(feature_range=(0, 100), column_name='a')
       a  b  c
0    0.0  0  1
1  100.0  1  0
</code></pre>
<p>The aforementioned example might be applied to something like scaling the
isoelectric points of amino acids. While technically they range from
approx 3-10, we can also think of them on the pH scale which ranges from
1 to 14. Hence, 3 gets scaled not to 0 but approx. 0.15 instead, while 10
gets scaled to approx. 0.69 instead.</p>
<div class="admonition summary">
<p class="admonition-title">Version Changed</p>
<ul>
<li>0.24.0<ul>
<li>Deleted <code>old_min</code>, <code>old_max</code>, <code>new_min</code>, and <code>new_max</code> options.</li>
<li>Added <code>feature_range</code>, and <code>jointly</code> options.</li>
</ul>
</li>
</ul>
</div>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>pd.DataFrame</code></td>
        <td><p>A pandas DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>feature_range</code></td>
        <td><code>tuple[int | float, int | float]</code></td>
        <td><p>(optional) Desired range of transformed data.</p></td>
        <td><code>(0, 1)</code></td>
      </tr>
      <tr>
        <td><code>column_name</code></td>
        <td><code>str | int | list[str | int] | pd.Index</code></td>
        <td><p>(optional) The column on which to perform scaling.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>jointly</code></td>
        <td><code>bool</code></td>
        <td><p>(bool) Scale the entire data if Ture.</p></td>
        <td><code>False</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>pd.DataFrame</code></td>
      <td><p>A pandas DataFrame with scaled data.</p></td>
    </tr>
  </tbody>
</table>
<p><strong>Exceptions:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>ValueError</code></td>
        <td><p>if <code>feature_range</code> isn't tuple type.</p></td>
      </tr>
      <tr>
        <td><code>ValueError</code></td>
        <td><p>if the length of <code>feature_range</code> isn't equal to two.</p></td>
      </tr>
      <tr>
        <td><code>ValueError</code></td>
        <td><p>if the element of <code>feature_range</code> isn't number type.</p></td>
      </tr>
      <tr>
        <td><code>ValueError</code></td>
        <td><p>if <code>feature_range[1]</code> &lt;= <code>feature_range[0]</code>.</p></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/min_max_scale.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
@deprecated_kwargs(
    "old_min",
    "old_max",
    "new_min",
    "new_max",
    message=(
        "The keyword argument {argument!r} of {func_name!r} is deprecated. "
        "Please use 'feature_range' instead."
    ),
)
@deprecated_alias(col_name="column_name")
def min_max_scale(
    df: pd.DataFrame,
    feature_range: tuple[int | float, int | float] = (0, 1),
    column_name: str | int | list[str | int] | pd.Index = None,
    jointly: bool = False,
) -&gt; pd.DataFrame:
    """
    Scales DataFrame to between a minimum and maximum value.

    One can optionally set a new target **minimum** and **maximum** value
    using the `feature_range` keyword argument.

    If `column_name` is specified, then only that column(s) of data is scaled.
    Otherwise, the entire dataframe is scaled.
    If `jointly` is `True`, the `column_names` provided entire dataframe will
    be regnozied as the one to jointly scale. Otherwise, each column of data
    will be scaled separately.

    Example: Basic usage.

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({'a':[1, 2], 'b':[0, 1]})
        &gt;&gt;&gt; df.min_max_scale()
             a    b
        0  0.0  0.0
        1  1.0  1.0
        &gt;&gt;&gt; df.min_max_scale(jointly=True)
             a    b
        0  0.5  0.0
        1  1.0  0.5

    Example: Setting custom minimum and maximum.

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({'a':[1, 2], 'b':[0, 1]})
        &gt;&gt;&gt; df.min_max_scale(feature_range=(0, 100))
               a      b
        0    0.0    0.0
        1  100.0  100.0
        &gt;&gt;&gt; df.min_max_scale(feature_range=(0, 100), jointly=True)
               a     b
        0   50.0   0.0
        1  100.0  50.0

    Example: Apply min-max to the selected columns.

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({'a':[1, 2], 'b':[0, 1], 'c': [1, 0]})
        &gt;&gt;&gt; df.min_max_scale(
        ...     feature_range=(0, 100),
        ...     column_name=["a", "c"],
        ... )
               a  b      c
        0    0.0  0  100.0
        1  100.0  1    0.0
        &gt;&gt;&gt; df.min_max_scale(
        ...     feature_range=(0, 100),
        ...     column_name=["a", "c"],
        ...     jointly=True,
        ... )
               a  b     c
        0   50.0  0  50.0
        1  100.0  1   0.0
        &gt;&gt;&gt; df.min_max_scale(feature_range=(0, 100), column_name='a')
               a  b  c
        0    0.0  0  1
        1  100.0  1  0

    The aforementioned example might be applied to something like scaling the
    isoelectric points of amino acids. While technically they range from
    approx 3-10, we can also think of them on the pH scale which ranges from
    1 to 14. Hence, 3 gets scaled not to 0 but approx. 0.15 instead, while 10
    gets scaled to approx. 0.69 instead.

    !!! summary "Version Changed"

        - 0.24.0
            - Deleted `old_min`, `old_max`, `new_min`, and `new_max` options.
            - Added `feature_range`, and `jointly` options.

    :param df: A pandas DataFrame.
    :param feature_range: (optional) Desired range of transformed data.
    :param column_name: (optional) The column on which to perform scaling.
    :param jointly: (bool) Scale the entire data if Ture.
    :returns: A pandas DataFrame with scaled data.
    :raises ValueError: if `feature_range` isn't tuple type.
    :raises ValueError: if the length of `feature_range` isn't equal to two.
    :raises ValueError: if the element of `feature_range` isn't number type.
    :raises ValueError: if `feature_range[1]` &lt;= `feature_range[0]`.
    """

    if not (
        isinstance(feature_range, (tuple, list))
        and len(feature_range) == 2
        and all((isinstance(i, (int, float))) for i in feature_range)
        and feature_range[1] &gt; feature_range[0]
    ):
        raise ValueError(
            "`feature_range` should be a range type contains number element, "
            "the first element must be greater than the second one"
        )

    if column_name is not None:
        df = df.copy()  # Avoid to change the original DataFrame.

        old_feature_range = df[column_name].pipe(_min_max_value, jointly)
        df[column_name] = df[column_name].pipe(
            _apply_min_max,
            *old_feature_range,
            *feature_range,
        )
    else:
        old_feature_range = df.pipe(_min_max_value, jointly)
        df = df.pipe(
            _apply_min_max,
            *old_feature_range,
            *feature_range,
        )

    return df
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.move" class="doc doc-heading">
        <code>move</code>



</h2>

    <div class="doc doc-contents ">

      <p>Implementation of move.</p>



  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.move.move" class="doc doc-heading">
<code class="highlight language-python">move(df, source, target, position='before', axis=0)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Moves a column or row to a position adjacent to another column or row in
the dataframe.</p>
<p>This operation does not reset the index of the dataframe. User must
explicitly do so.</p>
<p>This function does not apply to multilevel dataframes, and the dataframe
must have unique column names or indices.</p>
<p>Example: Moving a row</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({"a": [2, 4, 6, 8], "b": list("wxyz")})
&gt;&gt;&gt; df
   a  b
0  2  w
1  4  x
2  6  y
3  8  z
&gt;&gt;&gt; df.move(source=0, target=3, position="before", axis=0)
   a  b
1  4  x
2  6  y
0  2  w
3  8  z
</code></pre>
<p>Example: Moving a column</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({"a": [2, 4, 6], "b": [1, 3, 5], "c": [7, 8, 9]})
&gt;&gt;&gt; df
   a  b  c
0  2  1  7
1  4  3  8
2  6  5  9
&gt;&gt;&gt; df.move(source="a", target="c", position="after", axis=1)
   b  c  a
0  1  7  2
1  3  8  4
2  5  9  6


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>The pandas DataFrame object.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>source</code></td>
        <td><code>Union[int, str]</code></td>
        <td><p>Column or row to move.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>target</code></td>
        <td><code>Union[int, str]</code></td>
        <td><p>Column or row to move adjacent to.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>position</code></td>
        <td><code>str</code></td>
        <td><p>Specifies whether the Series is moved to before or after the adjacent Series. Values can be either <code>before</code> or <code>after</code>; defaults to <code>before</code>.</p></td>
        <td><code>&#39;before&#39;</code></td>
      </tr>
      <tr>
        <td><code>axis</code></td>
        <td><code>int</code></td>
        <td><p>Axis along which the function is applied. 0 to move a row, 1 to move a column.</p></td>
        <td><code>0</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>The dataframe with the Series moved.</p></td>
    </tr>
  </tbody>
</table>
<p><strong>Exceptions:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>ValueError</code></td>
        <td><p>If <code>axis</code> is not <code>0</code> or <code>1</code>.</p></td>
      </tr>
      <tr>
        <td><code>ValueError</code></td>
        <td><p>If <code>position</code> is not <code>before</code> or <code>after</code>.</p></td>
      </tr>
      <tr>
        <td><code>ValueError</code></td>
        <td><p>If  <code>source</code> row or column is not in dataframe.</p></td>
      </tr>
      <tr>
        <td><code>ValueError</code></td>
        <td><p>If <code>target</code> row or column is not in dataframe.</p></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/move.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
def move(
    df: pd.DataFrame,
    source: Union[int, str],
    target: Union[int, str],
    position: str = "before",
    axis: int = 0,
) -&gt; pd.DataFrame:
    """
    Moves a column or row to a position adjacent to another column or row in
    the dataframe.

    This operation does not reset the index of the dataframe. User must
    explicitly do so.

    This function does not apply to multilevel dataframes, and the dataframe
    must have unique column names or indices.

    Example: Moving a row

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({"a": [2, 4, 6, 8], "b": list("wxyz")})
        &gt;&gt;&gt; df
           a  b
        0  2  w
        1  4  x
        2  6  y
        3  8  z
        &gt;&gt;&gt; df.move(source=0, target=3, position="before", axis=0)
           a  b
        1  4  x
        2  6  y
        0  2  w
        3  8  z

    Example: Moving a column

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({"a": [2, 4, 6], "b": [1, 3, 5], "c": [7, 8, 9]})
        &gt;&gt;&gt; df
           a  b  c
        0  2  1  7
        1  4  3  8
        2  6  5  9
        &gt;&gt;&gt; df.move(source="a", target="c", position="after", axis=1)
           b  c  a
        0  1  7  2
        1  3  8  4
        2  5  9  6

    :param df: The pandas DataFrame object.
    :param source: Column or row to move.
    :param target: Column or row to move adjacent to.
    :param position: Specifies whether the Series is moved to before or
        after the adjacent Series. Values can be either `before` or `after`;
        defaults to `before`.
    :param axis: Axis along which the function is applied. 0 to move a
        row, 1 to move a column.
    :returns: The dataframe with the Series moved.
    :raises ValueError: If `axis` is not `0` or `1`.
    :raises ValueError: If `position` is not `before` or `after`.
    :raises ValueError: If  `source` row or column is not in dataframe.
    :raises ValueError: If `target` row or column is not in dataframe.
    """
    if axis not in [0, 1]:
        raise ValueError(f"Invalid axis '{axis}'. Can only be 0 or 1.")

    if position not in ["before", "after"]:
        raise ValueError(
            f"Invalid position '{position}'. Can only be 'before' or 'after'."
        )

    df = df.copy()
    if axis == 0:
        names = list(df.index)

        if source not in names:
            raise ValueError(f"Source row '{source}' not in dataframe.")

        if target not in names:
            raise ValueError(f"Target row '{target}' not in dataframe.")

        names.remove(source)
        pos = names.index(target)

        if position == "after":
            pos += 1
        names.insert(pos, source)

        df = df.loc[names, :]
    else:
        names = list(df.columns)

        if source not in names:
            raise ValueError(f"Source column '{source}' not in dataframe.")

        if target not in names:
            raise ValueError(f"Target column '{target}' not in dataframe.")

        names.remove(source)
        pos = names.index(target)

        if position == "after":
            pos += 1
        names.insert(pos, source)

        df = df.loc[:, names]

    return df
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.pivot" class="doc doc-heading">
        <code>pivot</code>



</h2>

    <div class="doc doc-contents ">




  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.pivot.pivot_longer" class="doc doc-heading">
<code class="highlight language-python">pivot_longer(df, index=None, column_names=None, names_to=None, values_to='value', column_level=None, names_sep=None, names_pattern=None, names_transform=None, dropna=False, sort_by_appearance=False, ignore_index=True)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Unpivots a DataFrame from <em>wide</em> to <em>long</em> format.</p>
<p>This method does not mutate the original DataFrame.</p>
<p>It is modeled after the <code>pivot_longer</code> function in R's tidyr package,
and also takes inspiration from R's data.table package.</p>
<p>This function is useful to massage a DataFrame into a format where
one or more columns are considered measured variables, and all other
columns are considered as identifier variables.</p>
<p>All measured variables are <em>unpivoted</em> (and typically duplicated) along the
row axis.</p>
<p>Column selection in <code>index</code> and <code>column_names</code> is possible using the
<a class="autorefs autorefs-internal" href="#janitor.functions.select.select_columns"><code>select_columns</code></a> syntax.</p>
<p>Example:</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame(
...     {
...         "Sepal.Length": [5.1, 5.9],
...         "Sepal.Width": [3.5, 3.0],
...         "Petal.Length": [1.4, 5.1],
...         "Petal.Width": [0.2, 1.8],
...         "Species": ["setosa", "virginica"],
...     }
... )
&gt;&gt;&gt; df
   Sepal.Length  Sepal.Width  Petal.Length  Petal.Width    Species
0           5.1          3.5           1.4          0.2     setosa
1           5.9          3.0           5.1          1.8  virginica
</code></pre>
<p>Replicate pandas' melt:</p>
<pre class="highlight"><code>&gt;&gt;&gt; df.pivot_longer(index = 'Species')
     Species      variable  value
0     setosa  Sepal.Length    5.1
1  virginica  Sepal.Length    5.9
2     setosa   Sepal.Width    3.5
3  virginica   Sepal.Width    3.0
4     setosa  Petal.Length    1.4
5  virginica  Petal.Length    5.1
6     setosa   Petal.Width    0.2
7  virginica   Petal.Width    1.8
</code></pre>
<p>Split the column labels into parts:</p>
<pre class="highlight"><code>&gt;&gt;&gt; df.pivot_longer(
...     index = 'Species',
...     names_to = ('part', 'dimension'),
...     names_sep = '.',
...     sort_by_appearance = True,
... )
     Species   part dimension  value
0     setosa  Sepal    Length    5.1
1     setosa  Sepal     Width    3.5
2     setosa  Petal    Length    1.4
3     setosa  Petal     Width    0.2
4  virginica  Sepal    Length    5.9
5  virginica  Sepal     Width    3.0
6  virginica  Petal    Length    5.1
7  virginica  Petal     Width    1.8
</code></pre>
<p>Retain parts of the column names as headers:</p>
<pre class="highlight"><code>&gt;&gt;&gt; df.pivot_longer(
...     index = 'Species',
...     names_to = ('part', '.value'),
...     names_sep = '.',
...     sort_by_appearance = True,
... )
     Species   part  Length  Width
0     setosa  Sepal     5.1    3.5
1     setosa  Petal     1.4    0.2
2  virginica  Sepal     5.9    3.0
3  virginica  Petal     5.1    1.8
</code></pre>
<p>Split the column labels based on regex:</p>
<pre class="highlight"><code>&gt;&gt;&gt; df = pd.DataFrame({"id": [1], "new_sp_m5564": [2], "newrel_f65": [3]})
&gt;&gt;&gt; df
   id  new_sp_m5564  newrel_f65
0   1             2           3
&gt;&gt;&gt; df.pivot_longer(
...     index = 'id',
...     names_to = ('diagnosis', 'gender', 'age'),
...     names_pattern = r"new_?(.+)_(.)(\d+)",
... )
   id diagnosis gender   age  value
0   1        sp      m  5564      2
1   1       rel      f    65      3
</code></pre>
<p>Convert the dtypes of specific columns with <code>names_transform</code>:</p>
<pre class="highlight"><code>&gt;&gt;&gt; result = (df
...          .pivot_longer(
...              index = 'id',
...              names_to = ('diagnosis', 'gender', 'age'),
...              names_pattern = r"new_?(.+)_(.)(\d+)",
...              names_transform = {'gender': 'category', 'age':'int'})
... )
&gt;&gt;&gt; result.dtypes
id           int64
gender    category
age          int64
value        int64
dtype: object
</code></pre>
<p>Use multiple <code>.value</code> to reshape dataframe:</p>
<pre class="highlight"><code>&gt;&gt;&gt; df = pd.DataFrame(
...     [
...         {
...             "x_1_mean": 10,
...             "x_2_mean": 20,
...             "y_1_mean": 30,
...             "y_2_mean": 40,
...             "unit": 50,
...         }
...     ]
... )
&gt;&gt;&gt; df
   x_1_mean  x_2_mean  y_1_mean  y_2_mean  unit
0        10        20        30        40    50
&gt;&gt;&gt; df.pivot_longer(
...     index="unit",
...     names_to=(".value", "time", ".value"),
...     names_pattern=r"(x|y)_([0-9])(_mean)",
... )
   unit time  x_mean  y_mean
0    50    1      10      30
1    50    2      20      40
</code></pre>
<p>Multiple values_to:</p>
<pre class="highlight"><code>&gt;&gt;&gt; df = pd.DataFrame(
...         {
...             "City": ["Houston", "Austin", "Hoover"],
...             "State": ["Texas", "Texas", "Alabama"],
...             "Name": ["Aria", "Penelope", "Niko"],
...             "Mango": [4, 10, 90],
...             "Orange": [10, 8, 14],
...             "Watermelon": [40, 99, 43],
...             "Gin": [16, 200, 34],
...             "Vodka": [20, 33, 18],
...         },
...         columns=[
...             "City",
...             "State",
...             "Name",
...             "Mango",
...             "Orange",
...             "Watermelon",
...             "Gin",
...             "Vodka",
...         ],
...     )
&gt;&gt;&gt; df
      City    State      Name  Mango  Orange  Watermelon  Gin  Vodka
0  Houston    Texas      Aria      4      10          40   16     20
1   Austin    Texas  Penelope     10       8          99  200     33
2   Hoover  Alabama      Niko     90      14          43   34     18
&gt;&gt;&gt; df.pivot_longer(
...         index=["City", "State"],
...         column_names=slice("Mango", "Vodka"),
...         names_to=("Fruit", "Drink"),
...         values_to=("Pounds", "Ounces"),
...         names_pattern=[r"M|O|W", r"G|V"],
...     )
      City    State       Fruit  Pounds  Drink  Ounces
0  Houston    Texas       Mango       4    Gin    16.0
1   Austin    Texas       Mango      10    Gin   200.0
2   Hoover  Alabama       Mango      90    Gin    34.0
3  Houston    Texas      Orange      10  Vodka    20.0
4   Austin    Texas      Orange       8  Vodka    33.0
5   Hoover  Alabama      Orange      14  Vodka    18.0
6  Houston    Texas  Watermelon      40   None     NaN
7   Austin    Texas  Watermelon      99   None     NaN
8   Hoover  Alabama  Watermelon      43   None     NaN
</code></pre>
<div class="admonition abstract">
<p class="admonition-title">Version Changed</p>
<ul>
<li>0.24.0<ul>
<li>Added <code>dropna</code> parameter.</li>
</ul>
</li>
</ul>
</div>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A pandas DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>index</code></td>
        <td><code>Union[list, tuple, str, Pattern]</code></td>
        <td><p>Name(s) of columns to use as identifier variables. Should be either a single column name, or a list/tuple of column names. <code>index</code> should be a list of tuples if the columns are a MultiIndex.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>column_names</code></td>
        <td><code>Union[list, tuple, str, Pattern]</code></td>
        <td><p>Name(s) of columns to unpivot. Should be either a single column name or a list/tuple of column names. <code>column_names</code> should be a list of tuples if the columns are a MultiIndex.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>names_to</code></td>
        <td><code>Union[list, tuple, str]</code></td>
        <td><p>Name of new column as a string that will contain what were previously the column names in <code>column_names</code>. The default is <code>variable</code> if no value is provided. It can also be a list/tuple of strings that will serve as new column names, if <code>name_sep</code> or <code>names_pattern</code> is provided. If <code>.value</code> is in <code>names_to</code>, new column names will be extracted from part of the existing column names and overrides<code>values_to</code>.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>values_to</code></td>
        <td><code>Optional[str]</code></td>
        <td><p>Name of new column as a string that will contain what were previously the values of the columns in <code>column_names</code>. values_to can also be a list/tuple and requires that names_pattern is also a list/tuple.</p></td>
        <td><code>&#39;value&#39;</code></td>
      </tr>
      <tr>
        <td><code>column_level</code></td>
        <td><code>Union[int, str]</code></td>
        <td><p>If columns are a MultiIndex, then use this level to unpivot the DataFrame. Provided for compatibility with pandas' melt, and applies only if neither <code>names_sep</code> nor <code>names_pattern</code> is provided.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>names_sep</code></td>
        <td><code>Union[str, Pattern]</code></td>
        <td><p>Determines how the column name is broken up, if <code>names_to</code> contains multiple values. It takes the same specification as pandas' <code>str.split</code> method, and can be a string or regular expression. <code>names_sep</code> does not work with MultiIndex columns.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>names_pattern</code></td>
        <td><code>Union[list, tuple, str, Pattern]</code></td>
        <td><p>Determines how the column name is broken up. It can be a regular expression containing matching groups (it takes the same specification as pandas' <code>str.extract</code> method), or a list/tuple of regular expressions. If it is a single regex, the number of groups must match the length of <code>names_to</code>. For a list/tuple of regular expressions, <code>names_to</code> must also be a list/tuple and the lengths of both arguments must match. <code>names_pattern</code> does not work with MultiIndex columns.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>names_transform</code></td>
        <td><code>Union[str, Callable, dict]</code></td>
        <td><p>Use this option to change the types of columns that have been transformed to rows. This does not applies to the values' columns. Accepts any argument that is acceptable by <code>pd.astype</code>.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>dropna</code></td>
        <td><code>bool</code></td>
        <td><p>Determines whether or not to drop nulls from the values columns. Default is <code>False</code>.</p></td>
        <td><code>False</code></td>
      </tr>
      <tr>
        <td><code>sort_by_appearance</code></td>
        <td><code>Optional[bool]</code></td>
        <td><p>Default <code>False</code>. Boolean value that determines the final look of the DataFrame. If <code>True</code>, the unpivoted DataFrame will be stacked in order of first appearance.</p></td>
        <td><code>False</code></td>
      </tr>
      <tr>
        <td><code>ignore_index</code></td>
        <td><code>Optional[bool]</code></td>
        <td><p>Default <code>True</code>. If <code>True</code>, the original index is ignored. If <code>False</code>, the original index is retained and the index labels will be repeated as necessary.</p></td>
        <td><code>True</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame that has been unpivoted from wide to long format.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/pivot.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
def pivot_longer(
    df: pd.DataFrame,
    index: Optional[Union[list, tuple, str, Pattern]] = None,
    column_names: Optional[Union[list, tuple, str, Pattern]] = None,
    names_to: Optional[Union[list, tuple, str]] = None,
    values_to: Optional[str] = "value",
    column_level: Optional[Union[int, str]] = None,
    names_sep: Optional[Union[str, Pattern]] = None,
    names_pattern: Optional[Union[list, tuple, str, Pattern]] = None,
    names_transform: Optional[Union[str, Callable, dict]] = None,
    dropna: bool = False,
    sort_by_appearance: Optional[bool] = False,
    ignore_index: Optional[bool] = True,
) -&gt; pd.DataFrame:
    """
    Unpivots a DataFrame from *wide* to *long* format.

    This method does not mutate the original DataFrame.

    It is modeled after the `pivot_longer` function in R's tidyr package,
    and also takes inspiration from R's data.table package.

    This function is useful to massage a DataFrame into a format where
    one or more columns are considered measured variables, and all other
    columns are considered as identifier variables.

    All measured variables are *unpivoted* (and typically duplicated) along the
    row axis.

    Column selection in `index` and `column_names` is possible using the
    [`select_columns`][janitor.functions.select.select_columns] syntax.

    Example:

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame(
        ...     {
        ...         "Sepal.Length": [5.1, 5.9],
        ...         "Sepal.Width": [3.5, 3.0],
        ...         "Petal.Length": [1.4, 5.1],
        ...         "Petal.Width": [0.2, 1.8],
        ...         "Species": ["setosa", "virginica"],
        ...     }
        ... )
        &gt;&gt;&gt; df
           Sepal.Length  Sepal.Width  Petal.Length  Petal.Width    Species
        0           5.1          3.5           1.4          0.2     setosa
        1           5.9          3.0           5.1          1.8  virginica

    Replicate pandas' melt:

        &gt;&gt;&gt; df.pivot_longer(index = 'Species')
             Species      variable  value
        0     setosa  Sepal.Length    5.1
        1  virginica  Sepal.Length    5.9
        2     setosa   Sepal.Width    3.5
        3  virginica   Sepal.Width    3.0
        4     setosa  Petal.Length    1.4
        5  virginica  Petal.Length    5.1
        6     setosa   Petal.Width    0.2
        7  virginica   Petal.Width    1.8

    Split the column labels into parts:

        &gt;&gt;&gt; df.pivot_longer(
        ...     index = 'Species',
        ...     names_to = ('part', 'dimension'),
        ...     names_sep = '.',
        ...     sort_by_appearance = True,
        ... )
             Species   part dimension  value
        0     setosa  Sepal    Length    5.1
        1     setosa  Sepal     Width    3.5
        2     setosa  Petal    Length    1.4
        3     setosa  Petal     Width    0.2
        4  virginica  Sepal    Length    5.9
        5  virginica  Sepal     Width    3.0
        6  virginica  Petal    Length    5.1
        7  virginica  Petal     Width    1.8

    Retain parts of the column names as headers:

        &gt;&gt;&gt; df.pivot_longer(
        ...     index = 'Species',
        ...     names_to = ('part', '.value'),
        ...     names_sep = '.',
        ...     sort_by_appearance = True,
        ... )
             Species   part  Length  Width
        0     setosa  Sepal     5.1    3.5
        1     setosa  Petal     1.4    0.2
        2  virginica  Sepal     5.9    3.0
        3  virginica  Petal     5.1    1.8

    Split the column labels based on regex:

        &gt;&gt;&gt; df = pd.DataFrame({"id": [1], "new_sp_m5564": [2], "newrel_f65": [3]})
        &gt;&gt;&gt; df
           id  new_sp_m5564  newrel_f65
        0   1             2           3
        &gt;&gt;&gt; df.pivot_longer(
        ...     index = 'id',
        ...     names_to = ('diagnosis', 'gender', 'age'),
        ...     names_pattern = r"new_?(.+)_(.)(\\d+)",
        ... )
           id diagnosis gender   age  value
        0   1        sp      m  5564      2
        1   1       rel      f    65      3

    Convert the dtypes of specific columns with `names_transform`:

        &gt;&gt;&gt; result = (df
        ...          .pivot_longer(
        ...              index = 'id',
        ...              names_to = ('diagnosis', 'gender', 'age'),
        ...              names_pattern = r"new_?(.+)_(.)(\\d+)",
        ...              names_transform = {'gender': 'category', 'age':'int'})
        ... )
        &gt;&gt;&gt; result.dtypes
        id           int64
        gender    category
        age          int64
        value        int64
        dtype: object

    Use multiple `.value` to reshape dataframe:

        &gt;&gt;&gt; df = pd.DataFrame(
        ...     [
        ...         {
        ...             "x_1_mean": 10,
        ...             "x_2_mean": 20,
        ...             "y_1_mean": 30,
        ...             "y_2_mean": 40,
        ...             "unit": 50,
        ...         }
        ...     ]
        ... )
        &gt;&gt;&gt; df
           x_1_mean  x_2_mean  y_1_mean  y_2_mean  unit
        0        10        20        30        40    50
        &gt;&gt;&gt; df.pivot_longer(
        ...     index="unit",
        ...     names_to=(".value", "time", ".value"),
        ...     names_pattern=r"(x|y)_([0-9])(_mean)",
        ... )
           unit time  x_mean  y_mean
        0    50    1      10      30
        1    50    2      20      40

    Multiple values_to:

        &gt;&gt;&gt; df = pd.DataFrame(
        ...         {
        ...             "City": ["Houston", "Austin", "Hoover"],
        ...             "State": ["Texas", "Texas", "Alabama"],
        ...             "Name": ["Aria", "Penelope", "Niko"],
        ...             "Mango": [4, 10, 90],
        ...             "Orange": [10, 8, 14],
        ...             "Watermelon": [40, 99, 43],
        ...             "Gin": [16, 200, 34],
        ...             "Vodka": [20, 33, 18],
        ...         },
        ...         columns=[
        ...             "City",
        ...             "State",
        ...             "Name",
        ...             "Mango",
        ...             "Orange",
        ...             "Watermelon",
        ...             "Gin",
        ...             "Vodka",
        ...         ],
        ...     )
        &gt;&gt;&gt; df
              City    State      Name  Mango  Orange  Watermelon  Gin  Vodka
        0  Houston    Texas      Aria      4      10          40   16     20
        1   Austin    Texas  Penelope     10       8          99  200     33
        2   Hoover  Alabama      Niko     90      14          43   34     18
        &gt;&gt;&gt; df.pivot_longer(
        ...         index=["City", "State"],
        ...         column_names=slice("Mango", "Vodka"),
        ...         names_to=("Fruit", "Drink"),
        ...         values_to=("Pounds", "Ounces"),
        ...         names_pattern=[r"M|O|W", r"G|V"],
        ...     )
              City    State       Fruit  Pounds  Drink  Ounces
        0  Houston    Texas       Mango       4    Gin    16.0
        1   Austin    Texas       Mango      10    Gin   200.0
        2   Hoover  Alabama       Mango      90    Gin    34.0
        3  Houston    Texas      Orange      10  Vodka    20.0
        4   Austin    Texas      Orange       8  Vodka    33.0
        5   Hoover  Alabama      Orange      14  Vodka    18.0
        6  Houston    Texas  Watermelon      40   None     NaN
        7   Austin    Texas  Watermelon      99   None     NaN
        8   Hoover  Alabama  Watermelon      43   None     NaN


    !!! abstract "Version Changed"

        - 0.24.0
            - Added `dropna` parameter.


    :param df: A pandas DataFrame.
    :param index: Name(s) of columns to use as identifier variables.
        Should be either a single column name, or a list/tuple of
        column names.
        `index` should be a list of tuples if the columns are a MultiIndex.
    :param column_names: Name(s) of columns to unpivot. Should be either
        a single column name or a list/tuple of column names.
        `column_names` should be a list of tuples
        if the columns are a MultiIndex.
    :param names_to: Name of new column as a string that will contain
        what were previously the column names in `column_names`.
        The default is `variable` if no value is provided. It can
        also be a list/tuple of strings that will serve as new column
        names, if `name_sep` or `names_pattern` is provided.
        If `.value` is in `names_to`, new column names will be extracted
        from part of the existing column names and overrides`values_to`.
    :param values_to: Name of new column as a string that will contain what
        were previously the values of the columns in `column_names`.
        values_to can also be a list/tuple
        and requires that names_pattern is also a list/tuple.
    :param column_level: If columns are a MultiIndex, then use this level to
        unpivot the DataFrame. Provided for compatibility with pandas' melt,
        and applies only if neither `names_sep` nor `names_pattern` is
        provided.
    :param names_sep: Determines how the column name is broken up, if
        `names_to` contains multiple values. It takes the same
        specification as pandas' `str.split` method, and can be a string
        or regular expression. `names_sep` does not work with MultiIndex
        columns.
    :param names_pattern: Determines how the column name is broken up.
        It can be a regular expression containing matching groups (it takes
        the same specification as pandas' `str.extract` method), or a
        list/tuple of regular expressions. If it is a single regex, the
        number of groups must match the length of `names_to`.
        For a list/tuple of regular expressions,
        `names_to` must also be a list/tuple and the lengths of both
        arguments must match.
        `names_pattern` does not work with MultiIndex columns.
    :param names_transform: Use this option to change the types of columns that
        have been transformed to rows. This does not applies to the values' columns.
        Accepts any argument that is acceptable by `pd.astype`.
    :param dropna: Determines whether or not to drop nulls
        from the values columns. Default is `False`.
    :param sort_by_appearance: Default `False`. Boolean value that determines
        the final look of the DataFrame. If `True`, the unpivoted DataFrame
        will be stacked in order of first appearance.
    :param ignore_index: Default `True`. If `True`,
        the original index is ignored. If `False`, the original index
        is retained and the index labels will be repeated as necessary.
    :returns: A pandas DataFrame that has been unpivoted from wide to long
        format.
    """  # noqa: E501

    # this code builds on the wonderful work of @benjaminjack’s PR
    # https://github.com/benjaminjack/pyjanitor/commit/e3df817903c20dd21634461c8a92aec137963ed0

    df = df.copy()

    (
        df,
        index,
        column_names,
        names_to,
        values_to,
        names_sep,
        names_pattern,
        names_transform,
        dropna,
        sort_by_appearance,
        ignore_index,
    ) = _data_checks_pivot_longer(
        df,
        index,
        column_names,
        names_to,
        values_to,
        column_level,
        names_sep,
        names_pattern,
        names_transform,
        dropna,
        sort_by_appearance,
        ignore_index,
    )

    return _computations_pivot_longer(
        df,
        index,
        column_names,
        names_to,
        values_to,
        names_sep,
        names_pattern,
        names_transform,
        dropna,
        sort_by_appearance,
        ignore_index,
    )
</code></pre>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.pivot.pivot_wider" class="doc doc-heading">
<code class="highlight language-python">pivot_wider(df, index=None, names_from=None, values_from=None, flatten_levels=True, names_sep='_', names_glue=None, reset_index=True, names_expand=False, index_expand=False)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Reshapes data from <em>long</em> to <em>wide</em> form.</p>
<p>The number of columns are increased, while decreasing
the number of rows. It is the inverse of the
<a class="autorefs autorefs-internal" href="#janitor.functions.pivot.pivot_longer"><code>pivot_longer</code></a>
method, and is a wrapper around <code>pd.DataFrame.pivot</code> method.</p>
<p>This method does not mutate the original DataFrame.</p>
<p>Column selection in <code>index</code>, <code>names_from</code> and <code>values_from</code>
is possible using the
<a class="autorefs autorefs-internal" href="#janitor.functions.select.select_columns"><code>select_columns</code></a> syntax.</p>
<p>A ValueError is raised if the combination
of the <code>index</code> and <code>names_from</code> is not unique.</p>
<p>By default, values from <code>values_from</code> are always
at the top level if the columns are not flattened.
If flattened, the values from <code>values_from</code> are usually
at the start of each label in the columns.</p>
<p>Example:</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = [{'dep': 5.5, 'step': 1, 'a': 20, 'b': 30},
...       {'dep': 5.5, 'step': 2, 'a': 25, 'b': 37},
...       {'dep': 6.1, 'step': 1, 'a': 22, 'b': 19},
...       {'dep': 6.1, 'step': 2, 'a': 18, 'b': 29}]
&gt;&gt;&gt; df = pd.DataFrame(df)
&gt;&gt;&gt; df
   dep  step   a   b
0  5.5     1  20  30
1  5.5     2  25  37
2  6.1     1  22  19
3  6.1     2  18  29
</code></pre>
<p>Pivot and flatten columns:</p>
<pre class="highlight"><code>&gt;&gt;&gt; df.pivot_wider(
...     index = "dep",
...     names_from = "step",
... )
   dep  a_1  a_2  b_1  b_2
0  5.5   20   25   30   37
1  6.1   22   18   19   29
</code></pre>
<p>Modify columns with <code>names_sep</code>:</p>
<pre class="highlight"><code>&gt;&gt;&gt; df.pivot_wider(
...     index = "dep",
...     names_from = "step",
...     names_sep = "",
... )
   dep  a1  a2  b1  b2
0  5.5  20  25  30  37
1  6.1  22  18  19  29
</code></pre>
<p>Modify columns with <code>names_glue</code>:</p>
<pre class="highlight"><code>&gt;&gt;&gt; df.pivot_wider(
...     index = "dep",
...     names_from = "step",
...     names_glue = "{_value}_step{step}",
... )
   dep  a_step1  a_step2  b_step1  b_step2
0  5.5       20       25       30       37
1  6.1       22       18       19       29
</code></pre>
<div class="admonition abstract">
<p class="admonition-title">Version Changed</p>
<ul>
<li>0.24.0<ul>
<li>Added <code>reset_index</code>, <code>names_expand</code> and <code>index_expand</code> parameters.</li>
</ul>
</li>
</ul>
</div>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A pandas DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>index</code></td>
        <td><code>Union[list, str]</code></td>
        <td><p>Name(s) of columns to use as identifier variables. It should be either a single column name, or a list of column names. If <code>index</code> is not provided, the DataFrame's index is used.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>names_from</code></td>
        <td><code>Union[list, str]</code></td>
        <td><p>Name(s) of column(s) to use to make the new DataFrame's columns. Should be either a single column name, or a list of column names.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>values_from</code></td>
        <td><code>Union[list, str]</code></td>
        <td><p>Name(s) of column(s) that will be used for populating the new DataFrame's values. If <code>values_from</code> is not specified,  all remaining columns will be used.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>flatten_levels</code></td>
        <td><code>Optional[bool]</code></td>
        <td><p>Default is <code>True</code>. If <code>False</code>, the DataFrame stays as a MultiIndex.</p></td>
        <td><code>True</code></td>
      </tr>
      <tr>
        <td><code>names_sep</code></td>
        <td><code>str</code></td>
        <td><p>If <code>names_from</code> or <code>values_from</code> contain multiple variables, this will be used to join the values into a single string to use as a column name. Default is <code>_</code>. Applicable only if <code>flatten_levels</code> is <code>True</code>.</p></td>
        <td><code>&#39;_&#39;</code></td>
      </tr>
      <tr>
        <td><code>names_glue</code></td>
        <td><code>str</code></td>
        <td><p>A string to control the output of the flattened columns. It offers more flexibility in creating custom column names, and uses python's <code>str.format_map</code> under the hood. Simply create the string template, using the column labels in <code>names_from</code>, and special <code>_value</code> as a placeholder for <code>values_from</code>. Applicable only if <code>flatten_levels</code> is <code>True</code>.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>reset_index</code></td>
        <td><code>bool</code></td>
        <td><p>Determines whether to restore <code>index</code> as a column/columns. Applicable only if <code>index</code> is provided, and <code>flatten_levels</code> is <code>True</code>. Default is <code>True</code>.</p></td>
        <td><code>True</code></td>
      </tr>
      <tr>
        <td><code>names_expand</code></td>
        <td><code>bool</code></td>
        <td><p>Expand columns to show all the categories. Applies only if <code>names_from</code> is a categorical column. Default is <code>False</code>.</p></td>
        <td><code>False</code></td>
      </tr>
      <tr>
        <td><code>index_expand</code></td>
        <td><code>bool</code></td>
        <td><p>Expand the index to show all the categories. Applies only if <code>index</code> is a categorical column. Default is <code>False</code>.</p></td>
        <td><code>False</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame that has been unpivoted from long to wide form.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/pivot.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
def pivot_wider(
    df: pd.DataFrame,
    index: Optional[Union[list, str]] = None,
    names_from: Optional[Union[list, str]] = None,
    values_from: Optional[Union[list, str]] = None,
    flatten_levels: Optional[bool] = True,
    names_sep: str = "_",
    names_glue: str = None,
    reset_index: bool = True,
    names_expand: bool = False,
    index_expand: bool = False,
) -&gt; pd.DataFrame:
    """
    Reshapes data from *long* to *wide* form.

    The number of columns are increased, while decreasing
    the number of rows. It is the inverse of the
    [`pivot_longer`][janitor.functions.pivot.pivot_longer]
    method, and is a wrapper around `pd.DataFrame.pivot` method.

    This method does not mutate the original DataFrame.

    Column selection in `index`, `names_from` and `values_from`
    is possible using the
    [`select_columns`][janitor.functions.select.select_columns] syntax.

    A ValueError is raised if the combination
    of the `index` and `names_from` is not unique.

    By default, values from `values_from` are always
    at the top level if the columns are not flattened.
    If flattened, the values from `values_from` are usually
    at the start of each label in the columns.



    Example:

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = [{'dep': 5.5, 'step': 1, 'a': 20, 'b': 30},
        ...       {'dep': 5.5, 'step': 2, 'a': 25, 'b': 37},
        ...       {'dep': 6.1, 'step': 1, 'a': 22, 'b': 19},
        ...       {'dep': 6.1, 'step': 2, 'a': 18, 'b': 29}]
        &gt;&gt;&gt; df = pd.DataFrame(df)
        &gt;&gt;&gt; df
           dep  step   a   b
        0  5.5     1  20  30
        1  5.5     2  25  37
        2  6.1     1  22  19
        3  6.1     2  18  29

    Pivot and flatten columns:

        &gt;&gt;&gt; df.pivot_wider(
        ...     index = "dep",
        ...     names_from = "step",
        ... )
           dep  a_1  a_2  b_1  b_2
        0  5.5   20   25   30   37
        1  6.1   22   18   19   29

    Modify columns with `names_sep`:

        &gt;&gt;&gt; df.pivot_wider(
        ...     index = "dep",
        ...     names_from = "step",
        ...     names_sep = "",
        ... )
           dep  a1  a2  b1  b2
        0  5.5  20  25  30  37
        1  6.1  22  18  19  29

    Modify columns with `names_glue`:

        &gt;&gt;&gt; df.pivot_wider(
        ...     index = "dep",
        ...     names_from = "step",
        ...     names_glue = "{_value}_step{step}",
        ... )
           dep  a_step1  a_step2  b_step1  b_step2
        0  5.5       20       25       30       37
        1  6.1       22       18       19       29


    !!! abstract "Version Changed"

        - 0.24.0
            - Added `reset_index`, `names_expand` and `index_expand` parameters.


    :param df: A pandas DataFrame.
    :param index: Name(s) of columns to use as identifier variables.
        It should be either a single column name, or a list of column names.
        If `index` is not provided, the DataFrame's index is used.
    :param names_from: Name(s) of column(s) to use to make the new
        DataFrame's columns. Should be either a single column name,
        or a list of column names.
    :param values_from: Name(s) of column(s) that will be used for populating
        the new DataFrame's values.
        If `values_from` is not specified,  all remaining columns
        will be used.
    :param flatten_levels: Default is `True`. If `False`, the DataFrame stays
        as a MultiIndex.
    :param names_sep: If `names_from` or `values_from` contain multiple
        variables, this will be used to join the values into a single string
        to use as a column name. Default is `_`.
        Applicable only if `flatten_levels` is `True`.
    :param names_glue: A string to control the output of the flattened columns.
        It offers more flexibility in creating custom column names,
        and uses python's `str.format_map` under the hood.
        Simply create the string template,
        using the column labels in `names_from`,
        and special `_value` as a placeholder for `values_from`.
        Applicable only if `flatten_levels` is `True`.
    :param reset_index: Determines whether to restore `index`
        as a column/columns. Applicable only if `index` is provided,
        and `flatten_levels` is `True`. Default is `True`.
    :param names_expand: Expand columns to show all the categories.
        Applies only if `names_from` is a categorical column.
        Default is `False`.
    :param index_expand: Expand the index to show all the categories.
        Applies only if `index` is a categorical column. Default is `False`.
    :returns: A pandas DataFrame that has been unpivoted from long to wide
        form.
    """  # noqa: E501

    df = df.copy()

    return _computations_pivot_wider(
        df,
        index,
        names_from,
        values_from,
        flatten_levels,
        names_sep,
        names_glue,
        reset_index,
        names_expand,
        index_expand,
    )
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.process_text" class="doc doc-heading">
        <code>process_text</code>



</h2>

    <div class="doc doc-contents ">




  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.process_text.process_text" class="doc doc-heading">
<code class="highlight language-python">process_text(df, column_name, string_function, **kwargs)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Apply a Pandas string method to an existing column.</p>
<p>This function aims to make string cleaning easy, while chaining,
by simply passing the string method name,
along with keyword arguments, if any, to the function.</p>
<p>This modifies an existing column; it does not create a new column;
new columns can be created via pyjanitor's
<a class="autorefs autorefs-internal" href="#janitor.functions.transform_columns.transform_columns"><code>transform_columns</code></a>.</p>
<p>A list of all the string methods in Pandas can be accessed <a href="https://pandas.pydata.org/docs/user_guide/text.html#method-summary">here</a>.</p>
<p>Example:</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; import re
&gt;&gt;&gt; df = pd.DataFrame({"text": ["Ragnar", "sammywemmy", "ginger"],
... "code": [1, 2, 3]})
&gt;&gt;&gt; df
         text  code
0      Ragnar     1
1  sammywemmy     2
2      ginger     3
&gt;&gt;&gt; df.process_text(column_name="text", string_function="lower")
         text  code
0      ragnar     1
1  sammywemmy     2
2      ginger     3
</code></pre>
<p>For string methods with parameters, simply pass the keyword arguments:</p>
<pre class="highlight"><code>&gt;&gt;&gt; df.process_text(
...     column_name="text",
...     string_function="extract",
...     pat=r"(ag)",
...     expand=False,
...     flags=re.IGNORECASE,
... )
  text  code
0   ag     1
1  NaN     2
2  NaN     3


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A pandas DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>column_name</code></td>
        <td><code>str</code></td>
        <td><p>String column to be operated on.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>string_function</code></td>
        <td><code>str</code></td>
        <td><p>pandas string method to be applied.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>kwargs</code></td>
        <td></td>
        <td><p>Keyword arguments for parameters of the <code>string_function</code>.</p></td>
        <td><code>{}</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame with modified column.</p></td>
    </tr>
  </tbody>
</table>
<p><strong>Exceptions:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>KeyError</code></td>
        <td><p>If <code>string_function</code> is not a Pandas string method.</p></td>
      </tr>
      <tr>
        <td><code>ValueError</code></td>
        <td><p>If the text function returns a DataFrame, instead of a Series.</p></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/process_text.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
@deprecated_alias(column="column_name")
def process_text(
    df: pd.DataFrame,
    column_name: str,
    string_function: str,
    **kwargs,
) -&gt; pd.DataFrame:
    """
    Apply a Pandas string method to an existing column.

    This function aims to make string cleaning easy, while chaining,
    by simply passing the string method name,
    along with keyword arguments, if any, to the function.

    This modifies an existing column; it does not create a new column;
    new columns can be created via pyjanitor's
    [`transform_columns`][janitor.functions.transform_columns.transform_columns].


    A list of all the string methods in Pandas can be accessed [here](https://pandas.pydata.org/docs/user_guide/text.html#method-summary).


    Example:

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; import re
        &gt;&gt;&gt; df = pd.DataFrame({"text": ["Ragnar", "sammywemmy", "ginger"],
        ... "code": [1, 2, 3]})
        &gt;&gt;&gt; df
                 text  code
        0      Ragnar     1
        1  sammywemmy     2
        2      ginger     3
        &gt;&gt;&gt; df.process_text(column_name="text", string_function="lower")
                 text  code
        0      ragnar     1
        1  sammywemmy     2
        2      ginger     3

    For string methods with parameters, simply pass the keyword arguments:

        &gt;&gt;&gt; df.process_text(
        ...     column_name="text",
        ...     string_function="extract",
        ...     pat=r"(ag)",
        ...     expand=False,
        ...     flags=re.IGNORECASE,
        ... )
          text  code
        0   ag     1
        1  NaN     2
        2  NaN     3

    :param df: A pandas DataFrame.
    :param column_name: String column to be operated on.
    :param string_function: pandas string method to be applied.
    :param kwargs: Keyword arguments for parameters of the `string_function`.
    :returns: A pandas DataFrame with modified column.
    :raises KeyError: If `string_function` is not a Pandas string method.
    :raises ValueError: If the text function returns a DataFrame, instead of a Series.
    """  # noqa: E501

    check("column_name", column_name, [str])
    check("string_function", string_function, [str])
    check_column(df, [column_name])

    pandas_string_methods = [
        func.__name__
        for _, func in inspect.getmembers(pd.Series.str, inspect.isfunction)
        if not func.__name__.startswith("_")
    ]

    if string_function not in pandas_string_methods:
        raise KeyError(f"{string_function} is not a Pandas string method.")

    result = getattr(df[column_name].str, string_function)(**kwargs)

    if isinstance(result, pd.DataFrame):
        raise ValueError(
            "The outcome of the processed text is a DataFrame, "
            "which is not supported in `process_text`."
        )

    return df.assign(**{column_name: result})
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.remove_columns" class="doc doc-heading">
        <code>remove_columns</code>



</h2>

    <div class="doc doc-contents ">

      <p>Implementation of remove_columns.</p>



  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.remove_columns.remove_columns" class="doc doc-heading">
<code class="highlight language-python">remove_columns(df, column_names)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Remove the set of columns specified in <code>column_names</code>.</p>
<p>This method does not mutate the original DataFrame.</p>
<p>Intended to be the method-chaining alternative to <code>del df[col]</code>.</p>
<p>Example:</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({"a": [2, 4, 6], "b": [1, 3, 5], "c": [7, 8, 9]})
&gt;&gt;&gt; df
   a  b  c
0  2  1  7
1  4  3  8
2  6  5  9
&gt;&gt;&gt; df.remove_columns(column_names=['a', 'c'])
   b
0  1
1  3
2  5


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A pandas DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>column_names</code></td>
        <td><code>Union[str, Iterable[str], Hashable]</code></td>
        <td><p>The columns to remove.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/remove_columns.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
@deprecated_alias(columns="column_names")
def remove_columns(
    df: pd.DataFrame,
    column_names: Union[str, Iterable[str], Hashable],
) -&gt; pd.DataFrame:
    """Remove the set of columns specified in `column_names`.

    This method does not mutate the original DataFrame.

    Intended to be the method-chaining alternative to `del df[col]`.

    Example:

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({"a": [2, 4, 6], "b": [1, 3, 5], "c": [7, 8, 9]})
        &gt;&gt;&gt; df
           a  b  c
        0  2  1  7
        1  4  3  8
        2  6  5  9
        &gt;&gt;&gt; df.remove_columns(column_names=['a', 'c'])
           b
        0  1
        1  3
        2  5

    :param df: A pandas DataFrame.
    :param column_names: The columns to remove.
    :returns: A pandas DataFrame.
    """
    return df.drop(columns=column_names)
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.remove_empty" class="doc doc-heading">
        <code>remove_empty</code>



</h2>

    <div class="doc doc-contents ">

      <p>Implementation of remove_empty.</p>



  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.remove_empty.remove_empty" class="doc doc-heading">
<code class="highlight language-python">remove_empty(df)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Drop all rows and columns that are completely null.</p>
<p>This method also resets the index (by default) since it doesn't make sense
to preserve the index of a completely empty row.</p>
<p>This method mutates the original DataFrame.</p>
<p>Implementation is inspired from <a href="https://stackoverflow.com/questions/38884538/python-pandas-find-all-rows-where-all-values-are-nan">StackOverflow</a>.</p>
<p>Example:</p>
<pre class="highlight"><code>&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({
...     "a": [1, np.nan, 2],
...     "b": [3, np.nan, 4],
...     "c": [np.nan, np.nan, np.nan],
... })
&gt;&gt;&gt; df
     a    b   c
0  1.0  3.0 NaN
1  NaN  NaN NaN
2  2.0  4.0 NaN
&gt;&gt;&gt; df.remove_empty()
     a    b
0  1.0  3.0
1  2.0  4.0


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>The pandas DataFrame object.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/remove_empty.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
def remove_empty(df: pd.DataFrame) -&gt; pd.DataFrame:
    """Drop all rows and columns that are completely null.

    This method also resets the index (by default) since it doesn't make sense
    to preserve the index of a completely empty row.

    This method mutates the original DataFrame.

    Implementation is inspired from [StackOverflow][so].

    [so]: https://stackoverflow.com/questions/38884538/python-pandas-find-all-rows-where-all-values-are-nan

    Example:

        &gt;&gt;&gt; import numpy as np
        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({
        ...     "a": [1, np.nan, 2],
        ...     "b": [3, np.nan, 4],
        ...     "c": [np.nan, np.nan, np.nan],
        ... })
        &gt;&gt;&gt; df
             a    b   c
        0  1.0  3.0 NaN
        1  NaN  NaN NaN
        2  2.0  4.0 NaN
        &gt;&gt;&gt; df.remove_empty()
             a    b
        0  1.0  3.0
        1  2.0  4.0

    :param df: The pandas DataFrame object.
    :returns: A pandas DataFrame.
    """  # noqa: E501
    nanrows = df.index[df.isna().all(axis=1)]
    df = df.drop(index=nanrows).reset_index(drop=True)

    nancols = df.columns[df.isna().all(axis=0)]
    df = df.drop(columns=nancols)

    return df
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.rename_columns" class="doc doc-heading">
        <code>rename_columns</code>



</h2>

    <div class="doc doc-contents ">




  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.rename_columns.rename_column" class="doc doc-heading">
<code class="highlight language-python">rename_column(df, old_column_name, new_column_name)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Rename a column in place.</p>
<p>This method does not mutate the original DataFrame.</p>
<p>Example: Change the name of column 'a' to 'a_new'.</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({"a": list(range(3)), "b": list("abc")})
&gt;&gt;&gt; df.rename_column(old_column_name='a', new_column_name='a_new')
   a_new  b
0      0  a
1      1  b
2      2  c
</code></pre>
<p>This is just syntactic sugar/a convenience function for renaming one column at a time.
If you are convinced that there are multiple columns in need of changing,
then use the <code>pandas.DataFrame.rename</code> method.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>The pandas DataFrame object.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>old_column_name</code></td>
        <td><code>str</code></td>
        <td><p>The old column name.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>new_column_name</code></td>
        <td><code>str</code></td>
        <td><p>The new column name.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame with renamed columns.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/rename_columns.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
@deprecated_alias(old="old_column_name", new="new_column_name")
def rename_column(
    df: pd.DataFrame,
    old_column_name: str,
    new_column_name: str,
) -&gt; pd.DataFrame:
    """Rename a column in place.

    This method does not mutate the original DataFrame.

    Example: Change the name of column 'a' to 'a_new'.

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({"a": list(range(3)), "b": list("abc")})
        &gt;&gt;&gt; df.rename_column(old_column_name='a', new_column_name='a_new')
           a_new  b
        0      0  a
        1      1  b
        2      2  c

    This is just syntactic sugar/a convenience function for renaming one column at a time.
    If you are convinced that there are multiple columns in need of changing,
    then use the `pandas.DataFrame.rename` method.

    :param df: The pandas DataFrame object.
    :param old_column_name: The old column name.
    :param new_column_name: The new column name.
    :returns: A pandas DataFrame with renamed columns.
    """  # noqa: E501
    check_column(df, [old_column_name])

    return df.rename(columns={old_column_name: new_column_name})
</code></pre>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.rename_columns.rename_columns" class="doc doc-heading">
<code class="highlight language-python">rename_columns(df, new_column_names=None, function=None)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Rename columns.</p>
<p>This method does not mutate the original DataFrame.</p>
<p>Example: Rename columns using a dictionary which maps old names to new names.</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({"a": list(range(3)), "b": list("xyz")})
&gt;&gt;&gt; df
   a  b
0  0  x
1  1  y
2  2  z
&gt;&gt;&gt; df.rename_columns(new_column_names={"a": "a_new", "b": "b_new"})
   a_new b_new
0      0     x
1      1     y
2      2     z
</code></pre>
<p>Example: Rename columns using a generic callable.</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({"a": list(range(3)), "b": list("xyz")})
&gt;&gt;&gt; df.rename_columns(function=str.upper)
   A  B
0  0  x
1  1  y
2  2  z
</code></pre>
<p>One of the <code>new_column_names</code> or <code>function</code> are a required parameter.
If both are provided, then <code>new_column_names</code> takes priority and <code>function</code>
is never executed.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>The pandas DataFrame object.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>new_column_names</code></td>
        <td><code>Optional[Dict]</code></td>
        <td><p>A dictionary of old and new column names.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>function</code></td>
        <td><code>Callable</code></td>
        <td><p>A function which should be applied to all the columns.</p></td>
        <td><code>None</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame with renamed columns.</p></td>
    </tr>
  </tbody>
</table>
<p><strong>Exceptions:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>ValueError</code></td>
        <td><p>if both <code>new_column_names</code> and <code>function</code> are None.</p></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/rename_columns.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
def rename_columns(
    df: pd.DataFrame,
    new_column_names: Union[Dict, None] = None,
    function: Callable = None,
) -&gt; pd.DataFrame:
    """Rename columns.

    This method does not mutate the original DataFrame.

    Example: Rename columns using a dictionary which maps old names to new names.

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({"a": list(range(3)), "b": list("xyz")})
        &gt;&gt;&gt; df
           a  b
        0  0  x
        1  1  y
        2  2  z
        &gt;&gt;&gt; df.rename_columns(new_column_names={"a": "a_new", "b": "b_new"})
           a_new b_new
        0      0     x
        1      1     y
        2      2     z

    Example: Rename columns using a generic callable.

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({"a": list(range(3)), "b": list("xyz")})
        &gt;&gt;&gt; df.rename_columns(function=str.upper)
           A  B
        0  0  x
        1  1  y
        2  2  z

    One of the `new_column_names` or `function` are a required parameter.
    If both are provided, then `new_column_names` takes priority and `function`
    is never executed.

    :param df: The pandas DataFrame object.
    :param new_column_names: A dictionary of old and new column names.
    :param function: A function which should be applied to all the columns.
    :returns: A pandas DataFrame with renamed columns.
    :raises ValueError: if both `new_column_names` and `function` are None.
    """  # noqa: E501

    if new_column_names is None and function is None:
        raise ValueError(
            "One of new_column_names or function must be provided"
        )

    if new_column_names is not None:
        check_column(df, new_column_names)
        return df.rename(columns=new_column_names)

    return df.rename(mapper=function, axis="columns")
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.reorder_columns" class="doc doc-heading">
        <code>reorder_columns</code>



</h2>

    <div class="doc doc-contents ">




  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.reorder_columns.reorder_columns" class="doc doc-heading">
<code class="highlight language-python">reorder_columns(df, column_order)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Reorder DataFrame columns by specifying desired order as list of col names.</p>
<p>Columns not specified retain their order and follow after the columns specified
in <code>column_order</code>.</p>
<p>All columns specified within the <code>column_order</code> list must be present within <code>df</code>.</p>
<p>This method does not mutate the original DataFrame.</p>
<p>Example:</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({"col1": [1, 1, 1], "col2": [2, 2, 2], "col3": [3, 3, 3]})
&gt;&gt;&gt; df
   col1  col2  col3
0     1     2     3
1     1     2     3
2     1     2     3
&gt;&gt;&gt; df.reorder_columns(['col3', 'col1'])
   col3  col1  col2
0     3     1     2
1     3     1     2
2     3     1     2
</code></pre>
<p>Notice that the column order of <code>df</code> is now <code>col3</code>, <code>col1</code>, <code>col2</code>.</p>
<p>Internally, this function uses <code>DataFrame.reindex</code> with <code>copy=False</code>
to avoid unnecessary data duplication.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p><code>DataFrame</code> to reorder</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>column_order</code></td>
        <td><code>Union[Iterable[str], pandas.core.indexes.base.Index, Hashable]</code></td>
        <td><p>A list of column names or Pandas <code>Index</code> specifying their order in the returned <code>DataFrame</code>.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame with reordered columns.</p></td>
    </tr>
  </tbody>
</table>
<p><strong>Exceptions:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>IndexError</code></td>
        <td><p>if a column within <code>column_order</code> is not found within the DataFrame.</p></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/reorder_columns.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
def reorder_columns(
    df: pd.DataFrame, column_order: Union[Iterable[str], pd.Index, Hashable]
) -&gt; pd.DataFrame:
    """Reorder DataFrame columns by specifying desired order as list of col names.

    Columns not specified retain their order and follow after the columns specified
    in `column_order`.

    All columns specified within the `column_order` list must be present within `df`.

    This method does not mutate the original DataFrame.

    Example:

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({"col1": [1, 1, 1], "col2": [2, 2, 2], "col3": [3, 3, 3]})
        &gt;&gt;&gt; df
           col1  col2  col3
        0     1     2     3
        1     1     2     3
        2     1     2     3
        &gt;&gt;&gt; df.reorder_columns(['col3', 'col1'])
           col3  col1  col2
        0     3     1     2
        1     3     1     2
        2     3     1     2

    Notice that the column order of `df` is now `col3`, `col1`, `col2`.

    Internally, this function uses `DataFrame.reindex` with `copy=False`
    to avoid unnecessary data duplication.

    :param df: `DataFrame` to reorder
    :param column_order: A list of column names or Pandas `Index`
        specifying their order in the returned `DataFrame`.
    :returns: A pandas DataFrame with reordered columns.
    :raises IndexError: if a column within `column_order` is not found
        within the DataFrame.
    """  # noqa: E501
    check("column_order", column_order, [list, tuple, pd.Index])

    if any(col not in df.columns for col in column_order):
        raise IndexError(
            "One or more columns in `column_order` were not found in the "
            "DataFrame."
        )

    # if column_order is a Pandas index, needs conversion to list:
    column_order = list(column_order)

    return df.reindex(
        columns=(
            column_order
            + [col for col in df.columns if col not in column_order]
        ),
        copy=False,
    )
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.round_to_fraction" class="doc doc-heading">
        <code>round_to_fraction</code>



</h2>

    <div class="doc doc-contents ">

      <p>Implementation of <code>round_to_fraction</code></p>



  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.round_to_fraction.round_to_fraction" class="doc doc-heading">
<code class="highlight language-python">round_to_fraction(df, column_name, denominator, digits=inf)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Round all values in a column to a fraction.</p>
<p>This method mutates the original DataFrame.</p>
<p>Taken from <a href="https://github.com/sfirke/janitor/issues/235">the R package</a>.</p>
<p>Also, optionally round to a specified number of digits.</p>
<p>Example: Round numeric column to the nearest 1/4 value.</p>
<pre class="highlight"><code>&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({
...     "a1": [1.263, 2.499, np.nan],
...     "a2": ["x", "y", "z"],
... })
&gt;&gt;&gt; df
      a1 a2
0  1.263  x
1  2.499  y
2    NaN  z
&gt;&gt;&gt; df.round_to_fraction("a1", denominator=4)
     a1 a2
0  1.25  x
1  2.50  y
2   NaN  z


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A pandas DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>column_name</code></td>
        <td><code>Hashable</code></td>
        <td><p>Name of column to round to fraction.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>denominator</code></td>
        <td><code>float</code></td>
        <td><p>The denominator of the fraction for rounding. Must be a positive number.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>digits</code></td>
        <td><code>float</code></td>
        <td><p>The number of digits for rounding after rounding to the fraction. Default is np.inf (i.e. no subsequent rounding).</p></td>
        <td><code>inf</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame with a column's values rounded.</p></td>
    </tr>
  </tbody>
</table>
<p><strong>Exceptions:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>ValueError</code></td>
        <td><p>If <code>denominator</code> is not a positive number.</p></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/round_to_fraction.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
@deprecated_alias(col_name="column_name")
def round_to_fraction(
    df: pd.DataFrame,
    column_name: Hashable,
    denominator: float,
    digits: float = np.inf,
) -&gt; pd.DataFrame:
    """Round all values in a column to a fraction.

    This method mutates the original DataFrame.

    Taken from [the R package](https://github.com/sfirke/janitor/issues/235).

    Also, optionally round to a specified number of digits.

    Example: Round numeric column to the nearest 1/4 value.

        &gt;&gt;&gt; import numpy as np
        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({
        ...     "a1": [1.263, 2.499, np.nan],
        ...     "a2": ["x", "y", "z"],
        ... })
        &gt;&gt;&gt; df
              a1 a2
        0  1.263  x
        1  2.499  y
        2    NaN  z
        &gt;&gt;&gt; df.round_to_fraction("a1", denominator=4)
             a1 a2
        0  1.25  x
        1  2.50  y
        2   NaN  z

    :param df: A pandas DataFrame.
    :param column_name: Name of column to round to fraction.
    :param denominator: The denominator of the fraction for rounding. Must be
        a positive number.
    :param digits: The number of digits for rounding after rounding to the
        fraction. Default is np.inf (i.e. no subsequent rounding).
    :returns: A pandas DataFrame with a column's values rounded.
    :raises ValueError: If `denominator` is not a positive number.
    """
    check_column(df, column_name)
    check("denominator", denominator, [float, int])
    check("digits", digits, [float, int])

    if denominator &lt;= 0:
        raise ValueError("denominator is expected to be a positive number.")

    df[column_name] = round(df[column_name] * denominator, 0) / denominator
    if not np.isinf(digits):
        df[column_name] = round(df[column_name], digits)

    return df
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.row_to_names" class="doc doc-heading">
        <code>row_to_names</code>



</h2>

    <div class="doc doc-contents ">

      <p>Implementation of the <code>row_to_names</code> function.</p>



  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.row_to_names.row_to_names" class="doc doc-heading">
<code class="highlight language-python">row_to_names(df, row_number=0, remove_row=False, remove_rows_above=False, reset_index=False)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Elevates a row to be the column names of a DataFrame.</p>
<p>This method mutates the original DataFrame.</p>
<p>Contains options to remove the elevated row from the DataFrame along with
removing the rows above the selected row.</p>
<p>Example: Replace column names with the first row and reset the index.</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({
...     "a": ["nums", 6, 9],
...     "b": ["chars", "x", "y"],
... })
&gt;&gt;&gt; df
      a      b
0  nums  chars
1     6      x
2     9      y
&gt;&gt;&gt; df.row_to_names(0, remove_row=True, reset_index=True)
  nums chars
0    6     x
1    9     y
</code></pre>
<p>Example: Remove rows above the elevated row and the elevated row itself.</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({
...     "a": ["bla1", "nums", 6, 9],
...     "b": ["bla2", "chars", "x", "y"],
... })
&gt;&gt;&gt; df
      a      b
0  bla1   bla2
1  nums  chars
2     6      x
3     9      y
&gt;&gt;&gt; df.row_to_names(1, remove_row=True, remove_rows_above=True, reset_index=True)
  nums chars
0    6     x
1    9     y


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A pandas DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>row_number</code></td>
        <td><code>int</code></td>
        <td><p>Position of the row containing the variable names. Note that indexing starts from 0. Defaults to 0 (first row).</p></td>
        <td><code>0</code></td>
      </tr>
      <tr>
        <td><code>remove_row</code></td>
        <td><code>bool</code></td>
        <td><p>Whether the row should be removed from the DataFrame. Defaults to False.</p></td>
        <td><code>False</code></td>
      </tr>
      <tr>
        <td><code>remove_rows_above</code></td>
        <td><code>bool</code></td>
        <td><p>Whether the rows above the selected row should be removed from the DataFrame. Defaults to False.</p></td>
        <td><code>False</code></td>
      </tr>
      <tr>
        <td><code>reset_index</code></td>
        <td><code>bool</code></td>
        <td><p>Whether the index should be reset on the returning DataFrame. Defaults to False.</p></td>
        <td><code>False</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame with set column names.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/row_to_names.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
def row_to_names(
    df: pd.DataFrame,
    row_number: int = 0,
    remove_row: bool = False,
    remove_rows_above: bool = False,
    reset_index: bool = False,
) -&gt; pd.DataFrame:
    """Elevates a row to be the column names of a DataFrame.

    This method mutates the original DataFrame.

    Contains options to remove the elevated row from the DataFrame along with
    removing the rows above the selected row.

    Example: Replace column names with the first row and reset the index.

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({
        ...     "a": ["nums", 6, 9],
        ...     "b": ["chars", "x", "y"],
        ... })
        &gt;&gt;&gt; df
              a      b
        0  nums  chars
        1     6      x
        2     9      y
        &gt;&gt;&gt; df.row_to_names(0, remove_row=True, reset_index=True)
          nums chars
        0    6     x
        1    9     y

    Example: Remove rows above the elevated row and the elevated row itself.

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({
        ...     "a": ["bla1", "nums", 6, 9],
        ...     "b": ["bla2", "chars", "x", "y"],
        ... })
        &gt;&gt;&gt; df
              a      b
        0  bla1   bla2
        1  nums  chars
        2     6      x
        3     9      y
        &gt;&gt;&gt; df.row_to_names(1, remove_row=True, remove_rows_above=True, reset_index=True)
          nums chars
        0    6     x
        1    9     y

    :param df: A pandas DataFrame.
    :param row_number: Position of the row containing the variable names.
        Note that indexing starts from 0. Defaults to 0 (first row).
    :param remove_row: Whether the row should be removed from the DataFrame.
        Defaults to False.
    :param remove_rows_above: Whether the rows above the selected row should
        be removed from the DataFrame. Defaults to False.
    :param reset_index: Whether the index should be reset on the returning
        DataFrame. Defaults to False.
    :returns: A pandas DataFrame with set column names.
    """  # noqa: E501

    check("row_number", row_number, [int])

    warnings.warn(
        "The function row_to_names will, in the official 1.0 release, "
        "change its behaviour to reset the dataframe's index by default. "
        "You can prepare for this change right now by explicitly setting "
        "`reset_index=True` when calling on `row_to_names`."
    )

    df.columns = df.iloc[row_number, :]
    df.columns.name = None

    if remove_row:
        df = df.drop(df.index[row_number])

    if remove_rows_above:
        df = df.drop(df.index[range(row_number)])

    if reset_index:
        df = df.reset_index(drop=["index"])

    return df
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.select" class="doc doc-heading">
        <code>select</code>



</h2>

    <div class="doc doc-contents ">




  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.select.select" class="doc doc-heading">
<code class="highlight language-python">select(df, *, rows=None, columns=None)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Method-chainable selection of rows and columns.</p>
<p>It accepts a string, shell-like glob strings <code>(*string*)</code>,
regex, slice, array-like object, or a list of the previous options.</p>
<p>Selection on a MultiIndex on a level, or multiple levels,
is possible with a dictionary.</p>
<p>This method does not mutate the original DataFrame.</p>
<p>Selection can be inverted with the <code>DropLabel</code> class.</p>
<div class="admonition info">
<p class="admonition-title">New in version 0.24.0</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The preferred option when selecting columns or rows in a Pandas DataFrame
is with <code>.loc</code> or <code>.iloc</code> methods, as they are generally performant.
<code>select</code> is primarily for convenience.</p>
</div>
<p>Example:</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],
...      index=['cobra', 'viper', 'sidewinder'],
...      columns=['max_speed', 'shield'])
&gt;&gt;&gt; df
            max_speed  shield
cobra               1       2
viper               4       5
sidewinder          7       8
&gt;&gt;&gt; df.select(rows='cobra', columns='shield')
       shield
cobra       2
</code></pre>
<p>Labels can be dropped with the <code>DropLabel</code> class:</p>
<pre class="highlight"><code>&gt;&gt;&gt; df.select(rows=DropLabel('cobra'))
            max_speed  shield
viper               4       5
sidewinder          7       8


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A pandas DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>rows</code></td>
        <td></td>
        <td><p>Valid inputs include: an exact label to look for, a shell-style glob string (e.g. <code>*_thing_*</code>), a regular expression, a callable, or variable arguments of all the aforementioned. A sequence of booleans is also acceptable. A dictionary can be used for selection on a MultiIndex on different levels.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>columns</code></td>
        <td></td>
        <td><p>Valid inputs include: an exact label to look for, a shell-style glob string (e.g. <code>*_thing_*</code>), a regular expression, a callable, or variable arguments of all the aforementioned. A sequence of booleans is also acceptable. A dictionary can be used for selection on a MultiIndex on different levels.</p></td>
        <td><code>None</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame with the specified rows and/or columns selected.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/select.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
def select(df: pd.DataFrame, *, rows=None, columns=None) -&gt; pd.DataFrame:
    """
    Method-chainable selection of rows and columns.

    It accepts a string, shell-like glob strings `(*string*)`,
    regex, slice, array-like object, or a list of the previous options.

    Selection on a MultiIndex on a level, or multiple levels,
    is possible with a dictionary.

    This method does not mutate the original DataFrame.

    Selection can be inverted with the `DropLabel` class.


    !!! info "New in version 0.24.0"


    !!!note

        The preferred option when selecting columns or rows in a Pandas DataFrame
        is with `.loc` or `.iloc` methods, as they are generally performant.
        `select` is primarily for convenience.


    Example:

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],
        ...      index=['cobra', 'viper', 'sidewinder'],
        ...      columns=['max_speed', 'shield'])
        &gt;&gt;&gt; df
                    max_speed  shield
        cobra               1       2
        viper               4       5
        sidewinder          7       8
        &gt;&gt;&gt; df.select(rows='cobra', columns='shield')
               shield
        cobra       2

    Labels can be dropped with the `DropLabel` class:

        &gt;&gt;&gt; df.select(rows=DropLabel('cobra'))
                    max_speed  shield
        viper               4       5
        sidewinder          7       8

    :param df: A pandas DataFrame.
    :param rows: Valid inputs include: an exact label to look for,
        a shell-style glob string (e.g. `*_thing_*`),
        a regular expression,
        a callable,
        or variable arguments of all the aforementioned.
        A sequence of booleans is also acceptable.
        A dictionary can be used for selection on a MultiIndex on different levels.
    :param columns: Valid inputs include: an exact label to look for,
        a shell-style glob string (e.g. `*_thing_*`),
        a regular expression,
        a callable,
        or variable arguments of all the aforementioned.
        A sequence of booleans is also acceptable.
        A dictionary can be used for selection on a MultiIndex on different levels.
    :returns: A pandas DataFrame with the specified rows and/or columns selected.
    """  # noqa: E501

    return _select(df, args=None, rows=rows, columns=columns, axis="both")
</code></pre>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.select.select_columns" class="doc doc-heading">
<code class="highlight language-python">select_columns(df, *args, *, invert=False)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Method-chainable selection of columns.</p>
<p>It accepts a string, shell-like glob strings <code>(*string*)</code>,
regex, slice, array-like object, or a list of the previous options.</p>
<p>Selection on a MultiIndex on a level, or multiple levels,
is possible with a dictionary.</p>
<p>This method does not mutate the original DataFrame.</p>
<p>Optional ability to invert selection of columns available as well.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The preferred option when selecting columns or rows in a Pandas DataFrame
is with <code>.loc</code> or <code>.iloc</code> methods, as they are generally performant.
<code>select_columns</code> is primarily for convenience.</p>
</div>
<p>Example:</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({"col1": [1, 2], "foo": [3, 4], "col2": [5, 6]})
&gt;&gt;&gt; df
   col1  foo  col2
0     1    3     5
1     2    4     6
&gt;&gt;&gt; df.select_columns("col*")
   col1  col2
0     1     5
1     2     6


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A pandas DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>args</code></td>
        <td></td>
        <td><p>Valid inputs include: an exact column name to look for, a shell-style glob string (e.g. <code>*_thing_*</code>), a regular expression, a callable, or variable arguments of all the aforementioned. A sequence of booleans is also acceptable. A dictionary can be used for selection on a MultiIndex on different levels.</p></td>
        <td><code>()</code></td>
      </tr>
      <tr>
        <td><code>invert</code></td>
        <td><code>bool</code></td>
        <td><p>Whether or not to invert the selection. This will result in the selection of the complement of the columns provided.</p></td>
        <td><code>False</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame with the specified columns selected.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/select.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
@deprecated_alias(search_cols="search_column_names")
def select_columns(
    df: pd.DataFrame,
    *args,
    invert: bool = False,
) -&gt; pd.DataFrame:
    """
    Method-chainable selection of columns.

    It accepts a string, shell-like glob strings `(*string*)`,
    regex, slice, array-like object, or a list of the previous options.

    Selection on a MultiIndex on a level, or multiple levels,
    is possible with a dictionary.

    This method does not mutate the original DataFrame.

    Optional ability to invert selection of columns available as well.

    !!!note

        The preferred option when selecting columns or rows in a Pandas DataFrame
        is with `.loc` or `.iloc` methods, as they are generally performant.
        `select_columns` is primarily for convenience.

    Example:

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({"col1": [1, 2], "foo": [3, 4], "col2": [5, 6]})
        &gt;&gt;&gt; df
           col1  foo  col2
        0     1    3     5
        1     2    4     6
        &gt;&gt;&gt; df.select_columns("col*")
           col1  col2
        0     1     5
        1     2     6

    :param df: A pandas DataFrame.
    :param args: Valid inputs include: an exact column name to look for,
        a shell-style glob string (e.g. `*_thing_*`),
        a regular expression,
        a callable,
        or variable arguments of all the aforementioned.
        A sequence of booleans is also acceptable.
        A dictionary can be used for selection on a MultiIndex on different levels.
    :param invert: Whether or not to invert the selection.
        This will result in the selection of the complement of the columns
        provided.
    :returns: A pandas DataFrame with the specified columns selected.
    """  # noqa: E501

    return _select(df, args=args, invert=invert, axis="columns")
</code></pre>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.select.select_rows" class="doc doc-heading">
<code class="highlight language-python">select_rows(df, *args, *, invert=False)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Method-chainable selection of rows.</p>
<p>It accepts a string, shell-like glob strings <code>(*string*)</code>,
regex, slice, array-like object, or a list of the previous options.</p>
<p>Selection on a MultiIndex on a level, or multiple levels,
is possible with a dictionary.</p>
<p>This method does not mutate the original DataFrame.</p>
<p>Optional ability to invert selection of rows available as well.</p>
<div class="admonition info">
<p class="admonition-title">New in version 0.24.0</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The preferred option when selecting columns or rows in a Pandas DataFrame
is with <code>.loc</code> or <code>.iloc</code> methods, as they are generally performant.
<code>select_rows</code> is primarily for convenience.</p>
</div>
<p>Example:</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = {"col1": [1, 2], "foo": [3, 4], "col2": [5, 6]}
&gt;&gt;&gt; df = pd.DataFrame.from_dict(df, orient='index')
&gt;&gt;&gt; df
      0  1
col1  1  2
foo   3  4
col2  5  6
&gt;&gt;&gt; df.select_rows("col*")
      0  1
col1  1  2
col2  5  6


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A pandas DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>args</code></td>
        <td></td>
        <td><p>Valid inputs include: an exact index name to look for, a shell-style glob string (e.g. <code>*_thing_*</code>), a regular expression, a callable, or variable arguments of all the aforementioned. A sequence of booleans is also acceptable. A dictionary can be used for selection on a MultiIndex on different levels.</p></td>
        <td><code>()</code></td>
      </tr>
      <tr>
        <td><code>invert</code></td>
        <td><code>bool</code></td>
        <td><p>Whether or not to invert the selection. This will result in the selection of the complement of the rows provided.</p></td>
        <td><code>False</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame with the specified rows selected.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/select.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
def select_rows(
    df: pd.DataFrame,
    *args,
    invert: bool = False,
) -&gt; pd.DataFrame:
    """
    Method-chainable selection of rows.

    It accepts a string, shell-like glob strings `(*string*)`,
    regex, slice, array-like object, or a list of the previous options.

    Selection on a MultiIndex on a level, or multiple levels,
    is possible with a dictionary.

    This method does not mutate the original DataFrame.

    Optional ability to invert selection of rows available as well.


    !!! info "New in version 0.24.0"


    !!!note

        The preferred option when selecting columns or rows in a Pandas DataFrame
        is with `.loc` or `.iloc` methods, as they are generally performant.
        `select_rows` is primarily for convenience.


    Example:

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = {"col1": [1, 2], "foo": [3, 4], "col2": [5, 6]}
        &gt;&gt;&gt; df = pd.DataFrame.from_dict(df, orient='index')
        &gt;&gt;&gt; df
              0  1
        col1  1  2
        foo   3  4
        col2  5  6
        &gt;&gt;&gt; df.select_rows("col*")
              0  1
        col1  1  2
        col2  5  6

    :param df: A pandas DataFrame.
    :param args: Valid inputs include: an exact index name to look for,
        a shell-style glob string (e.g. `*_thing_*`),
        a regular expression,
        a callable,
        or variable arguments of all the aforementioned.
        A sequence of booleans is also acceptable.
        A dictionary can be used for selection on a MultiIndex on different levels.
    :param invert: Whether or not to invert the selection.
        This will result in the selection of the complement of the rows
        provided.
    :returns: A pandas DataFrame with the specified rows selected.
    """  # noqa: E501
    return _select(df, args=args, invert=invert, axis="index")
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.shuffle" class="doc doc-heading">
        <code>shuffle</code>



</h2>

    <div class="doc doc-contents ">

      <p>Implementation of <code>shuffle</code> functions.</p>



  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.shuffle.shuffle" class="doc doc-heading">
<code class="highlight language-python">shuffle(df, random_state=None, reset_index=True)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Shuffle the rows of the DataFrame.</p>
<p>This method does not mutate the original DataFrame.</p>
<p>Super-sugary syntax! Underneath the hood, we use <code>df.sample(frac=1)</code>,
with the option to set the random state.</p>
<p>Example:</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({
...     "col1": range(5),
...     "col2": list("abcde"),
... })
&gt;&gt;&gt; df
   col1 col2
0     0    a
1     1    b
2     2    c
3     3    d
4     4    e
&gt;&gt;&gt; df.shuffle(random_state=42)
   col1 col2
0     1    b
1     4    e
2     2    c
3     0    a
4     3    d


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A pandas DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>random_state</code></td>
        <td></td>
        <td><p>If provided, set a seed for the random number generator.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>reset_index</code></td>
        <td><code>bool</code></td>
        <td><p>If True, reset the dataframe index to the default RangeIndex.</p></td>
        <td><code>True</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A shuffled pandas DataFrame.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/shuffle.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
def shuffle(
    df: pd.DataFrame, random_state=None, reset_index: bool = True
) -&gt; pd.DataFrame:
    """Shuffle the rows of the DataFrame.

    This method does not mutate the original DataFrame.

    Super-sugary syntax! Underneath the hood, we use `df.sample(frac=1)`,
    with the option to set the random state.

    Example:

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({
        ...     "col1": range(5),
        ...     "col2": list("abcde"),
        ... })
        &gt;&gt;&gt; df
           col1 col2
        0     0    a
        1     1    b
        2     2    c
        3     3    d
        4     4    e
        &gt;&gt;&gt; df.shuffle(random_state=42)
           col1 col2
        0     1    b
        1     4    e
        2     2    c
        3     0    a
        4     3    d

    :param df: A pandas DataFrame.
    :param random_state: If provided, set a seed for the random number
        generator.
    :param reset_index: If True, reset the dataframe index to the default
        RangeIndex.
    :returns: A shuffled pandas DataFrame.
    """
    result = df.sample(frac=1, random_state=random_state)
    if reset_index:
        result = result.reset_index(drop=True)
    return result
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.sort_column_value_order" class="doc doc-heading">
        <code>sort_column_value_order</code>



</h2>

    <div class="doc doc-contents ">

      <p>Implementation of the <code>sort_column_value_order</code> function.</p>



  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.sort_column_value_order.sort_column_value_order" class="doc doc-heading">
<code class="highlight language-python">sort_column_value_order(df, column, column_value_order, columns=None)</code>


</h3>

    <div class="doc doc-contents ">

      <p>This function adds precedence to certain values in a specified column, then
sorts based on that column and any other specified columns.</p>
<p>Example:</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; company_sales = {
...     "SalesMonth": ["Jan", "Feb", "Feb", "Mar", "April"],
...     "Company1": [150.0, 200.0, 200.0, 300.0, 400.0],
...     "Company2": [180.0, 250.0, 250.0, np.nan, 500.0],
...     "Company3": [400.0, 500.0, 500.0, 600.0, 675.0],
... }
&gt;&gt;&gt; df = pd.DataFrame.from_dict(company_sales)
&gt;&gt;&gt; df
  SalesMonth  Company1  Company2  Company3
0        Jan     150.0     180.0     400.0
1        Feb     200.0     250.0     500.0
2        Feb     200.0     250.0     500.0
3        Mar     300.0       NaN     600.0
4      April     400.0     500.0     675.0
&gt;&gt;&gt; df.sort_column_value_order(
...     "SalesMonth",
...     {"April": 1, "Mar": 2, "Feb": 3, "Jan": 4}
... )
  SalesMonth  Company1  Company2  Company3
4      April     400.0     500.0     675.0
3        Mar     300.0       NaN     600.0
1        Feb     200.0     250.0     500.0
2        Feb     200.0     250.0     500.0
0        Jan     150.0     180.0     400.0


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>This is our DataFrame that we are manipulating</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>column</code></td>
        <td><code>str</code></td>
        <td><p>This is a column name as a string we are using to specify which column to sort by</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>column_value_order</code></td>
        <td><code>dict</code></td>
        <td><p>This is a dictionary of values that will represent precedence of the values in the specified column</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>columns</code></td>
        <td></td>
        <td><p>This is a list of additional columns that we can sort by</p></td>
        <td><code>None</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A sorted pandas DataFrame.</p></td>
    </tr>
  </tbody>
</table>
<p><strong>Exceptions:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>ValueError</code></td>
        <td><p>raises error if chosen Column Name is not in Dataframe, or if column_value_order dictionary is empty.</p></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/sort_column_value_order.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
def sort_column_value_order(
    df: pd.DataFrame, column: str, column_value_order: dict, columns=None
) -&gt; pd.DataFrame:
    """
    This function adds precedence to certain values in a specified column, then
    sorts based on that column and any other specified columns.

    Example:

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; import numpy as np
        &gt;&gt;&gt; company_sales = {
        ...     "SalesMonth": ["Jan", "Feb", "Feb", "Mar", "April"],
        ...     "Company1": [150.0, 200.0, 200.0, 300.0, 400.0],
        ...     "Company2": [180.0, 250.0, 250.0, np.nan, 500.0],
        ...     "Company3": [400.0, 500.0, 500.0, 600.0, 675.0],
        ... }
        &gt;&gt;&gt; df = pd.DataFrame.from_dict(company_sales)
        &gt;&gt;&gt; df
          SalesMonth  Company1  Company2  Company3
        0        Jan     150.0     180.0     400.0
        1        Feb     200.0     250.0     500.0
        2        Feb     200.0     250.0     500.0
        3        Mar     300.0       NaN     600.0
        4      April     400.0     500.0     675.0
        &gt;&gt;&gt; df.sort_column_value_order(
        ...     "SalesMonth",
        ...     {"April": 1, "Mar": 2, "Feb": 3, "Jan": 4}
        ... )
          SalesMonth  Company1  Company2  Company3
        4      April     400.0     500.0     675.0
        3        Mar     300.0       NaN     600.0
        1        Feb     200.0     250.0     500.0
        2        Feb     200.0     250.0     500.0
        0        Jan     150.0     180.0     400.0

    :param df: This is our DataFrame that we are manipulating
    :param column: This is a column name as a string we are using to specify
        which column to sort by
    :param column_value_order: This is a dictionary of values that will
        represent precedence of the values in the specified column
    :param columns: This is a list of additional columns that we can sort by
    :raises ValueError: raises error if chosen Column Name is not in
        Dataframe, or if column_value_order dictionary is empty.
    :return: A sorted pandas DataFrame.
    """
    # Validation checks
    check_column(df, column, present=True)
    check("column_value_order", column_value_order, [dict])
    if not column_value_order:
        raise ValueError("column_value_order dictionary cannot be empty")

    df = df.assign(cond_order=df[column].replace(column_value_order))

    sort_by = ["cond_order"]
    if columns is not None:
        sort_by = ["cond_order"] + columns

    df = df.sort_values(sort_by).remove_columns("cond_order")
    return df
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.sort_naturally" class="doc doc-heading">
        <code>sort_naturally</code>



</h2>

    <div class="doc doc-contents ">

      <p>Implementation of the <code>sort_naturally</code> function.</p>



  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.sort_naturally.sort_naturally" class="doc doc-heading">
<code class="highlight language-python">sort_naturally(df, column_name, **natsorted_kwargs)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Sort a DataFrame by a column using <em>natural</em> sorting.</p>
<p>Natural sorting is distinct from
the default lexiographical sorting provided by <code>pandas</code>.
For example, given the following list of items:</p>
<pre class="highlight"><code>["A1", "A11", "A3", "A2", "A10"]
</code></pre>
<p>lexicographical sorting would give us:</p>
<pre class="highlight"><code>["A1", "A10", "A11", "A2", "A3"]
</code></pre>
<p>By contrast, "natural" sorting would give us:</p>
<pre class="highlight"><code>["A1", "A2", "A3", "A10", "A11"]
</code></pre>
<p>This function thus provides <em>natural</em> sorting
on a single column of a dataframe.</p>
<p>To accomplish this, we do a natural sort
on the unique values that are present in the dataframe.
Then, we reconstitute the entire dataframe
in the naturally sorted order.</p>
<p>Natural sorting is provided by the Python package
<a href="https://natsort.readthedocs.io/en/master/index.html">natsort</a></p>
<p>All keyword arguments to <code>natsort</code> should be provided
after the column name to sort by is provided.
They are passed through to the <code>natsorted</code> function.</p>
<p>Example:</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame(
...     {
...         "Well": ["A21", "A3", "A21", "B2", "B51", "B12"],
...         "Value": [1, 2, 13, 3, 4, 7],
...     }
... )
&gt;&gt;&gt; df
  Well  Value
0  A21      1
1   A3      2
2  A21     13
3   B2      3
4  B51      4
5  B12      7
&gt;&gt;&gt; df.sort_naturally("Well")
  Well  Value
1   A3      2
0  A21      1
2  A21     13
3   B2      3
5  B12      7
4  B51      4


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A pandas DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>column_name</code></td>
        <td><code>str</code></td>
        <td><p>The column on which natural sorting should take place.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>natsorted_kwargs</code></td>
        <td></td>
        <td><p>Keyword arguments to be passed to natsort's <code>natsorted</code> function.</p></td>
        <td><code>{}</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A sorted pandas DataFrame.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/sort_naturally.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
def sort_naturally(
    df: pd.DataFrame, column_name: str, **natsorted_kwargs
) -&gt; pd.DataFrame:
    """Sort a DataFrame by a column using *natural* sorting.

    Natural sorting is distinct from
    the default lexiographical sorting provided by `pandas`.
    For example, given the following list of items:

        ["A1", "A11", "A3", "A2", "A10"]

    lexicographical sorting would give us:


        ["A1", "A10", "A11", "A2", "A3"]

    By contrast, "natural" sorting would give us:

        ["A1", "A2", "A3", "A10", "A11"]

    This function thus provides *natural* sorting
    on a single column of a dataframe.

    To accomplish this, we do a natural sort
    on the unique values that are present in the dataframe.
    Then, we reconstitute the entire dataframe
    in the naturally sorted order.

    Natural sorting is provided by the Python package
    [natsort](https://natsort.readthedocs.io/en/master/index.html)

    All keyword arguments to `natsort` should be provided
    after the column name to sort by is provided.
    They are passed through to the `natsorted` function.

    Example:

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame(
        ...     {
        ...         "Well": ["A21", "A3", "A21", "B2", "B51", "B12"],
        ...         "Value": [1, 2, 13, 3, 4, 7],
        ...     }
        ... )
        &gt;&gt;&gt; df
          Well  Value
        0  A21      1
        1   A3      2
        2  A21     13
        3   B2      3
        4  B51      4
        5  B12      7
        &gt;&gt;&gt; df.sort_naturally("Well")
          Well  Value
        1   A3      2
        0  A21      1
        2  A21     13
        3   B2      3
        5  B12      7
        4  B51      4

    :param df: A pandas DataFrame.
    :param column_name: The column on which natural sorting should take place.
    :param natsorted_kwargs: Keyword arguments to be passed
        to natsort's `natsorted` function.
    :returns: A sorted pandas DataFrame.
    """
    new_order = index_natsorted(df[column_name], **natsorted_kwargs)
    return df.iloc[new_order, :]
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.take_first" class="doc doc-heading">
        <code>take_first</code>



</h2>

    <div class="doc doc-contents ">

      <p>Implementation of take_first function.</p>



  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.take_first.take_first" class="doc doc-heading">
<code class="highlight language-python">take_first(df, subset, by, ascending=True)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Take the first row within each group specified by <code>subset</code>.</p>
<p>Example:</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({"a": ["x", "x", "y", "y"], "b": [0, 1, 2, 3]})
&gt;&gt;&gt; df
   a  b
0  x  0
1  x  1
2  y  2
3  y  3
&gt;&gt;&gt; df.take_first(subset="a", by="b")
   a  b
0  x  0
2  y  2


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A pandas DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>subset</code></td>
        <td><code>Union[Hashable, Iterable[Hashable]]</code></td>
        <td><p>Column(s) defining the group.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>by</code></td>
        <td><code>Hashable</code></td>
        <td><p>Column to sort by.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>ascending</code></td>
        <td><code>bool</code></td>
        <td><p>Whether or not to sort in ascending order, <code>bool</code>.</p></td>
        <td><code>True</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/take_first.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
def take_first(
    df: pd.DataFrame,
    subset: Union[Hashable, Iterable[Hashable]],
    by: Hashable,
    ascending: bool = True,
) -&gt; pd.DataFrame:
    """
    Take the first row within each group specified by `subset`.

    Example:

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({"a": ["x", "x", "y", "y"], "b": [0, 1, 2, 3]})
        &gt;&gt;&gt; df
           a  b
        0  x  0
        1  x  1
        2  y  2
        3  y  3
        &gt;&gt;&gt; df.take_first(subset="a", by="b")
           a  b
        0  x  0
        2  y  2

    :param df: A pandas DataFrame.
    :param subset: Column(s) defining the group.
    :param by: Column to sort by.
    :param ascending: Whether or not to sort in ascending order, `bool`.
    :returns: A pandas DataFrame.
    """
    result = df.sort_values(by=by, ascending=ascending).drop_duplicates(
        subset=subset, keep="first"
    )

    return result
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.then" class="doc doc-heading">
        <code>then</code>



</h2>

    <div class="doc doc-contents ">




  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.then.then" class="doc doc-heading">
<code class="highlight language-python">then(df, func)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Add an arbitrary function to run in the <code>pyjanitor</code> method chain.</p>
<p>This method does not mutate the original DataFrame.</p>
<p>Example: A trivial example using a lambda <code>func</code>.</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; (pd.DataFrame({"a": [1, 2, 3], "b": [7, 8, 9]})
...  .then(lambda df: df * 2))
   a   b
0  2  14
1  4  16
2  6  18


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A pandas DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>func</code></td>
        <td><code>Callable</code></td>
        <td><p>A function you would like to run in the method chain. It should take one parameter and return one parameter, each being the DataFrame object. After that, do whatever you want in the middle. Go crazy.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/then.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
def then(df: pd.DataFrame, func: Callable) -&gt; pd.DataFrame:
    """Add an arbitrary function to run in the `pyjanitor` method chain.

    This method does not mutate the original DataFrame.

    Example: A trivial example using a lambda `func`.

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; (pd.DataFrame({"a": [1, 2, 3], "b": [7, 8, 9]})
        ...  .then(lambda df: df * 2))
           a   b
        0  2  14
        1  4  16
        2  6  18

    :param df: A pandas DataFrame.
    :param func: A function you would like to run in the method chain.
        It should take one parameter and return one parameter, each being the
        DataFrame object. After that, do whatever you want in the middle.
        Go crazy.
    :returns: A pandas DataFrame.
    """
    df = func(df)
    return df
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.to_datetime" class="doc doc-heading">
        <code>to_datetime</code>



</h2>

    <div class="doc doc-contents ">




  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.to_datetime.to_datetime" class="doc doc-heading">
<code class="highlight language-python">to_datetime(df, column_name, **kwargs)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Convert column to a datetime type, in-place.</p>
<p>Intended to be the method-chaining equivalent of:</p>
<pre class="highlight"><code>df[column_name] = pd.to_datetime(df[column_name], **kwargs)
</code></pre>
<p>This method mutates the original DataFrame.</p>
<p>Example: Converting a string column to datetime type with custom format.</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({'date': ['20200101', '20200202', '20200303']})
&gt;&gt;&gt; df
       date
0  20200101
1  20200202
2  20200303
&gt;&gt;&gt; df.to_datetime('date', format='%Y%m%d')
        date
0 2020-01-01
1 2020-02-02
2 2020-03-03
</code></pre>
<p>Read the pandas documentation for <a href="https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html"><code>to_datetime</code></a> for more information.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A pandas DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>column_name</code></td>
        <td><code>Hashable</code></td>
        <td><p>Column name.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>kwargs</code></td>
        <td></td>
        <td><p>Provide any kwargs that <code>pd.to_datetime</code> can take.</p></td>
        <td><code>{}</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame with updated datetime data.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/to_datetime.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
@deprecated_alias(column="column_name")
def to_datetime(
    df: pd.DataFrame, column_name: Hashable, **kwargs
) -&gt; pd.DataFrame:
    """Convert column to a datetime type, in-place.

    Intended to be the method-chaining equivalent of:

        df[column_name] = pd.to_datetime(df[column_name], **kwargs)

    This method mutates the original DataFrame.

    Example: Converting a string column to datetime type with custom format.

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({'date': ['20200101', '20200202', '20200303']})
        &gt;&gt;&gt; df
               date
        0  20200101
        1  20200202
        2  20200303
        &gt;&gt;&gt; df.to_datetime('date', format='%Y%m%d')
                date
        0 2020-01-01
        1 2020-02-02
        2 2020-03-03

    Read the pandas documentation for [`to_datetime`][pd_docs] for more information.

    [pd_docs]: https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html

    :param df: A pandas DataFrame.
    :param column_name: Column name.
    :param kwargs: Provide any kwargs that `pd.to_datetime` can take.
    :returns: A pandas DataFrame with updated datetime data.
    """  # noqa: E501
    df[column_name] = pd.to_datetime(df[column_name], **kwargs)

    return df
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.toset" class="doc doc-heading">
        <code>toset</code>



</h2>

    <div class="doc doc-contents ">

      <p>Implementation of the <code>toset</code> function.</p>



  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.toset.toset" class="doc doc-heading">
<code class="highlight language-python">toset(series)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Return a set of the values.</p>
<p>These are each a scalar type, which is a Python scalar
(for str, int, float) or a pandas scalar
(for Timestamp/Timedelta/Interval/Period)</p>
<p>Example:</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; s = pd.Series([1, 2, 3, 5, 5], index=["a", "b", "c", "d", "e"])
&gt;&gt;&gt; s
a    1
b    2
c    3
d    5
e    5
dtype: int64
&gt;&gt;&gt; s.toset()
{1, 2, 3, 5}


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>series</code></td>
        <td><code>Series</code></td>
        <td><p>A pandas series.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Set</code></td>
      <td><p>A set of values.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/toset.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_series_method
def toset(series: pd.Series) -&gt; Set:
    """Return a set of the values.

    These are each a scalar type, which is a Python scalar
    (for str, int, float) or a pandas scalar
    (for Timestamp/Timedelta/Interval/Period)

    Example:

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; s = pd.Series([1, 2, 3, 5, 5], index=["a", "b", "c", "d", "e"])
        &gt;&gt;&gt; s
        a    1
        b    2
        c    3
        d    5
        e    5
        dtype: int64
        &gt;&gt;&gt; s.toset()
        {1, 2, 3, 5}

    :param series: A pandas series.
    :returns: A set of values.
    """

    return set(series.tolist())
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.transform_columns" class="doc doc-heading">
        <code>transform_columns</code>



</h2>

    <div class="doc doc-contents ">




  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.transform_columns.transform_column" class="doc doc-heading">
<code class="highlight language-python">transform_column(df, column_name, function, dest_column_name=None, elementwise=True)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Transform the given column using the provided function.</p>
<p>Meant to be the method-chaining equivalent of:</p>
<pre><code class="language-python">df[dest_column_name] = df[column_name].apply(function)
</code></pre>
<p>Functions can be applied in one of two ways:</p>
<ul>
<li><strong>Element-wise</strong> (default; <code>elementwise=True</code>). Then, the individual
column elements will be passed in as the first argument of <code>function</code>.</li>
<li><strong>Column-wise</strong> (<code>elementwise=False</code>). Then, <code>function</code> is expected to
take in a pandas Series and return a sequence that is of identical length
to the original.</li>
</ul>
<p>If <code>dest_column_name</code> is provided, then the transformation result is stored
in that column. Otherwise, the transformed result is stored under the name
of the original column.</p>
<p>This method does not mutate the original DataFrame.</p>
<p>Example: Transform a column in-place with an element-wise function.</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({
...     "a": [2, 3, 4],
...     "b": ["area", "pyjanitor", "grapefruit"],
... })
&gt;&gt;&gt; df
   a           b
0  2        area
1  3   pyjanitor
2  4  grapefruit
&gt;&gt;&gt; df.transform_column(
...     column_name="a",
...     function=lambda x: x**2 - 1,
... )
    a           b
0   3        area
1   8   pyjanitor
2  15  grapefruit
</code></pre>
<p>Example: Transform a column in-place with an column-wise function.</p>
<pre class="highlight"><code>&gt;&gt;&gt; df.transform_column(
...     column_name="b",
...     function=lambda srs: srs.str[:5],
...     elementwise=False,
... )
   a      b
0  2   area
1  3  pyjan
2  4  grape


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A pandas DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>column_name</code></td>
        <td><code>Hashable</code></td>
        <td><p>The column to transform.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>function</code></td>
        <td><code>Callable</code></td>
        <td><p>A function to apply on the column.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>dest_column_name</code></td>
        <td><code>Optional[str]</code></td>
        <td><p>The column name to store the transformation result in. Defaults to None, which will result in the original column name being overwritten. If a name is provided here, then a new column with the transformed values will be created.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>elementwise</code></td>
        <td><code>bool</code></td>
        <td><p>Whether to apply the function elementwise or not. If <code>elementwise</code> is True, then the function's first argument should be the data type of each datum in the column of data, and should return a transformed datum. If <code>elementwise</code> is False, then the function's should expect a pandas Series passed into it, and return a pandas Series.</p></td>
        <td><code>True</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame with a transformed column.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/transform_columns.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
@deprecated_alias(col_name="column_name", dest_col_name="dest_column_name")
def transform_column(
    df: pd.DataFrame,
    column_name: Hashable,
    function: Callable,
    dest_column_name: Optional[str] = None,
    elementwise: bool = True,
) -&gt; pd.DataFrame:
    """Transform the given column using the provided function.

    Meant to be the method-chaining equivalent of:
    ```python
    df[dest_column_name] = df[column_name].apply(function)
    ```

    Functions can be applied in one of two ways:

    - **Element-wise** (default; `elementwise=True`). Then, the individual
    column elements will be passed in as the first argument of `function`.
    - **Column-wise** (`elementwise=False`). Then, `function` is expected to
    take in a pandas Series and return a sequence that is of identical length
    to the original.

    If `dest_column_name` is provided, then the transformation result is stored
    in that column. Otherwise, the transformed result is stored under the name
    of the original column.

    This method does not mutate the original DataFrame.

    Example: Transform a column in-place with an element-wise function.

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({
        ...     "a": [2, 3, 4],
        ...     "b": ["area", "pyjanitor", "grapefruit"],
        ... })
        &gt;&gt;&gt; df
           a           b
        0  2        area
        1  3   pyjanitor
        2  4  grapefruit
        &gt;&gt;&gt; df.transform_column(
        ...     column_name="a",
        ...     function=lambda x: x**2 - 1,
        ... )
            a           b
        0   3        area
        1   8   pyjanitor
        2  15  grapefruit

    Example: Transform a column in-place with an column-wise function.

        &gt;&gt;&gt; df.transform_column(
        ...     column_name="b",
        ...     function=lambda srs: srs.str[:5],
        ...     elementwise=False,
        ... )
           a      b
        0  2   area
        1  3  pyjan
        2  4  grape

    :param df: A pandas DataFrame.
    :param column_name: The column to transform.
    :param function: A function to apply on the column.
    :param dest_column_name: The column name to store the transformation result
        in. Defaults to None, which will result in the original column
        name being overwritten. If a name is provided here, then a new column
        with the transformed values will be created.
    :param elementwise: Whether to apply the function elementwise or not.
        If `elementwise` is True, then the function's first argument
        should be the data type of each datum in the column of data,
        and should return a transformed datum.
        If `elementwise` is False, then the function's should expect
        a pandas Series passed into it, and return a pandas Series.

    :returns: A pandas DataFrame with a transformed column.
    """
    check_column(df, column_name)

    if dest_column_name is None:
        dest_column_name = column_name
    elif dest_column_name != column_name:
        # If `dest_column_name` is provided and equals `column_name`, then we
        # assume that the user's intent is to perform an in-place
        # transformation (Same behaviour as when `dest_column_name` = None).
        # Otherwise we throw an error if `dest_column_name` already exists in
        # df.
        check_column(df, dest_column_name, present=False)

    result = _get_transform_column_result(
        df[column_name],
        function,
        elementwise,
    )

    return df.assign(**{dest_column_name: result})
</code></pre>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.transform_columns.transform_columns" class="doc doc-heading">
<code class="highlight language-python">transform_columns(df, column_names, function, suffix=None, elementwise=True, new_column_names=None)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Transform multiple columns through the same transformation.</p>
<p>This method does not mutate the original DataFrame.</p>
<p>Super syntactic sugar!
Essentially wraps <a class="autorefs autorefs-internal" href="#janitor.functions.transform_columns.transform_column"><code>transform_column</code></a>
and calls it repeatedly over all column names provided.</p>
<p>User can optionally supply either a suffix to create a new set of columns
with the specified suffix, or provide a dictionary mapping each original
column name in <code>column_names</code> to its corresponding new column name.
Note that all column names must be strings.</p>
<p>Example: log10 transform a list of columns, replacing original columns.</p>
<pre class="highlight"><code>&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({
...     "col1": [5, 10, 15],
...     "col2": [3, 6, 9],
...     "col3": [10, 100, 1_000],
... })
&gt;&gt;&gt; df
   col1  col2  col3
0     5     3    10
1    10     6   100
2    15     9  1000
&gt;&gt;&gt; df.transform_columns(["col1", "col2", "col3"], np.log10)
       col1      col2  col3
0  0.698970  0.477121   1.0
1  1.000000  0.778151   2.0
2  1.176091  0.954243   3.0
</code></pre>
<p>Example: Using the <code>suffix</code> parameter to create new columns.</p>
<pre class="highlight"><code>&gt;&gt;&gt; df.transform_columns(["col1", "col3"], np.log10, suffix="_log")
   col1  col2  col3  col1_log  col3_log
0     5     3    10  0.698970       1.0
1    10     6   100  1.000000       2.0
2    15     9  1000  1.176091       3.0
</code></pre>
<p>Example: Using the <code>new_column_names</code> parameter to create new columns.</p>
<pre class="highlight"><code>&gt;&gt;&gt; df.transform_columns(
...     ["col1", "col3"],
...     np.log10,
...     new_column_names={"col1": "transform1"},
... )
   col1  col2  col3  transform1
0     5     3   1.0    0.698970
1    10     6   2.0    1.000000
2    15     9   3.0    1.176091


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A pandas DataFrame.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>column_names</code></td>
        <td><code>Union[List[str], Tuple[str]]</code></td>
        <td><p>An iterable of columns to transform.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>function</code></td>
        <td><code>Callable</code></td>
        <td><p>A function to apply on each column.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>suffix</code></td>
        <td><code>Optional[str]</code></td>
        <td><p>Suffix to use when creating new columns to hold the transformed values.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>elementwise</code></td>
        <td><code>bool</code></td>
        <td><p>Passed on to <code>transform_column</code>; whether or not to apply the transformation function elementwise (True) or columnwise (False).</p></td>
        <td><code>True</code></td>
      </tr>
      <tr>
        <td><code>new_column_names</code></td>
        <td><code>Optional[Dict[str, str]]</code></td>
        <td><p>An explicit mapping of old column names in <code>column_names</code> to new column names. If any column specified in <code>column_names</code> is not a key in this dictionary, the transformation will happen in-place for that column.</p></td>
        <td><code>None</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame with transformed columns.</p></td>
    </tr>
  </tbody>
</table>
<p><strong>Exceptions:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>ValueError</code></td>
        <td><p>If both <code>suffix</code> and <code>new_column_names</code> are specified.</p></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/transform_columns.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
@deprecated_alias(columns="column_names", new_names="new_column_names")
def transform_columns(
    df: pd.DataFrame,
    column_names: Union[List[str], Tuple[str]],
    function: Callable,
    suffix: Optional[str] = None,
    elementwise: bool = True,
    new_column_names: Optional[Dict[str, str]] = None,
) -&gt; pd.DataFrame:
    """Transform multiple columns through the same transformation.

    This method does not mutate the original DataFrame.

    Super syntactic sugar!
    Essentially wraps [`transform_column`][janitor.functions.transform_columns.transform_column]
    and calls it repeatedly over all column names provided.

    User can optionally supply either a suffix to create a new set of columns
    with the specified suffix, or provide a dictionary mapping each original
    column name in `column_names` to its corresponding new column name.
    Note that all column names must be strings.

    Example: log10 transform a list of columns, replacing original columns.

        &gt;&gt;&gt; import numpy as np
        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({
        ...     "col1": [5, 10, 15],
        ...     "col2": [3, 6, 9],
        ...     "col3": [10, 100, 1_000],
        ... })
        &gt;&gt;&gt; df
           col1  col2  col3
        0     5     3    10
        1    10     6   100
        2    15     9  1000
        &gt;&gt;&gt; df.transform_columns(["col1", "col2", "col3"], np.log10)
               col1      col2  col3
        0  0.698970  0.477121   1.0
        1  1.000000  0.778151   2.0
        2  1.176091  0.954243   3.0

    Example: Using the `suffix` parameter to create new columns.

        &gt;&gt;&gt; df.transform_columns(["col1", "col3"], np.log10, suffix="_log")
           col1  col2  col3  col1_log  col3_log
        0     5     3    10  0.698970       1.0
        1    10     6   100  1.000000       2.0
        2    15     9  1000  1.176091       3.0

    Example: Using the `new_column_names` parameter to create new columns.

        &gt;&gt;&gt; df.transform_columns(
        ...     ["col1", "col3"],
        ...     np.log10,
        ...     new_column_names={"col1": "transform1"},
        ... )
           col1  col2  col3  transform1
        0     5     3   1.0    0.698970
        1    10     6   2.0    1.000000
        2    15     9   3.0    1.176091

    :param df: A pandas DataFrame.
    :param column_names: An iterable of columns to transform.
    :param function: A function to apply on each column.
    :param suffix: Suffix to use when creating new columns to hold
        the transformed values.
    :param elementwise: Passed on to `transform_column`; whether or not
        to apply the transformation function elementwise (True)
        or columnwise (False).
    :param new_column_names: An explicit mapping of old column names in
        `column_names` to new column names. If any column specified in
        `column_names` is not a key in this dictionary, the transformation
        will happen in-place for that column.
    :returns: A pandas DataFrame with transformed columns.
    :raises ValueError: If both `suffix` and `new_column_names` are
        specified.
    """  # noqa: E501
    check("column_names", column_names, [list, tuple])
    check_column(df, column_names)

    if suffix is not None and new_column_names is not None:
        raise ValueError(
            "Only one of `suffix` or `new_column_names` should be specified."
        )

    if suffix:
        check("suffix", suffix, [str])
        dest_column_names = {col: col + suffix for col in column_names}
    elif new_column_names:
        check("new_column_names", new_column_names, [dict])
        dest_column_names = {
            col: new_column_names.get(col, col) for col in column_names
        }
    else:
        dest_column_names = dict(zip(column_names, column_names))

    results = {}
    for old_col, new_col in dest_column_names.items():
        if old_col != new_col:
            check_column(df, new_col, present=False)
        results[new_col] = _get_transform_column_result(
            df[old_col],
            function,
            elementwise=elementwise,
        )

    return df.assign(**results)
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.truncate_datetime" class="doc doc-heading">
        <code>truncate_datetime</code>



</h2>

    <div class="doc doc-contents ">

      <p>Implementation of the <code>truncate_datetime</code> family of functions.</p>



  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.truncate_datetime.truncate_datetime_dataframe" class="doc doc-heading">
<code class="highlight language-python">truncate_datetime_dataframe(df, datepart)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Truncate times down to a user-specified precision of
year, month, day, hour, minute, or second.</p>
<p>This method does not mutate the original DataFrame.</p>
<p>Examples:</p>
<pre class="highlight"><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import janitor
&gt;&gt;&gt; df = pd.DataFrame({
...     "foo": ["xxxx", "yyyy", "zzzz"],
...     "dt": pd.date_range("2020-03-11", periods=3, freq="15H"),
... })
&gt;&gt;&gt; df
    foo                  dt
0  xxxx 2020-03-11 00:00:00
1  yyyy 2020-03-11 15:00:00
2  zzzz 2020-03-12 06:00:00
&gt;&gt;&gt; df.truncate_datetime_dataframe("day")
    foo         dt
0  xxxx 2020-03-11
1  yyyy 2020-03-11
2  zzzz 2020-03-12


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>The pandas DataFrame on which to truncate datetime.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>datepart</code></td>
        <td><code>str</code></td>
        <td><p>Truncation precision, YEAR, MONTH, DAY, HOUR, MINUTE, SECOND. (String is automagically capitalized)</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame with all valid datetimes truncated down to the specified precision.</p></td>
    </tr>
  </tbody>
</table>
<p><strong>Exceptions:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>ValueError</code></td>
        <td><p>If an invalid <code>datepart</code> precision is passed in.</p></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/truncate_datetime.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
def truncate_datetime_dataframe(
    df: pd.DataFrame,
    datepart: str,
) -&gt; pd.DataFrame:
    """Truncate times down to a user-specified precision of
    year, month, day, hour, minute, or second.

    This method does not mutate the original DataFrame.

    Examples:

        &gt;&gt;&gt; import pandas as pd
        &gt;&gt;&gt; import janitor
        &gt;&gt;&gt; df = pd.DataFrame({
        ...     "foo": ["xxxx", "yyyy", "zzzz"],
        ...     "dt": pd.date_range("2020-03-11", periods=3, freq="15H"),
        ... })
        &gt;&gt;&gt; df
            foo                  dt
        0  xxxx 2020-03-11 00:00:00
        1  yyyy 2020-03-11 15:00:00
        2  zzzz 2020-03-12 06:00:00
        &gt;&gt;&gt; df.truncate_datetime_dataframe("day")
            foo         dt
        0  xxxx 2020-03-11
        1  yyyy 2020-03-11
        2  zzzz 2020-03-12

    :param df: The pandas DataFrame on which to truncate datetime.
    :param datepart: Truncation precision, YEAR, MONTH, DAY,
        HOUR, MINUTE, SECOND. (String is automagically
        capitalized)

    :raises ValueError: If an invalid `datepart` precision is passed in.
    :returns: A pandas DataFrame with all valid datetimes truncated down
        to the specified precision.
    """
    ACCEPTABLE_DATEPARTS = ("YEAR", "MONTH", "DAY", "HOUR", "MINUTE", "SECOND")
    datepart = datepart.upper()
    if datepart not in ACCEPTABLE_DATEPARTS:
        raise ValueError(
            "Received an invalid `datepart` precision. "
            f"Please enter any one of {ACCEPTABLE_DATEPARTS}."
        )

    dt_cols = [
        column
        for column, coltype in df.dtypes.items()
        if is_datetime64_any_dtype(coltype)
    ]
    if not dt_cols:
        # avoid copying df if no-op is expected
        return df

    df = df.copy()
    # NOTE: use **kwargs of `applymap` instead of lambda when we upgrade to
    #   pandas &gt;= 1.3.0
    df[dt_cols] = df[dt_cols].applymap(
        lambda x: _truncate_datetime(x, datepart=datepart),
    )

    return df
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.update_where" class="doc doc-heading">
        <code>update_where</code>



</h2>

    <div class="doc doc-contents ">

      <p>Function for updating values based on other column values</p>



  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.update_where.update_where" class="doc doc-heading">
<code class="highlight language-python">update_where(df, conditions, target_column_name, target_val)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Add multiple conditions to update a column in the dataframe.</p>
<p>This method does not mutate the original DataFrame.</p>
<p>Example usage:</p>
<pre class="highlight"><code>&gt;&gt;&gt; data = {
...    "a": [1, 2, 3, 4],
...    "b": [5, 6, 7, 8],
...    "c": [0, 0, 0, 0],
... }
&gt;&gt;&gt; df = pd.DataFrame(data)
&gt;&gt;&gt; df
   a  b  c
0  1  5  0
1  2  6  0
2  3  7  0
3  4  8  0
&gt;&gt;&gt; df.update_where(
...    conditions = (df.a &gt; 2) &amp; (df.b &lt; 8),
...    target_column_name = 'c',
...    target_val = 10
... )
   a  b   c
0  1  5   0
1  2  6   0
2  3  7  10
3  4  8   0
&gt;&gt;&gt; df.update_where( # supports pandas *query* style string expressions
...    conditions = "a &gt; 2 and b &lt; 8",
...    target_column_name = 'c',
...    target_val = 10
... )
   a  b   c
0  1  5   0
1  2  6   0
2  3  7  10
3  4  8   0


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>The pandas DataFrame object.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>conditions</code></td>
        <td><code>Any</code></td>
        <td><p>Conditions used to update a target column and target value.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>target_column_name</code></td>
        <td><code>Hashable</code></td>
        <td><p>Column to be updated. If column does not exist in DataFrame, a new column will be created; note that entries that do not get set in the new column will be null.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>target_val</code></td>
        <td><code>Any</code></td>
        <td><p>Value to be updated</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>A pandas DataFrame.</p></td>
    </tr>
  </tbody>
</table>
<p><strong>Exceptions:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>ValueError</code></td>
        <td><p>if <code>conditions</code> does not return a boolean array-like data structure.  .. # noqa: DAR402</p></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/update_where.py</code></summary>
          <pre class="highlight"><code class="language-python">@pf.register_dataframe_method
@deprecated_alias(target_col="target_column_name")
def update_where(
    df: pd.DataFrame,
    conditions: Any,
    target_column_name: Hashable,
    target_val: Any,
) -&gt; pd.DataFrame:
    """
    Add multiple conditions to update a column in the dataframe.

    This method does not mutate the original DataFrame.

    Example usage:

        &gt;&gt;&gt; data = {
        ...    "a": [1, 2, 3, 4],
        ...    "b": [5, 6, 7, 8],
        ...    "c": [0, 0, 0, 0],
        ... }
        &gt;&gt;&gt; df = pd.DataFrame(data)
        &gt;&gt;&gt; df
           a  b  c
        0  1  5  0
        1  2  6  0
        2  3  7  0
        3  4  8  0
        &gt;&gt;&gt; df.update_where(
        ...    conditions = (df.a &gt; 2) &amp; (df.b &lt; 8),
        ...    target_column_name = 'c',
        ...    target_val = 10
        ... )
           a  b   c
        0  1  5   0
        1  2  6   0
        2  3  7  10
        3  4  8   0
        &gt;&gt;&gt; df.update_where( # supports pandas *query* style string expressions
        ...    conditions = "a &gt; 2 and b &lt; 8",
        ...    target_column_name = 'c',
        ...    target_val = 10
        ... )
           a  b   c
        0  1  5   0
        1  2  6   0
        2  3  7  10
        3  4  8   0

    :param df: The pandas DataFrame object.
    :param conditions: Conditions used to update a target column
        and target value.
    :param target_column_name: Column to be updated. If column does not exist
        in DataFrame, a new column will be created; note that entries that do
        not get set in the new column will be null.
    :param target_val: Value to be updated
    :returns: A pandas DataFrame.
    :raises ValueError: if `conditions` does not return a boolean array-like
        data structure.

    .. # noqa: DAR402
    """

    df = df.copy()

    # use query mode if a string expression is passed
    if isinstance(conditions, str):
        conditions = df.eval(conditions)

    if not is_bool_dtype(conditions):
        raise ValueError(
            """
            Kindly ensure that `conditions` passed
            evaluates to a Boolean dtype.
            """
        )

    df.loc[conditions, target_column_name] = target_val

    return df
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="janitor.functions.utils" class="doc doc-heading">
        <code>utils</code>



</h2>

    <div class="doc doc-contents ">

      <p>Utility functions for all of the functions submodule.</p>



  <div class="doc doc-children">







  <div class="doc doc-object doc-class">



<h3 id="janitor.functions.utils.DropLabel" class="doc doc-heading">
        <code>
DropLabel        </code>


  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-dataclass"><code>dataclass</code></small>
  </span>

</h3>

    <div class="doc doc-contents ">

      <p>Helper class for removing labels within the <code>select</code> syntax.
<code>label</code> can be any of the types supported in the <code>select</code>,
<code>select_rows</code> and <code>select_columns</code> functions.
An array of integers not matching the labels is returned.</p>
<div class="admonition info">
<p class="admonition-title">New in version 0.24.0</p>
</div>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>label</code></td>
        <td></td>
        <td><p>Label(s) to be dropped from the index.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td></td>
      <td><p>A dataclass.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/utils.py</code></summary>
          <pre class="highlight"><code class="language-python">@dataclass
class DropLabel:
    """
    Helper class for removing labels within the `select` syntax.
    `label` can be any of the types supported in the `select`,
    `select_rows` and `select_columns` functions.
    An array of integers not matching the labels is returned.

    !!! info "New in version 0.24.0"

    :param label: Label(s) to be dropped from the index.
    :returns: A dataclass.
    """

    label: Any
</code></pre>
        </details>



  <div class="doc doc-children">















  </div>

    </div>

  </div>




  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.utils.patterns" class="doc doc-heading">
<code class="highlight language-python">patterns(regex_pattern)</code>


</h3>

    <div class="doc doc-contents ">

      <p>This function converts a string into a compiled regular expression;
it can be used to select columns in the index or columns_names
arguments of <code>pivot_longer</code> function.</p>
<p><strong>Warning</strong>:</p>
<pre class="highlight"><code>This function is deprecated. Kindly use `re.compile` instead.


</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>regex_pattern</code></td>
        <td><code>Union[str, Pattern]</code></td>
        <td><p>string to be converted to compiled regular expression.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Pattern</code></td>
      <td><p>A compile regular expression from provided <code>regex_pattern</code>.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/utils.py</code></summary>
          <pre class="highlight"><code class="language-python">def patterns(regex_pattern: Union[str, Pattern]) -&gt; Pattern:
    """
    This function converts a string into a compiled regular expression;
    it can be used to select columns in the index or columns_names
    arguments of `pivot_longer` function.

    **Warning**:

        This function is deprecated. Kindly use `re.compile` instead.

    :param regex_pattern: string to be converted to compiled regular
        expression.
    :returns: A compile regular expression from provided
        `regex_pattern`.
    """
    warnings.warn(
        "This function is deprecated. Kindly use `re.compile` instead.",
        DeprecationWarning,
        stacklevel=2,
    )
    check("regular expression", regex_pattern, [str, Pattern])

    return re.compile(regex_pattern)
</code></pre>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-function">



<h3 id="janitor.functions.utils.unionize_dataframe_categories" class="doc doc-heading">
<code class="highlight language-python">unionize_dataframe_categories(*dataframes, *, column_names=None)</code>


</h3>

    <div class="doc doc-contents ">

      <p>Given a group of dataframes which contain some categorical columns, for
each categorical column present, find all the possible categories across
all the dataframes which have that column.
Update each dataframes' corresponding column with a new categorical object
that contains the original data
but has labels for all the possible categories from all dataframes.
This is useful when concatenating a list of dataframes which all have the
same categorical columns into one dataframe.</p>
<p>If, for a given categorical column, all input dataframes do not have at
least one instance of all the possible categories,
Pandas will change the output dtype of that column from <code>category</code> to
<code>object</code>, losing out on dramatic speed gains you get from the former
format.</p>
<p>Usage example for concatenation of categorical column-containing
dataframes:</p>
<p>Instead of:</p>
<pre><code class="language-python">concatenated_df = pd.concat([df1, df2, df3], ignore_index=True)
</code></pre>
<p>which in your case has resulted in <code>category</code> -&gt; <code>object</code> conversion,
use:</p>
<pre><code class="language-python">unionized_dataframes = unionize_dataframe_categories(df1, df2, df2)
concatenated_df = pd.concat(unionized_dataframes, ignore_index=True)
</code></pre>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>dataframes</code></td>
        <td></td>
        <td><p>The dataframes you wish to unionize the categorical objects for.</p></td>
        <td><code>()</code></td>
      </tr>
      <tr>
        <td><code>column_names</code></td>
        <td><code>Optional[Iterable[pandas.core.dtypes.dtypes.CategoricalDtype]]</code></td>
        <td><p>If supplied, only unionize this subset of columns.</p></td>
        <td><code>None</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>List[pandas.core.frame.DataFrame]</code></td>
      <td><p>A list of the category-unioned dataframes in the same order they were provided.</p></td>
    </tr>
  </tbody>
</table>
<p><strong>Exceptions:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>TypeError</code></td>
        <td><p>If any of the inputs are not pandas DataFrames.</p></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>janitor/functions/utils.py</code></summary>
          <pre class="highlight"><code class="language-python">def unionize_dataframe_categories(
    *dataframes, column_names: Optional[Iterable[pd.CategoricalDtype]] = None
) -&gt; List[pd.DataFrame]:
    """
    Given a group of dataframes which contain some categorical columns, for
    each categorical column present, find all the possible categories across
    all the dataframes which have that column.
    Update each dataframes' corresponding column with a new categorical object
    that contains the original data
    but has labels for all the possible categories from all dataframes.
    This is useful when concatenating a list of dataframes which all have the
    same categorical columns into one dataframe.

    If, for a given categorical column, all input dataframes do not have at
    least one instance of all the possible categories,
    Pandas will change the output dtype of that column from `category` to
    `object`, losing out on dramatic speed gains you get from the former
    format.

    Usage example for concatenation of categorical column-containing
    dataframes:

    Instead of:

    ```python
    concatenated_df = pd.concat([df1, df2, df3], ignore_index=True)
    ```

    which in your case has resulted in `category` -&gt; `object` conversion,
    use:

    ```python
    unionized_dataframes = unionize_dataframe_categories(df1, df2, df2)
    concatenated_df = pd.concat(unionized_dataframes, ignore_index=True)
    ```

    :param dataframes: The dataframes you wish to unionize the categorical
        objects for.
    :param column_names: If supplied, only unionize this subset of columns.
    :returns: A list of the category-unioned dataframes in the same order they
        were provided.
    :raises TypeError: If any of the inputs are not pandas DataFrames.
    """

    if any(not isinstance(df, pd.DataFrame) for df in dataframes):
        raise TypeError("Inputs must all be dataframes.")

    if column_names is None:
        # Find all columns across all dataframes that are categorical

        column_names = set()

        for dataframe in dataframes:
            column_names = column_names.union(
                [
                    column_name
                    for column_name in dataframe.columns
                    if isinstance(
                        dataframe[column_name].dtype, pd.CategoricalDtype
                    )
                ]
            )

    else:
        column_names = [column_names]
    # For each categorical column, find all possible values across the DFs

    category_unions = {
        column_name: union_categoricals(
            [df[column_name] for df in dataframes if column_name in df.columns]
        )
        for column_name in column_names
    }

    # Make a shallow copy of all DFs and modify the categorical columns
    # such that they can encode the union of all possible categories for each.

    refactored_dfs = []

    for df in dataframes:
        df = df.copy(deep=False)

        for column_name, categorical in category_unions.items():
            if column_name in df.columns:
                df[column_name] = pd.Categorical(
                    df[column_name], categories=categorical.categories
                )

        refactored_dfs.append(df)

    return refactored_dfs
</code></pre>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>




  </div>

    </div>

  </div>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    
    <nav class="md-footer__inner md-grid" aria-label="Footer" >
      
        
        <a href="../../devguide/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Development Guide" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              Development Guide
            </div>
          </div>
        </a>
      
      
        
        <a href="../biology/" class="md-footer__link md-footer__link--next" aria-label="Next: Biology" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              Biology
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["instant"], "search": "../../assets/javascripts/workers/search.ecf98df9.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.39f04ddb.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.7.2/highlight.min.js"></script>
      
        <script src="../../js/config.js"></script>
      
    
  </body>
</html>